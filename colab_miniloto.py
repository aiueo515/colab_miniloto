# ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  ãƒ‘ãƒ¼ãƒˆ1A: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå‰åŠï¼‰
# ========================= ãƒ‘ãƒ¼ãƒˆ1Aé–‹å§‹ =========================

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from collections import Counter, defaultdict
import json
import traceback
import gc
from datetime import datetime, timedelta
import requests
import io

print("ğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‘ãƒ¼ãƒˆ1A: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå‰åŠï¼‰")
print("ğŸ¯ å¯¾è±¡: ãƒŸãƒ‹ãƒ­ãƒˆï¼ˆ1-31ã‹ã‚‰5å€‹é¸æŠ + ãƒœãƒ¼ãƒŠã‚¹1å€‹ï¼‰")
print("ğŸ“Š ç‰¹å¾´é‡: 14æ¬¡å…ƒæœ€é©åŒ–ç‰ˆ")
print("ğŸ”§ å›ºå®šçª“: 50å›åˆ†ã«èª¿æ•´")

# ãƒŸãƒ‹ãƒ­ãƒˆç”¨è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹
class MiniLotoDataFetcher:
    def __init__(self):
        self.csv_url = "https://miniloto.thekyo.jp/data/miniloto.csv"
        # ãƒŸãƒ‹ãƒ­ãƒˆç”¨ã‚«ãƒ©ãƒ ï¼ˆæ–‡å­—åŒ–ã‘å¯¾å¿œï¼‰
        self.main_columns = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
        self.bonus_column = 'ãƒœãƒ¼ãƒŠã‚¹æ•°å­—'
        self.round_column = 'é–‹å‚¬å›'
        self.date_column = 'æ—¥ä»˜'
        self.latest_data = None
        self.latest_round = 0
        
        # æ–‡å­—åŒ–ã‘å¯¾å¿œã®ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°
        self.column_mapping = {
            0: 'é–‹å‚¬å›',      # ç¬¬1ã‚«ãƒ©ãƒ 
            1: 'æ—¥ä»˜',        # ç¬¬2ã‚«ãƒ©ãƒ   
            2: 'ç¬¬1æ•°å­—',     # ç¬¬3ã‚«ãƒ©ãƒ 
            3: 'ç¬¬2æ•°å­—',     # ç¬¬4ã‚«ãƒ©ãƒ 
            4: 'ç¬¬3æ•°å­—',     # ç¬¬5ã‚«ãƒ©ãƒ 
            5: 'ç¬¬4æ•°å­—',     # ç¬¬6ã‚«ãƒ©ãƒ 
            6: 'ç¬¬5æ•°å­—',     # ç¬¬7ã‚«ãƒ©ãƒ 
            7: 'ãƒœãƒ¼ãƒŠã‚¹æ•°å­—'  # ç¬¬8ã‚«ãƒ©ãƒ 
        }
        
    def fetch_latest_data(self):
        """æœ€æ–°ã®ãƒŸãƒ‹ãƒ­ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å–å¾—"""
        try:
            print("ğŸŒ === ãƒŸãƒ‹ãƒ­ãƒˆè‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ ===")
            print(f"ğŸ“¡ URL: {self.csv_url}")
            
            # CSVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            response = requests.get(self.csv_url, timeout=30)
            response.raise_for_status()
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(response.content)} bytes")
            
            # CSVã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆæ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è€ƒæ…®ï¼‰
            try:
                # shift-jisã§è©¦ã™ï¼ˆæ—¥æœ¬ã®CSVã®ä¸€èˆ¬çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
                csv_content = response.content.decode('shift-jis')
                df = pd.read_csv(io.StringIO(csv_content))
            except:
                try:
                    # UTF-8ã§è©¦ã™
                    csv_content = response.content.decode('utf-8')
                    df = pd.read_csv(io.StringIO(csv_content))
                except:
                    # cp932ã§è©¦ã™
                    csv_content = response.content.decode('cp932')
                    df = pd.read_csv(io.StringIO(csv_content))
            
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
            
            # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–ï¼ˆä½ç½®ãƒ™ãƒ¼ã‚¹ã§å®‰å…¨ã«å‡¦ç†ï¼‰
            if len(df.columns) >= 8:
                # æ–°ã—ã„ã‚«ãƒ©ãƒ åã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å†æ§‹ç¯‰
                normalized_data = {}
                
                for i, new_col_name in self.column_mapping.items():
                    if i < len(df.columns):
                        normalized_data[new_col_name] = df.iloc[:, i].values
                
                # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                self.latest_data = pd.DataFrame(normalized_data)
                
                # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèªã¨ä¿®æ­£
                for col in ['é–‹å‚¬å›', 'ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—', 'ãƒœãƒ¼ãƒŠã‚¹æ•°å­—']:
                    if col in self.latest_data.columns:
                        self.latest_data[col] = pd.to_numeric(self.latest_data[col], errors='coerce')
                
                # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
                self.latest_data = self.latest_data.dropna()
                
                print(f"ğŸ“‹ æ­£è¦åŒ–å®Œäº†: {list(self.latest_data.columns)}")
                
                # æœ€æ–°å›ã‚’å–å¾—
                if 'é–‹å‚¬å›' in self.latest_data.columns:
                    self.latest_round = int(self.latest_data['é–‹å‚¬å›'].max())
                    print(f"ğŸ¯ æœ€æ–°é–‹å‚¬å›: ç¬¬{self.latest_round}å›")
                    
                    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                    latest_entry = self.latest_data[self.latest_data['é–‹å‚¬å›'] == self.latest_round].iloc[0]
                    print(f"ğŸ“… æœ€æ–°å›æ—¥ä»˜: {latest_entry.get('æ—¥ä»˜', 'N/A')}")
                    
                    main_nums = [int(latest_entry[f'ç¬¬{i}æ•°å­—']) for i in range(1, 6)]
                    bonus_num = int(latest_entry['ãƒœãƒ¼ãƒŠã‚¹æ•°å­—'])
                    print(f"ğŸ² æœ€æ–°å›å½“é¸ç•ªå·: {main_nums} + ãƒœãƒ¼ãƒŠã‚¹{bonus_num}")
                
                print("âœ… ãƒŸãƒ‹ãƒ­ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
                return True
            else:
                print("âŒ CSVã®æ§‹é€ ãŒæœŸå¾…ã¨ç•°ãªã‚Šã¾ã™")
                return False
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"è©³ç´°: {traceback.format_exc()}")
            return False
    
    def get_next_round_info(self):
        """æ¬¡å›é–‹å‚¬å›ã®æƒ…å ±ã‚’å–å¾—"""
        if self.latest_round == 0:
            return None
            
        next_round = self.latest_round + 1
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        return {
            'next_round': next_round,
            'current_date': current_date,
            'latest_round': self.latest_round,
            'prediction_target': f"ç¬¬{next_round}å›"
        }
    
    def get_data_for_training(self):
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
        if self.latest_data is None:
            return None
        return self.latest_data

# ãƒŸãƒ‹ãƒ­ãƒˆç”¨äºˆæ¸¬è¨˜éŒ²ç®¡ç†ã‚¯ãƒ©ã‚¹
class MiniLotoPredictionHistory:
    def __init__(self):
        self.predictions = []  # [{'round': int, 'date': str, 'predictions': list, 'actual': list or None}]
        self.accuracy_stats = {}
        
    def add_prediction_with_round(self, predictions, target_round, date=None):
        """é–‹å‚¬å›ä»˜ãã§äºˆæ¸¬ã‚’è¨˜éŒ²"""
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        entry = {
            'round': target_round,
            'date': date,
            'predictions': predictions.copy(),
            'actual': None,
            'matches': [],
            'verified': False
        }
        self.predictions.append(entry)
        print(f"ğŸ“ äºˆæ¸¬è¨˜éŒ²: ç¬¬{target_round}å› - {date} - {len(predictions)}ã‚»ãƒƒãƒˆ")
        
    def find_prediction_by_round(self, round_number):
        """æŒ‡å®šé–‹å‚¬å›ã®äºˆæ¸¬ã‚’æ¤œç´¢"""
        for entry in self.predictions:
            if entry['round'] == round_number:
                return entry
        return None
    
    def auto_verify_with_data(self, latest_data, round_col='é–‹å‚¬å›'):
        """æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã¨è‡ªå‹•ç…§åˆ"""
        verified_count = 0
        main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
        
        for entry in self.predictions:
            if entry['verified']:
                continue
                
            # è©²å½“ã™ã‚‹é–‹å‚¬å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            matching_data = latest_data[latest_data[round_col] == entry['round']]
            
            if len(matching_data) > 0:
                actual_row = matching_data.iloc[0]
                actual_numbers = []
                for col in main_cols:
                    if col in actual_row.index:
                        actual_numbers.append(int(actual_row[col]))
                
                if len(actual_numbers) == 5:
                    entry['actual'] = actual_numbers
                    
                    # å„äºˆæ¸¬ã‚»ãƒƒãƒˆã¨ã®ä¸€è‡´æ•°ã‚’è¨ˆç®—
                    matches = []
                    for pred_set in entry['predictions']:
                        match_count = len(set(pred_set) & set(actual_numbers))
                        matches.append(match_count)
                    
                    entry['matches'] = matches
                    entry['verified'] = True
                    verified_count += 1
                    
                    print(f"âœ… è‡ªå‹•ç…§åˆå®Œäº†: ç¬¬{entry['round']}å›")
                    print(f"   å½“é¸ç•ªå·: {actual_numbers}")
                    print(f"   ä¸€è‡´æ•°: {matches}")
                    print(f"   æœ€é«˜ä¸€è‡´: {max(matches)}å€‹")
        
        if verified_count > 0:
            self._update_accuracy_stats()
            print(f"ğŸ“Š {verified_count}ä»¶ã®äºˆæ¸¬ã‚’è‡ªå‹•ç…§åˆã—ã¾ã—ãŸ")
        
        return verified_count
    
    def _update_accuracy_stats(self):
        """ç²¾åº¦çµ±è¨ˆã‚’æ›´æ–°"""
        all_matches = []
        verified_predictions = [entry for entry in self.predictions if entry['verified']]
        
        for entry in verified_predictions:
            all_matches.extend(entry['matches'])
        
        if all_matches:
            self.accuracy_stats = {
                'total_predictions': len(all_matches),
                'verified_rounds': len(verified_predictions),
                'avg_matches': np.mean(all_matches),
                'max_matches': max(all_matches),
                'match_distribution': dict(Counter(all_matches)),
                'accuracy_by_match': {
                    f'{i}_matches': all_matches.count(i) for i in range(6)
                }
            }
    
    def get_accuracy_report(self):
        """ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not self.accuracy_stats:
            return "ğŸ“Š ã¾ã ç…§åˆæ¸ˆã¿ã®äºˆæ¸¬ãŒã‚ã‚Šã¾ã›ã‚“"
        
        stats = self.accuracy_stats
        report = []
        report.append("ğŸ“Š === ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆ ===")
        report.append(f"ç…§åˆæ¸ˆã¿å›æ•°: {stats['verified_rounds']}å›")
        report.append(f"ç·äºˆæ¸¬ã‚»ãƒƒãƒˆæ•°: {stats['total_predictions']}ã‚»ãƒƒãƒˆ")
        report.append(f"å¹³å‡ä¸€è‡´æ•°: {stats['avg_matches']:.2f}å€‹")
        report.append(f"æœ€é«˜ä¸€è‡´æ•°: {stats['max_matches']}å€‹")
        report.append("")
        report.append("ä¸€è‡´æ•°åˆ†å¸ƒ:")
        for i in range(6):
            count = stats['accuracy_by_match'].get(f'{i}_matches', 0)
            percentage = (count / stats['total_predictions']) * 100 if stats['total_predictions'] > 0 else 0
            report.append(f"  {i}å€‹ä¸€è‡´: {count}ã‚»ãƒƒãƒˆ ({percentage:.1f}%)")
        
        return "\n".join(report)
    
    def save_to_json(self):
        """äºˆæ¸¬å±¥æ­´ã‚’JSONã«ä¿å­˜ï¼ˆãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ï¼‰"""
        try:
            # JSONå½¢å¼ã§ä¿å­˜ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ãƒ¡ãƒ¢ãƒªï¼‰
            self.saved_data = {
                'predictions': self.predictions,
                'accuracy_stats': self.accuracy_stats,
                'last_updated': datetime.now().isoformat()
            }
            print(f"ğŸ’¾ äºˆæ¸¬å±¥æ­´ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜å®Œäº†")
            return True
        except Exception as e:
            print(f"âŒ JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_from_json(self):
        """JSONã‹ã‚‰äºˆæ¸¬å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ï¼‰"""
        try:
            if hasattr(self, 'saved_data') and self.saved_data:
                self.predictions = self.saved_data['predictions']
                self.accuracy_stats = self.saved_data['accuracy_stats']
                print(f"ğŸ“‚ äºˆæ¸¬å±¥æ­´ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰èª­ã¿è¾¼ã¿: {len(self.predictions)}å›åˆ†")
                return True
            else:
                print("ğŸ“‚ ä¿å­˜æ¸ˆã¿å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
        except Exception as e:
            print(f"âŒ JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

# ========================= ãƒ‘ãƒ¼ãƒˆ1Aï¼ˆå‰åŠï¼‰ã“ã“ã¾ã§ =========================

# ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  ãƒ‘ãƒ¼ãƒˆ1B: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¾ŒåŠï¼‰
# ========================= ãƒ‘ãƒ¼ãƒˆ1Bé–‹å§‹ =========================
# ãƒ‘ãƒ¼ãƒˆ1Aã®ç¶šã - åŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹

# ãƒŸãƒ‹ãƒ­ãƒˆç”¨åŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
class MiniLotoBasicPredictor:
    def __init__(self):
        print("ğŸ”§ MiniLotoBasicPredictoråˆæœŸåŒ–")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨
        self.data_fetcher = MiniLotoDataFetcher()
        
        # åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‘ãƒ¼ãƒˆ1ã§ã¯2ãƒ¢ãƒ‡ãƒ«ï¼‰
        self.models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100, max_depth=10, random_state=42, n_jobs=-1
            ),
            'gradient_boost': GradientBoostingClassifier(
                n_estimators=80, max_depth=6, random_state=42
            )
        }
        
        self.scalers = {}
        self.model_weights = {
            'random_forest': 0.6,
            'gradient_boost': 0.4
        }
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†æ
        self.freq_counter = Counter()
        self.pair_freq = Counter()
        self.pattern_stats = {}
        
        # å­¦ç¿’çŠ¶æ…‹
        self.trained_models = {}
        self.model_scores = {}
        self.data_count = 0
        
        # äºˆæ¸¬å±¥æ­´
        self.history = MiniLotoPredictionHistory()
        
        print("âœ… åŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def create_basic_features(self, data):
        """åŸºæœ¬çš„ãª14æ¬¡å…ƒç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
        try:
            print("ğŸ”§ 14æ¬¡å…ƒç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹")
            
            features = []
            targets = []
            main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
            
            for i in range(len(data)):
                try:
                    current = []
                    for col in main_cols:
                        if col in data.columns:
                            current.append(int(data.iloc[i][col]))
                    
                    if len(current) != 5:
                        continue
                    
                    # ãƒŸãƒ‹ãƒ­ãƒˆã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ1-31ï¼‰
                    if not all(1 <= x <= 31 for x in current):
                        continue
                    if len(set(current)) != 5:  # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        continue
                    
                    # åŸºæœ¬çµ±è¨ˆï¼ˆé »å‡ºã‚«ã‚¦ãƒ³ãƒˆï¼‰
                    for num in current:
                        self.freq_counter[num] += 1
                    
                    # ãƒšã‚¢åˆ†æ
                    for j in range(len(current)):
                        for k in range(j+1, len(current)):
                            pair = tuple(sorted([current[j], current[k]]))
                            self.pair_freq[pair] += 1
                    
                    # 14æ¬¡å…ƒç‰¹å¾´é‡ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆæœ€é©åŒ–ç‰ˆï¼‰
                    sorted_nums = sorted(current)
                    gaps = [sorted_nums[j+1] - sorted_nums[j] for j in range(4)]  # 4å€‹ã®ã‚®ãƒ£ãƒƒãƒ—
                    
                    feat = [
                        float(np.mean(current)),           # 1. å¹³å‡å€¤
                        float(np.std(current)),            # 2. æ¨™æº–åå·®
                        float(np.sum(current)),            # 3. åˆè¨ˆå€¤
                        float(sum(1 for x in current if x % 2 == 1)),  # 4. å¥‡æ•°å€‹æ•°
                        float(max(current)),               # 5. æœ€å¤§å€¤
                        float(min(current)),               # 6. æœ€å°å€¤
                        float(np.median(current)),         # 7. ä¸­å¤®å€¤
                        float(max(current) - min(current)), # 8. ç¯„å›²
                        float(len([j for j in range(len(sorted_nums)-1) 
                                 if sorted_nums[j+1] - sorted_nums[j] == 1])), # 9. é€£ç¶šæ•°
                        float(current[0]),                 # 10. ç¬¬1æ•°å­—
                        float(current[2]),                 # 11. ç¬¬3æ•°å­—ï¼ˆä¸­å¤®ï¼‰
                        float(current[4]),                 # 12. ç¬¬5æ•°å­—ï¼ˆæœ€å¾Œï¼‰
                        float(np.mean(gaps)),              # 13. å¹³å‡ã‚®ãƒ£ãƒƒãƒ—
                        float(len([x for x in current if x <= 15])), # 14. å°æ•°å­—æ•°ï¼ˆâ‰¤15ï¼‰
                    ]
                    
                    # æ¬¡å›äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                    if i < len(data) - 1:
                        next_nums = []
                        for col in main_cols:
                            if col in data.columns:
                                next_nums.append(int(data.iloc[i+1][col]))
                        
                        if len(next_nums) == 5:
                            for target_num in next_nums:
                                features.append(feat.copy())
                                targets.append(target_num)
                        
                except Exception as e:
                    continue
                
                if (i + 1) % 100 == 0:
                    print(f"  ç‰¹å¾´é‡é€²æ—: {i+1}/{len(data)}ä»¶")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ
            if len(features) > 0:
                sum_patterns = []
                for i in range(len(data)):
                    try:
                        current = []
                        for col in main_cols:
                            if col in data.columns:
                                current.append(int(data.iloc[i][col]))
                        if len(current) == 5 and all(1 <= x <= 31 for x in current) and len(set(current)) == 5:
                            sum_patterns.append(sum(current))
                    except:
                        continue
                
                if sum_patterns:
                    self.pattern_stats = {
                        'avg_sum': float(np.mean(sum_patterns)),
                        'std_sum': float(np.std(sum_patterns)),
                        'most_frequent_pairs': self.pair_freq.most_common(10)
                    }
            
            print(f"âœ… 14æ¬¡å…ƒç‰¹å¾´é‡å®Œæˆ: {len(features)}å€‹")
            return np.array(features), np.array(targets)
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    
    def train_basic_models(self, data):
        """åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        try:
            print("ğŸ“Š === åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ ===")
            
            # 14æ¬¡å…ƒç‰¹å¾´é‡ä½œæˆ
            X, y = self.create_basic_features(data)
            if X is None or len(X) < 100:
                print(f"âŒ ç‰¹å¾´é‡ä¸è¶³: {len(X) if X is not None else 0}ä»¶")
                return False
            
            self.data_count = len(data)
            
            # å„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            print("ğŸ¤– åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            
            for name, model in self.models.items():
                try:
                    print(f"  {name} å­¦ç¿’ä¸­...")
                    
                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    self.scalers[name] = scaler
                    
                    # å­¦ç¿’
                    model.fit(X_scaled, y)
                    
                    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
                    cv_score = np.mean(cross_val_score(model, X_scaled, y, cv=3))
                    
                    self.trained_models[name] = model
                    self.model_scores[name] = cv_score
                    
                    print(f"    âœ… {name}: CVç²¾åº¦ {cv_score*100:.2f}%")
                    
                except Exception as e:
                    print(f"    âŒ {name}: ã‚¨ãƒ©ãƒ¼ {e}")
                    continue
            
            print(f"âœ… åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†: {len(self.trained_models)}ãƒ¢ãƒ‡ãƒ«")
            return True
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def basic_predict(self, count=20):
        """åŸºæœ¬ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œ"""
        try:
            if not self.trained_models:
                print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãªã—")
                return []
            
            # åŸºæº–ç‰¹å¾´é‡ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆç”¨ï¼‰
            if hasattr(self, 'pattern_stats') and self.pattern_stats:
                avg_sum = self.pattern_stats.get('avg_sum', 80)  # ãƒŸãƒ‹ãƒ­ãƒˆã®å¹³å‡åˆè¨ˆ
                base_features = [
                    avg_sum / 5,        # 1. å¹³å‡å€¤ï¼ˆ16ç¨‹åº¦ï¼‰
                    6.0,                # 2. æ¨™æº–åå·®
                    avg_sum,            # 3. åˆè¨ˆå€¤ï¼ˆ80ç¨‹åº¦ï¼‰
                    2.5,                # 4. å¥‡æ•°å€‹æ•°
                    28.0,               # 5. æœ€å¤§å€¤
                    5.0,                # 6. æœ€å°å€¤
                    16.0,               # 7. ä¸­å¤®å€¤
                    23.0,               # 8. ç¯„å›²
                    1.0,                # 9. é€£ç¶šæ•°
                    8.0,                # 10. ç¬¬1æ•°å­—
                    16.0,               # 11. ç¬¬3æ•°å­—
                    24.0,               # 12. ç¬¬5æ•°å­—
                    5.5,                # 13. å¹³å‡ã‚®ãƒ£ãƒƒãƒ—
                    2.5                 # 14. å°æ•°å­—æ•°
                ]
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                base_features = [16.0, 6.0, 80.0, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5]
            
            predictions = []
            
            for i in range(count):
                # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’åé›†
                ensemble_votes = Counter()
                
                for name, model in self.trained_models.items():
                    try:
                        scaler = self.scalers[name]
                        X_scaled = scaler.transform([base_features])
                        
                        # è¤‡æ•°å›äºˆæ¸¬
                        for _ in range(6):  # ãƒŸãƒ‹ãƒ­ãƒˆç”¨ã«èª¿æ•´
                            if hasattr(model, 'predict_proba'):
                                proba = model.predict_proba(X_scaled)[0]
                                classes = model.classes_
                                if len(classes) > 0:
                                    selected = np.random.choice(classes, p=proba/proba.sum())
                                    if 1 <= selected <= 31:
                                        weight = self.model_weights.get(name, 0.5)
                                        ensemble_votes[int(selected)] += weight
                            else:
                                pred = model.predict(X_scaled)[0]
                                if 1 <= pred <= 31:
                                    weight = self.model_weights.get(name, 0.5)
                                    ensemble_votes[int(pred)] += weight
                                    
                    except Exception as e:
                        continue
                
                # é »å‡ºæ•°å­—ã¨çµ„ã¿åˆã‚ã›
                frequent_nums = [num for num, _ in self.freq_counter.most_common(12)]
                for num in frequent_nums[:8]:
                    ensemble_votes[num] += 0.1
                
                # ä¸Šä½5å€‹ã‚’é¸æŠ
                top_numbers = [num for num, _ in ensemble_votes.most_common(5)]
                
                # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ è£œå®Œ
                while len(top_numbers) < 5:
                    candidate = np.random.randint(1, 32)
                    if candidate not in top_numbers:
                        top_numbers.append(candidate)
                
                final_pred = sorted([int(x) for x in top_numbers[:5]])
                predictions.append(final_pred)
            
            return predictions
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def auto_setup_and_predict(self):
        """è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»äºˆæ¸¬å®Ÿè¡Œ"""
        try:
            print("\n" + "="*80)
            print("ğŸŒ ãƒŸãƒ‹ãƒ­ãƒˆåŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œé–‹å§‹")
            print("="*80)
            
            # 1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
            if not self.data_fetcher.fetch_latest_data():
                print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                return [], {}
            
            training_data = self.data_fetcher.get_data_for_training()
            next_info = self.data_fetcher.get_next_round_info()
            
            print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(training_data)}ä»¶")
            print(f"ğŸ¯ äºˆæ¸¬å¯¾è±¡: {next_info['prediction_target']}")
            
            # 2. åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            success = self.train_basic_models(training_data)
            if not success:
                print("âŒ å­¦ç¿’å¤±æ•—")
                return [], {}
            
            # 3. äºˆæ¸¬å®Ÿè¡Œ
            predictions = self.basic_predict(20)
            if not predictions:
                print("âŒ äºˆæ¸¬å¤±æ•—")
                return [], {}
            
            # 4. äºˆæ¸¬è¨˜éŒ²
            self.history.add_prediction_with_round(
                predictions, 
                next_info['next_round'], 
                next_info['current_date']
            )
            
            print("\n" + "="*80)
            print(f"ğŸ¯ {next_info['prediction_target']}ã®äºˆæ¸¬çµæœï¼ˆ20ã‚»ãƒƒãƒˆï¼‰")
            print("="*80)
            print(f"ğŸ“… äºˆæ¸¬ä½œæˆæ—¥æ™‚: {next_info['current_date']}")
            print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: ç¬¬1å›ã€œç¬¬{next_info['latest_round']}å›ï¼ˆ{self.data_count}ä»¶ï¼‰")
            print("-"*80)
            
            for i, pred in enumerate(predictions, 1):
                clean_pred = [int(x) for x in pred]
                print(f"ç¬¬{next_info['next_round']}å›äºˆæ¸¬ {i:2d}: {clean_pred}")
            
            # 5. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è¡¨ç¤º
            print("\n" + "="*80)
            print("ğŸ¤– åŸºæœ¬ãƒ¢ãƒ‡ãƒ«æ€§èƒ½")
            print("="*80)
            
            for name, score in self.model_scores.items():
                weight = self.model_weights.get(name, 0)
                print(f"{name:15s}: CVç²¾åº¦ {score*100:5.2f}% | é‡ã¿ {weight:.2f}")
            
            # 6. çµ±è¨ˆæƒ…å ±
            print("\n" + "="*80)
            print("ğŸ“Š åˆ†æçµæœ")
            print("="*80)
            print(f"ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒï¼ˆãƒŸãƒ‹ãƒ­ãƒˆæœ€é©åŒ–ç‰ˆï¼‰")
            
            if hasattr(self, 'pattern_stats') and self.pattern_stats:
                print(f"å¹³å‡åˆè¨ˆå€¤: {self.pattern_stats.get('avg_sum', 0):.1f}")
            
            print(f"\nğŸ”¥ é »å‡ºæ•°å­—TOP10:")
            for i, (num, count) in enumerate(self.freq_counter.most_common(10)):
                if i % 5 == 0:
                    print("")
                print(f"{int(num)}ç•ª({int(count)}å›)", end="  ")
            
            print(f"\n\nâœ… åŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†")
            return predictions, next_info
            
        except Exception as e:
            print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            print(f"è©³ç´°: {traceback.format_exc()}")
            return [], {}

    def save_models(self):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜"""
        try:
            if not self.trained_models:
                return False
                
            # ãƒ¢ãƒ‡ãƒ«ã¨é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã¦ä¿å­˜
            self.saved_model_data = {
                'trained_models': self.trained_models,
                'scalers': self.scalers,
                'model_weights': self.model_weights,
                'model_scores': self.model_scores,
                'freq_counter': dict(self.freq_counter),
                'pair_freq': dict(self.pair_freq),
                'pattern_stats': self.pattern_stats,
                'data_count': self.data_count,
                'save_timestamp': datetime.now().isoformat()
            }
            
            print(f"ğŸ’¾ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜å®Œäº†")
            
            # äºˆæ¸¬å±¥æ­´ã‚‚ä¿å­˜
            self.history.save_to_json()
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_models(self):
        """ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰èª­ã¿è¾¼ã¿"""
        try:
            if not hasattr(self, 'saved_model_data') or not self.saved_model_data:
                print("ğŸ“‚ ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # ãƒ¢ãƒ‡ãƒ«ã¨é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
            data = self.saved_model_data
            self.trained_models = data['trained_models']
            self.scalers = data['scalers']
            self.model_weights = data['model_weights']
            self.model_scores = data['model_scores']
            self.freq_counter = Counter(data['freq_counter'])
            self.pair_freq = Counter(data['pair_freq'])
            self.pattern_stats = data['pattern_stats']
            self.data_count = data['data_count']
            
            print(f"ğŸ“‚ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {self.data_count}ä»¶")
            print(f"  ãƒ¢ãƒ‡ãƒ«æ•°: {len(self.trained_models)}")
            
            # äºˆæ¸¬å±¥æ­´ã‚‚èª­ã¿è¾¼ã¿
            self.history.load_from_json()
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

# ========================= ãƒ‘ãƒ¼ãƒˆ1Bï¼ˆå¾ŒåŠï¼‰ã“ã“ã¾ã§ =========================

# ========================= ãƒ‘ãƒ¼ãƒˆ1Cé–‹å§‹ =========================

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚·ã‚¹ãƒ†ãƒ 
basic_system = MiniLotoBasicPredictor()

# ãƒ‘ãƒ¼ãƒˆ1å®Ÿè¡Œé–¢æ•°
def run_miniloto_basic_prediction():
    try:
        print("\nğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆåŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ")
        
        # åŸºæœ¬äºˆæ¸¬å®Ÿè¡Œ
        predictions, next_info = basic_system.auto_setup_and_predict()
        
        if predictions:
            print("\nğŸ‰ ãƒ‘ãƒ¼ãƒˆ1: åŸºæœ¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œäº†!")
            print("ğŸ“ äºˆæ¸¬çµæœãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
            return "SUCCESS"
        else:
            print("âŒ åŸºæœ¬äºˆæ¸¬å¤±æ•—")
            return "FAILED"
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

# ãƒ‘ãƒ¼ãƒˆ1ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
print("\n" + "="*80)
print("ğŸ§ª ãƒ‘ãƒ¼ãƒˆ1: åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
print("="*80)

test_result = run_miniloto_basic_prediction()
print(f"\nğŸ ãƒ‘ãƒ¼ãƒˆ1ãƒ†ã‚¹ãƒˆçµæœ: {test_result}")

if test_result == "SUCCESS":
    print("âœ… ãƒ‘ãƒ¼ãƒˆ1å®Œäº† - ãƒ‘ãƒ¼ãƒˆ2ã«é€²ã‚€æº–å‚™å®Œäº†")
    
    # åŸºæœ¬çµ±è¨ˆè¡¨ç¤º
    if basic_system.trained_models:
        print(f"\nğŸ“Š ãƒ‘ãƒ¼ãƒˆ1å®Œäº†çµ±è¨ˆ:")
        print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {basic_system.data_count}ä»¶")
        print(f"  ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒ")
        print(f"  å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ•°: {len(basic_system.trained_models)}å€‹")
        print(f"  é »å‡ºæ•°å­—æ•°: {len(basic_system.freq_counter)}å€‹")
else:
    print("âŒ ãƒ‘ãƒ¼ãƒˆ1ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")

print("\n" + "="*80)
print("ğŸ¯ ãƒ‘ãƒ¼ãƒˆ1: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ å®Œäº†")
print("æ¬¡å›: ãƒ‘ãƒ¼ãƒˆ2 - é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ™‚ç³»åˆ—æ¤œè¨¼ï¼‰")
print("="*80)

# ========================= ãƒ‘ãƒ¼ãƒˆ1Cã“ã“ã¾ã§ =========================

# ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  ãƒ‘ãƒ¼ãƒˆ2: é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ™‚ç³»åˆ—æ¤œè¨¼ï¼‰
# ========================= ãƒ‘ãƒ¼ãƒˆ2Aé–‹å§‹ =========================

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from collections import Counter, defaultdict
import json
import traceback
from datetime import datetime

print("ğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‘ãƒ¼ãƒˆ2: é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ")
print("ğŸ“Š æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ + Neural Network + 14æ¬¡å…ƒç‰¹å¾´é‡")
print("ğŸ”§ å›ºå®šçª“: 50å›åˆ†ï¼ˆ30, 50, 70ã§ã®æ¤œè¨¼ï¼‰")

# æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ã‚¯ãƒ©ã‚¹ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆç‰ˆãƒ»50å›åˆ†å¯¾å¿œï¼‰
class MiniLotoTimeSeriesValidator:
    """ãƒŸãƒ‹ãƒ­ãƒˆå°‚ç”¨æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ã‚¯ãƒ©ã‚¹ï¼ˆå›ºå®šçª“50å›åˆ†å¯¾å¿œï¼‰"""
    def __init__(self, min_train_size=30):
        self.min_train_size = min_train_size
        self.fixed_window_results = {}  # çª“ã‚µã‚¤ã‚ºåˆ¥ã®çµæœ
        self.expanding_window_results = []
        self.validation_history = []
        self.feature_importance_history = {}
        
        # ãƒŸãƒ‹ãƒ­ãƒˆç”¨ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
        self.validation_models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100, max_depth=10, random_state=42, n_jobs=-1
            ),
            'gradient_boost': GradientBoostingClassifier(
                n_estimators=80, max_depth=6, random_state=42
            ),
            'neural_network': MLPClassifier(
                hidden_layer_sizes=(64, 32, 16), max_iter=300, random_state=42
            )
        }
        
        self.model_weights = {
            'random_forest': 0.4,
            'gradient_boost': 0.35,
            'neural_network': 0.25
        }
        
    def evaluate_prediction_sets(self, predicted_sets, actual):
        """20ã‚»ãƒƒãƒˆäºˆæ¸¬ã¨å®Ÿéš›ã®ä¸€è‡´ã‚’è©•ä¾¡"""
        results = []
        
        actual_set = set(actual)
        
        for i, predicted in enumerate(predicted_sets):
            predicted_set = set(predicted)
            matches = len(predicted_set & actual_set)
            
            result = {
                'set_idx': i,
                'matches': matches,
                'accuracy': matches / 5.0,  # ãƒŸãƒ‹ãƒ­ãƒˆã¯5å€‹
                'predicted': predicted,
                'actual': actual,
                'matched_numbers': sorted(list(predicted_set & actual_set)),
                'missed_numbers': sorted(list(actual_set - predicted_set)),
                'extra_numbers': sorted(list(predicted_set - actual_set))
            }
            results.append(result)
        
        # å…¨ä½“çµ±è¨ˆ
        all_matches = [r['matches'] for r in results]
        summary = {
            'avg_matches': np.mean(all_matches),
            'max_matches': max(all_matches),
            'min_matches': min(all_matches),
            'std_matches': np.std(all_matches),
            'sets_3_plus': sum(1 for m in all_matches if m >= 3),
            'sets_4_plus': sum(1 for m in all_matches if m >= 4),
            'sets_5_plus': sum(1 for m in all_matches if m >= 5),
            'match_distribution': dict(Counter(all_matches)),
            'individual_results': results
        }
        
        return summary
    
    def create_validation_features(self, data):
        """ãƒŸãƒ‹ãƒ­ãƒˆç”¨14æ¬¡å…ƒãƒ•ãƒ«ç‰¹å¾´é‡ã‚’ä½œæˆ"""
        try:
            features = []
            targets = []
            freq_counter = Counter()
            pair_freq = Counter()
            main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
            
            for i in range(len(data)):
                try:
                    current = []
                    for col in main_cols:
                        if col in data.columns:
                            current.append(int(data.iloc[i][col]))
                    
                    if len(current) != 5:
                        continue
                    
                    if not all(1 <= x <= 31 for x in current):
                        continue
                    if len(set(current)) != 5:
                        continue
                    
                    # åŸºæœ¬çµ±è¨ˆ
                    for num in current:
                        freq_counter[num] += 1
                    
                    # ãƒšã‚¢åˆ†æ
                    for j in range(len(current)):
                        for k in range(j+1, len(current)):
                            pair = tuple(sorted([current[j], current[k]]))
                            pair_freq[pair] += 1
                    
                    # ãƒŸãƒ‹ãƒ­ãƒˆç”¨14æ¬¡å…ƒç‰¹å¾´é‡
                    sorted_nums = sorted(current)
                    gaps = [sorted_nums[j+1] - sorted_nums[j] for j in range(4)]
                    
                    feat = [
                        float(np.mean(current)),           # 1. å¹³å‡å€¤
                        float(np.std(current)),            # 2. æ¨™æº–åå·®
                        float(np.sum(current)),            # 3. åˆè¨ˆå€¤
                        float(sum(1 for x in current if x % 2 == 1)),  # 4. å¥‡æ•°å€‹æ•°
                        float(max(current)),               # 5. æœ€å¤§å€¤
                        float(min(current)),               # 6. æœ€å°å€¤
                        float(np.median(current)),         # 7. ä¸­å¤®å€¤
                        float(max(current) - min(current)), # 8. ç¯„å›²
                        float(len([j for j in range(len(sorted_nums)-1) 
                                 if sorted_nums[j+1] - sorted_nums[j] == 1])), # 9. é€£ç¶šæ•°
                        float(current[0]),                 # 10. ç¬¬1æ•°å­—
                        float(current[2]),                 # 11. ç¬¬3æ•°å­—ï¼ˆä¸­å¤®ï¼‰
                        float(current[4]),                 # 12. ç¬¬5æ•°å­—ï¼ˆæœ€å¾Œï¼‰
                        float(np.mean(gaps)),              # 13. å¹³å‡ã‚®ãƒ£ãƒƒãƒ—
                        float(len([x for x in current if x <= 15])), # 14. å°æ•°å­—æ•°
                    ]
                    
                    # æ¬¡å›äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                    if i < len(data) - 1:
                        next_nums = []
                        for col in main_cols:
                            if col in data.columns:
                                next_nums.append(int(data.iloc[i+1][col]))
                        
                        if len(next_nums) == 5:
                            for target_num in next_nums:
                                features.append(feat.copy())
                                targets.append(target_num)
                        
                except Exception as e:
                    continue
            
            print(f"âœ… 14æ¬¡å…ƒç‰¹å¾´é‡å®Œæˆ: {len(features)}å€‹")
            return np.array(features), np.array(targets), freq_counter
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, Counter()

    def train_validation_models(self, train_data):
        """ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’å­¦ç¿’"""
        try:
            # 14æ¬¡å…ƒç‰¹å¾´é‡ä½œæˆ
            X, y, freq_counter = self.create_validation_features(train_data)
            if X is None or len(X) < 50:  # æœ€ä½é™å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ•°
                return None
            
            trained_models = {}
            scalers = {}
            
            for name, model in self.validation_models.items():
                try:
                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    
                    # å­¦ç¿’
                    model_copy = type(model)(**model.get_params())
                    model_copy.fit(X_scaled, y)
                    
                    trained_models[name] = model_copy
                    scalers[name] = scaler
                    
                except Exception as e:
                    continue
            
            return {
                'models': trained_models, 
                'scalers': scalers,
                'freq_counter': freq_counter
            }
            
        except Exception as e:
            return None
    
    def generate_validation_predictions(self, model_data, freq_counter, count=20):
        """ãƒ•ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã§20ã‚»ãƒƒãƒˆäºˆæ¸¬ã‚’ç”Ÿæˆ"""
        try:
            if not model_data or not model_data['models']:
                return []
            
            trained_models = model_data['models']
            scalers = model_data['scalers']
            
            # ãƒŸãƒ‹ãƒ­ãƒˆç”¨åŸºæº–ç‰¹å¾´é‡ï¼ˆ14æ¬¡å…ƒï¼‰
            base_features = [16.0, 6.0, 80.0, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5]
            
            predictions = []
            
            for i in range(count):
                # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’åé›†
                ensemble_votes = Counter()
                
                for name, model in trained_models.items():
                    try:
                        scaler = scalers[name]
                        X_scaled = scaler.transform([base_features])
                        
                        # è¤‡æ•°å›äºˆæ¸¬
                        for _ in range(6):
                            if hasattr(model, 'predict_proba'):
                                proba = model.predict_proba(X_scaled)[0]
                                classes = model.classes_
                                if len(classes) > 0:
                                    selected = np.random.choice(classes, p=proba/proba.sum())
                                    if 1 <= selected <= 31:
                                        weight = self.model_weights.get(name, 0.33)
                                        ensemble_votes[int(selected)] += weight
                            else:
                                pred = model.predict(X_scaled)[0]
                                if 1 <= pred <= 31:
                                    weight = self.model_weights.get(name, 0.33)
                                    ensemble_votes[int(pred)] += weight
                                    
                    except Exception as e:
                        continue
                
                # é »å‡ºæ•°å­—ã¨çµ„ã¿åˆã‚ã›
                frequent_nums = [num for num, _ in freq_counter.most_common(12)]
                for num in frequent_nums[:8]:
                    ensemble_votes[num] += 0.1
                
                # ä¸Šä½5å€‹ã‚’é¸æŠ
                top_numbers = [num for num, _ in ensemble_votes.most_common(5)]
                
                # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ è£œå®Œ
                while len(top_numbers) < 5:
                    candidate = np.random.randint(1, 32)
                    if candidate not in top_numbers:
                        top_numbers.append(candidate)
                
                final_pred = sorted([int(x) for x in top_numbers[:5]])
                predictions.append(final_pred)
            
            return predictions
            
        except Exception as e:
            print(f"âŒ æ¤œè¨¼ç”¨äºˆæ¸¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

# ========================= ãƒ‘ãƒ¼ãƒˆ2Aã“ã“ã¾ã§ =========================

# ========================= ãƒ‘ãƒ¼ãƒˆ2Bé–‹å§‹ =========================

    def fixed_window_validation(self, data, window_sizes=[30, 50, 70]):
        """è¤‡æ•°çª“ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹å›ºå®šçª“æ¤œè¨¼ï¼ˆ50å›åˆ†ãƒ¡ã‚¤ãƒ³ï¼‰"""
        print(f"\nğŸ“Š === å›ºå®šçª“æ¤œè¨¼é–‹å§‹ï¼ˆçª“ã‚µã‚¤ã‚º: {window_sizes}å›ï¼‰ ===")
        print("âš¡ ãƒ•ãƒ«ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰: 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ»14æ¬¡å…ƒç‰¹å¾´é‡")
        
        total_rounds = len(data)
        results_by_window = {}
        main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
        round_col = 'é–‹å‚¬å›'
        
        for window_size in window_sizes:
            print(f"\nğŸ”„ {window_size}å›åˆ†çª“ã§ã®æ¤œè¨¼é–‹å§‹")
            results = []
            
            # æ¤œè¨¼ç¯„å›²ã®è¨ˆç®—
            max_tests = min(200, total_rounds - window_size - 1)  # åŠ¹ç‡åŒ–ã®ãŸã‚200å›ã¾ã§
            step = max(1, (total_rounds - window_size - 1) // max_tests)
            
            print(f"æ¤œè¨¼ç¯„å›²: ç¬¬{window_size + 1}å› ã€œ ç¬¬{total_rounds}å›ï¼ˆ{max_tests}å›ã®æ¤œè¨¼ã€ã‚¹ãƒ†ãƒƒãƒ—{step}ï¼‰")
            
            test_count = 0
            for i in range(0, total_rounds - window_size - 1, step):
                if test_count >= max_tests:
                    break
                
                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿: iã€œi+window_size-1
                train_start = i
                train_end = i + window_size
                test_idx = train_end
                
                if test_idx >= total_rounds:
                    break
                
                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿å–å¾—
                train_data = data.iloc[train_start:train_end]
                test_round = data.iloc[test_idx][round_col]
                actual_numbers = []
                for col in main_cols:
                    if col in data.columns:
                        actual_numbers.append(int(data.iloc[test_idx][col]))
                
                if len(actual_numbers) == 5:
                    # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                    model_data = self.train_validation_models(train_data)
                    
                    if model_data and model_data['models']:
                        # 20ã‚»ãƒƒãƒˆäºˆæ¸¬ç”Ÿæˆ
                        predicted_sets = self.generate_validation_predictions(
                            model_data, 
                            model_data['freq_counter'], 
                            20
                        )
                        
                        if predicted_sets:
                            # è©³ç´°è©•ä¾¡
                            eval_result = self.evaluate_prediction_sets(predicted_sets, actual_numbers)
                            eval_result['train_range'] = f"ç¬¬{train_start + 1}å›ã€œç¬¬{train_end}å›"
                            eval_result['test_round'] = test_round
                            eval_result['window_size'] = window_size
                            
                            results.append(eval_result)
                
                test_count += 1
                
                # é€²æ—è¡¨ç¤º
                if test_count % 50 == 0:
                    if results:
                        avg_matches = np.mean([r['avg_matches'] for r in results])
                        sets_3_plus = np.mean([r['sets_3_plus'] for r in results])
                        print(f"  é€²æ—: {test_count}/{max_tests}ä»¶ | å¹³å‡ä¸€è‡´: {avg_matches:.2f} | 3å€‹ä»¥ä¸Šä¸€è‡´: {sets_3_plus:.1f}ã‚»ãƒƒãƒˆ")
            
            results_by_window[window_size] = results
            
            # çª“ã‚µã‚¤ã‚ºåˆ¥ã‚µãƒãƒªãƒ¼
            if results:
                avg_matches = np.mean([r['avg_matches'] for r in results])
                max_matches = max([r['max_matches'] for r in results])
                sets_3_plus = np.mean([r['sets_3_plus'] for r in results])
                sets_4_plus = np.mean([r['sets_4_plus'] for r in results])
                print(f"\nğŸ“Š {window_size}å›åˆ†çª“ æœ€çµ‚çµæœ:")
                print(f"    æ¤œè¨¼å›æ•°: {len(results)}å› | å¹³å‡ä¸€è‡´: {avg_matches:.3f}å€‹ | æœ€é«˜ä¸€è‡´: {max_matches}å€‹")
                print(f"    3å€‹ä»¥ä¸Šä¸€è‡´: {sets_3_plus:.2f}ã‚»ãƒƒãƒˆ | 4å€‹ä»¥ä¸Šä¸€è‡´: {sets_4_plus:.2f}ã‚»ãƒƒãƒˆ")
        
        self.fixed_window_results = results_by_window
        return results_by_window
    
    def expanding_window_validation(self, data, initial_size=50):
        """ç´¯ç©çª“ã«ã‚ˆã‚‹æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ï¼ˆ50å›åˆ†åˆæœŸã‚µã‚¤ã‚ºï¼‰"""
        print(f"\nğŸ“Š === ç´¯ç©çª“æ¤œè¨¼é–‹å§‹ï¼ˆåˆæœŸã‚µã‚¤ã‚º: {initial_size}å›ï¼‰ ===")
        print("âš¡ ãƒ•ãƒ«ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰: 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ»14æ¬¡å…ƒç‰¹å¾´é‡")
        
        results = []
        total_rounds = len(data)
        main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
        round_col = 'é–‹å‚¬å›'
        
        # åŠ¹ç‡åŒ–ã®ãŸã‚150å›ã¾ã§
        max_tests = min(150, total_rounds - initial_size)
        step = max(1, (total_rounds - initial_size) // max_tests)
        
        print(f"æ¤œè¨¼ç¯„å›²: ç¬¬{initial_size + 1}å› ã€œ ç¬¬{total_rounds}å›ï¼ˆ{max_tests}å›ã®æ¤œè¨¼ã€ã‚¹ãƒ†ãƒƒãƒ—{step}ï¼‰")
        
        test_count = 0
        for i in range(0, total_rounds - initial_size, step):
            if test_count >= max_tests:
                break
                
            test_idx = initial_size + i
            
            if test_idx >= total_rounds:
                break
            
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 0ã€œtest_idx-1ï¼ˆç´¯ç©ï¼‰
            train_data = data.iloc[0:test_idx]
            test_round = data.iloc[test_idx][round_col]
            actual_numbers = []
            for col in main_cols:
                if col in data.columns:
                    actual_numbers.append(int(data.iloc[test_idx][col]))
            
            if len(actual_numbers) == 5:
                # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                model_data = self.train_validation_models(train_data)
                
                if model_data and model_data['models']:
                    # 20ã‚»ãƒƒãƒˆäºˆæ¸¬ç”Ÿæˆ
                    predicted_sets = self.generate_validation_predictions(
                        model_data, 
                        model_data['freq_counter'], 
                        20
                    )
                    
                    if predicted_sets:
                        # è©³ç´°è©•ä¾¡
                        eval_result = self.evaluate_prediction_sets(predicted_sets, actual_numbers)
                        eval_result['train_range'] = f"ç¬¬1å›ã€œç¬¬{test_idx}å›"
                        eval_result['test_round'] = test_round
                        eval_result['train_size'] = len(train_data)
                        
                        results.append(eval_result)
            
            test_count += 1
            
            # é€²æ—è¡¨ç¤º
            if test_count % 30 == 0:
                if results:
                    avg_matches = np.mean([r['avg_matches'] for r in results])
                    sets_3_plus = np.mean([r['sets_3_plus'] for r in results])
                    print(f"  é€²æ—: {test_count}/{max_tests}ä»¶ | å¹³å‡ä¸€è‡´: {avg_matches:.2f} | 3å€‹ä»¥ä¸Šä¸€è‡´: {sets_3_plus:.1f}ã‚»ãƒƒãƒˆ")
        
        self.expanding_window_results = results
        
        # ç´¯ç©çª“ã‚µãƒãƒªãƒ¼
        if results:
            avg_matches = np.mean([r['avg_matches'] for r in results])
            max_matches = max([r['max_matches'] for r in results])
            sets_3_plus = np.mean([r['sets_3_plus'] for r in results])
            sets_4_plus = np.mean([r['sets_4_plus'] for r in results])
            print(f"\nğŸ“Š ç´¯ç©çª“ æœ€çµ‚çµæœ:")
            print(f"    æ¤œè¨¼å›æ•°: {len(results)}å› | å¹³å‡ä¸€è‡´: {avg_matches:.3f}å€‹ | æœ€é«˜ä¸€è‡´: {max_matches}å€‹")
            print(f"    3å€‹ä»¥ä¸Šä¸€è‡´: {sets_3_plus:.2f}ã‚»ãƒƒãƒˆ | 4å€‹ä»¥ä¸Šä¸€è‡´: {sets_4_plus:.2f}ã‚»ãƒƒãƒˆ")
        
        return results
    
    def compare_validation_methods(self):
        """å›ºå®šçª“ï¼ˆè¤‡æ•°ã‚µã‚¤ã‚ºï¼‰ã¨ç´¯ç©çª“ã®çµæœã‚’æ¯”è¼ƒ"""
        print("\nğŸ“Š === æ¤œè¨¼æ‰‹æ³•ã®è©³ç´°æ¯”è¼ƒåˆ†æ ===")
        
        if not self.fixed_window_results or not self.expanding_window_results:
            print("âŒ æ¤œè¨¼çµæœãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return None
        
        comparison_results = {}
        
        # å›ºå®šçª“ï¼ˆå„ã‚µã‚¤ã‚ºï¼‰ã®çµ±è¨ˆ
        for window_size, results in self.fixed_window_results.items():
            if results:
                avg_matches_list = [r['avg_matches'] for r in results]
                max_matches_list = [r['max_matches'] for r in results]
                sets_3_plus_list = [r['sets_3_plus'] for r in results]
                sets_4_plus_list = [r['sets_4_plus'] for r in results]
                
                stats = {
                    'method': f'å›ºå®šçª“ï¼ˆ{window_size}å›ï¼‰',
                    'window_size': window_size,
                    'avg_matches': np.mean(avg_matches_list),
                    'std_matches': np.std(avg_matches_list),
                    'max_matches': max(max_matches_list),
                    'avg_sets_3_plus': np.mean(sets_3_plus_list),
                    'avg_sets_4_plus': np.mean(sets_4_plus_list),
                    'total_tests': len(results)
                }
                comparison_results[f'fixed_{window_size}'] = stats
        
        # ç´¯ç©çª“ã®çµ±è¨ˆ
        if self.expanding_window_results:
            avg_matches_list = [r['avg_matches'] for r in self.expanding_window_results]
            max_matches_list = [r['max_matches'] for r in self.expanding_window_results]
            sets_3_plus_list = [r['sets_3_plus'] for r in self.expanding_window_results]
            sets_4_plus_list = [r['sets_4_plus'] for r in self.expanding_window_results]
            
            expanding_stats = {
                'method': 'ç´¯ç©çª“',
                'avg_matches': np.mean(avg_matches_list),
                'std_matches': np.std(avg_matches_list),
                'max_matches': max(max_matches_list),
                'avg_sets_3_plus': np.mean(sets_3_plus_list),
                'avg_sets_4_plus': np.mean(sets_4_plus_list),
                'total_tests': len(self.expanding_window_results)
            }
            comparison_results['expanding'] = expanding_stats
        
        # çµæœè¡¨ç¤º
        print("\nã€ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—æ¤œè¨¼ã«ã‚ˆã‚‹è©³ç´°æ¯”è¼ƒçµæœã€‘")
        best_method = None
        best_score = 0
        
        for method_key, stats in comparison_results.items():
            print(f"\nğŸ”¹ {stats['method']}")
            print(f"  å¹³å‡ä¸€è‡´æ•°: {stats['avg_matches']:.3f} Â± {stats['std_matches']:.3f}")
            print(f"  æœ€é«˜ä¸€è‡´æ•°: {stats['max_matches']}å€‹")
            print(f"  å¹³å‡3å€‹ä»¥ä¸Šä¸€è‡´ã‚»ãƒƒãƒˆæ•°: {stats['avg_sets_3_plus']:.2f}ã‚»ãƒƒãƒˆ")
            print(f"  å¹³å‡4å€‹ä»¥ä¸Šä¸€è‡´ã‚»ãƒƒãƒˆæ•°: {stats['avg_sets_4_plus']:.2f}ã‚»ãƒƒãƒˆ")
            print(f"  æ¤œè¨¼å›æ•°: {stats['total_tests']}å›")
            
            # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆå¹³å‡ä¸€è‡´æ•° + 3å€‹ä»¥ä¸Šä¸€è‡´ã‚»ãƒƒãƒˆæ•° + 4å€‹ä»¥ä¸Šä¸€è‡´ã‚»ãƒƒãƒˆæ•°ã®é‡ã¿ä»˜ã‘ï¼‰
            score = stats['avg_matches'] + stats['avg_sets_3_plus'] * 0.3 + stats['avg_sets_4_plus'] * 0.8
            print(f"  ç·åˆã‚¹ã‚³ã‚¢: {score:.3f}")
            
            if score > best_score:
                best_score = score
                best_method = stats['method']
        
        # æœ€é©æ‰‹æ³•ã®æ±ºå®š
        print(f"\nâœ… æœ€é©æ‰‹æ³•: {best_method}")
        print(f"   ç·åˆã‚¹ã‚³ã‚¢: {best_score:.3f}")
        
        # æ¨å¥¨äº‹é …
        if 'fixed_50' in comparison_results and comparison_results['fixed_50']['avg_matches'] > comparison_results.get('fixed_30', {}).get('avg_matches', 0):
            recommendation = 'fixed_50'
            print(f"\nğŸ’¡ æ¨å¥¨: 50å›åˆ†ã®å›ºå®šçª“ãŒæœ€ã‚‚åŠ¹æœçš„")
            print(f"   ç†ç”±: ååˆ†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§å®‰å®šã—ãŸäºˆæ¸¬æ€§èƒ½ã‚’å®Ÿç¾")
        elif 'fixed_70' in comparison_results and comparison_results['fixed_70']['avg_matches'] > comparison_results.get('fixed_50', {}).get('avg_matches', 0):
            recommendation = 'fixed_70'
            print(f"\nğŸ’¡ æ¨å¥¨: 70å›åˆ†ã®å›ºå®šçª“ãŒæœ€é©")
            print(f"   ç†ç”±: ã‚ˆã‚Šå¤šãã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦ã‚’å®Ÿç¾")
        elif 'fixed_30' in comparison_results:
            recommendation = 'fixed_30'
            print(f"\nğŸ’¡ æ¨å¥¨: 30å›åˆ†ã®å›ºå®šçª“ã‚’ä½¿ç”¨")
            print(f"   ç†ç”±: æœ€æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®é©å¿œæ€§ãŒé«˜ã„")
        else:
            recommendation = 'expanding'
            print(f"\nğŸ’¡ æ¨å¥¨: ç´¯ç©çª“ã‚’ä½¿ç”¨")
            print(f"   ç†ç”±: é•·æœŸçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãŒæœ‰åŠ¹")
        
        # å®Ÿç”¨çš„ãªæ¨å¥¨äº‹é …
        print(f"\nğŸ¯ å®Ÿç”¨çš„æ¨å¥¨äº‹é …:")
        if best_method and 'fixed' in best_method:
            window_size = [key for key, val in comparison_results.items() if val['method'] == best_method][0].split('_')[1]
            print(f"   - æœ¬ç•ªäºˆæ¸¬ã§ã¯éå»{window_size}å›åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
            print(f"   - ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’æœ€é©åŒ–çµæœã«åŸºã¥ã„ã¦èª¿æ•´")
        
        return {
            'detailed_results': comparison_results,
            'best_method': best_method,
            'best_score': best_score,
            'recommendation': recommendation,
            'improvement': best_score - min([stats.get('avg_matches', 0) for stats in comparison_results.values()])
        }

# ========================= ãƒ‘ãƒ¼ãƒˆ2Bã“ã“ã¾ã§ =========================

# ========================= ãƒ‘ãƒ¼ãƒˆ2Cé–‹å§‹ =========================

# é«˜åº¦çµ±åˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆç‰ˆãƒ»3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
class MiniLotoAdvancedPredictor:
    def __init__(self):
        print("ğŸ”§ MiniLotoAdvancedPredictoråˆæœŸåŒ–")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨ï¼ˆãƒ‘ãƒ¼ãƒˆ1ã‹ã‚‰ç¶™æ‰¿ï¼‰
        from __main__ import basic_system
        self.data_fetcher = basic_system.data_fetcher
        
        # 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
        self.models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100, max_depth=10, random_state=42, n_jobs=-1
            ),
            'gradient_boost': GradientBoostingClassifier(
                n_estimators=80, max_depth=6, random_state=42
            ),
            'neural_network': MLPClassifier(
                hidden_layer_sizes=(64, 32, 16), max_iter=300, random_state=42
            )
        }
        
        self.scalers = {}
        self.model_weights = {
            'random_forest': 0.4,
            'gradient_boost': 0.35,
            'neural_network': 0.25
        }
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†æ
        self.freq_counter = Counter()
        self.pair_freq = Counter()
        self.pattern_stats = {}
        
        # å­¦ç¿’çŠ¶æ…‹
        self.trained_models = {}
        self.model_scores = {}
        self.data_count = 0
        
        # äºˆæ¸¬å±¥æ­´
        self.history = basic_system.history
        
        # æ™‚ç³»åˆ—æ¤œè¨¼å™¨
        self.validator = None
        
        print("âœ… é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
    def create_advanced_features(self, data):
        """é«˜åº¦ãª14æ¬¡å…ƒç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
        try:
            print("ğŸ”§ é«˜åº¦14æ¬¡å…ƒç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹")
            
            features = []
            targets = []
            main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
            
            for i in range(len(data)):
                try:
                    current = []
                    for col in main_cols:
                        if col in data.columns:
                            current.append(int(data.iloc[i][col]))
                    
                    if len(current) != 5:
                        continue
                    
                    if not all(1 <= x <= 31 for x in current):
                        continue
                    if len(set(current)) != 5:
                        continue
                    
                    # åŸºæœ¬çµ±è¨ˆ
                    for num in current:
                        self.freq_counter[num] += 1
                    
                    # ãƒšã‚¢åˆ†æ
                    for j in range(len(current)):
                        for k in range(j+1, len(current)):
                            pair = tuple(sorted([current[j], current[k]]))
                            self.pair_freq[pair] += 1
                    
                    # é«˜åº¦14æ¬¡å…ƒç‰¹å¾´é‡
                    sorted_nums = sorted(current)
                    gaps = [sorted_nums[j+1] - sorted_nums[j] for j in range(4)]
                    
                    feat = [
                        float(np.mean(current)),           # 1. å¹³å‡å€¤
                        float(np.std(current)),            # 2. æ¨™æº–åå·®
                        float(np.sum(current)),            # 3. åˆè¨ˆå€¤
                        float(sum(1 for x in current if x % 2 == 1)),  # 4. å¥‡æ•°å€‹æ•°
                        float(max(current)),               # 5. æœ€å¤§å€¤
                        float(min(current)),               # 6. æœ€å°å€¤
                        float(np.median(current)),         # 7. ä¸­å¤®å€¤
                        float(max(current) - min(current)), # 8. ç¯„å›²
                        float(len([j for j in range(len(sorted_nums)-1) 
                                 if sorted_nums[j+1] - sorted_nums[j] == 1])), # 9. é€£ç¶šæ•°
                        float(current[0]),                 # 10. ç¬¬1æ•°å­—
                        float(current[2]),                 # 11. ç¬¬3æ•°å­—ï¼ˆä¸­å¤®ï¼‰
                        float(current[4]),                 # 12. ç¬¬5æ•°å­—ï¼ˆæœ€å¾Œï¼‰
                        float(np.mean(gaps)),              # 13. å¹³å‡ã‚®ãƒ£ãƒƒãƒ—
                        float(len([x for x in current if x <= 15])), # 14. å°æ•°å­—æ•°
                    ]
                    
                    # æ¬¡å›äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                    if i < len(data) - 1:
                        next_nums = []
                        for col in main_cols:
                            if col in data.columns:
                                next_nums.append(int(data.iloc[i+1][col]))
                        
                        if len(next_nums) == 5:
                            for target_num in next_nums:
                                features.append(feat.copy())
                                targets.append(target_num)
                        
                except Exception as e:
                    continue
                
                if (i + 1) % 100 == 0:
                    print(f"  ç‰¹å¾´é‡é€²æ—: {i+1}/{len(data)}ä»¶")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ
            if len(features) > 0:
                sum_patterns = []
                for i in range(len(data)):
                    try:
                        current = []
                        for col in main_cols:
                            if col in data.columns:
                                current.append(int(data.iloc[i][col]))
                        if len(current) == 5 and all(1 <= x <= 31 for x in current) and len(set(current)) == 5:
                            sum_patterns.append(sum(current))
                    except:
                        continue
                
                if sum_patterns:
                    self.pattern_stats = {
                        'avg_sum': float(np.mean(sum_patterns)),
                        'std_sum': float(np.std(sum_patterns)),
                        'most_frequent_pairs': self.pair_freq.most_common(10)
                    }
            
            print(f"âœ… é«˜åº¦14æ¬¡å…ƒç‰¹å¾´é‡å®Œæˆ: {len(features)}å€‹")
            return np.array(features), np.array(targets)
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    
    def train_advanced_models(self, data):
        """é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ï¼‰"""
        try:
            print("ğŸ“Š === é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’é–‹å§‹ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ï¼‰ ===")
            
            # é«˜åº¦14æ¬¡å…ƒç‰¹å¾´é‡ä½œæˆ
            X, y = self.create_advanced_features(data)
            if X is None or len(X) < 100:
                print(f"âŒ ç‰¹å¾´é‡ä¸è¶³: {len(X) if X is not None else 0}ä»¶")
                return False
            
            self.data_count = len(data)
            
            # å„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            print("ğŸ¤– é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            
            for name, model in self.models.items():
                try:
                    print(f"  {name} å­¦ç¿’ä¸­...")
                    
                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    self.scalers[name] = scaler
                    
                    # å­¦ç¿’
                    model.fit(X_scaled, y)
                    
                    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
                    cv_score = np.mean(cross_val_score(model, X_scaled, y, cv=3))
                    
                    self.trained_models[name] = model
                    self.model_scores[name] = cv_score
                    
                    print(f"    âœ… {name}: CVç²¾åº¦ {cv_score*100:.2f}%")
                    
                except Exception as e:
                    print(f"    âŒ {name}: ã‚¨ãƒ©ãƒ¼ {e}")
                    continue
            
            print(f"âœ… é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’å®Œäº†: {len(self.trained_models)}ãƒ¢ãƒ‡ãƒ«")
            return True
            
        except Exception as e:
            print(f"âŒ é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def advanced_predict(self, count=20):
        """é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œï¼ˆ3ãƒ¢ãƒ‡ãƒ«ï¼‰"""
        try:
            if not self.trained_models:
                print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãªã—")
                return []
            
            # åŸºæº–ç‰¹å¾´é‡ï¼ˆé«˜åº¦ç‰ˆï¼‰
            if hasattr(self, 'pattern_stats') and self.pattern_stats:
                avg_sum = self.pattern_stats.get('avg_sum', 80)
                base_features = [
                    avg_sum / 5, 6.0, avg_sum, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5
                ]
            else:
                base_features = [16.0, 6.0, 80.0, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5]
            
            predictions = []
            
            for i in range(count):
                # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’åé›†
                ensemble_votes = Counter()
                
                for name, model in self.trained_models.items():
                    try:
                        scaler = self.scalers[name]
                        X_scaled = scaler.transform([base_features])
                        
                        # è¤‡æ•°å›äºˆæ¸¬
                        for _ in range(8):  # é«˜åº¦ç‰ˆã§ã¯å¤šã‚ã«äºˆæ¸¬
                            if hasattr(model, 'predict_proba'):
                                proba = model.predict_proba(X_scaled)[0]
                                classes = model.classes_
                                if len(classes) > 0:
                                    selected = np.random.choice(classes, p=proba/proba.sum())
                                    if 1 <= selected <= 31:
                                        weight = self.model_weights.get(name, 0.33)
                                        ensemble_votes[int(selected)] += weight
                            else:
                                pred = model.predict(X_scaled)[0]
                                if 1 <= pred <= 31:
                                    weight = self.model_weights.get(name, 0.33)
                                    ensemble_votes[int(pred)] += weight
                                    
                    except Exception as e:
                        continue
                
                # é »å‡ºæ•°å­—ã¨çµ„ã¿åˆã‚ã›
                frequent_nums = [num for num, _ in self.freq_counter.most_common(15)]
                for num in frequent_nums[:10]:
                    ensemble_votes[num] += 0.12
                
                # ä¸Šä½5å€‹ã‚’é¸æŠ
                top_numbers = [num for num, _ in ensemble_votes.most_common(5)]
                
                # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ è£œå®Œ
                while len(top_numbers) < 5:
                    candidate = np.random.randint(1, 32)
                    if candidate not in top_numbers:
                        top_numbers.append(candidate)
                
                final_pred = sorted([int(x) for x in top_numbers[:5]])
                predictions.append(final_pred)
            
            return predictions
            
        except Exception as e:
            print(f"âŒ é«˜åº¦äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def run_timeseries_validation(self):
        """æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        try:
            print("\n" + "="*80)
            print("ğŸ”„ ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Ÿè¡Œé–‹å§‹")
            print("="*80)
            
            if not hasattr(self, 'data_fetcher') or self.data_fetcher.latest_data is None:
                print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return None
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
            self.validator = MiniLotoTimeSeriesValidator()
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            data = self.data_fetcher.latest_data
            
            # 1. å›ºå®šçª“æ¤œè¨¼ï¼ˆ30, 50, 70å›åˆ†ï¼‰
            fixed_results = self.validator.fixed_window_validation(data)
            
            # 2. ç´¯ç©çª“æ¤œè¨¼
            expanding_results = self.validator.expanding_window_validation(data)
            
            # 3. çµæœæ¯”è¼ƒ
            comparison = self.validator.compare_validation_methods()
            
            # 4. ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’èª¿æ•´
            if comparison:
                self._adjust_model_weights(comparison)
            
            print("\nâœ… ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Œäº†")
            return comparison
            
        except Exception as e:
            print(f"âŒ æ™‚ç³»åˆ—æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            print(traceback.format_exc())
            return None
    
    def _adjust_model_weights(self, comparison):
        """æ¤œè¨¼çµæœã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’èª¿æ•´"""
        print("\nğŸ”§ === ãƒ¢ãƒ‡ãƒ«é‡ã¿èª¿æ•´ ===")
        
        # åŸºæœ¬èª¿æ•´ç‡
        adjustment_rate = 0.1
        
        # æœ€é©çª“ã‚µã‚¤ã‚ºã«åŸºã¥ãèª¿æ•´
        if 'fixed' in comparison['recommendation']:
            print("ğŸ“Œ å›ºå®šçª“å„ªä½ã®ãŸã‚ã€çŸ­æœŸãƒ‘ã‚¿ãƒ¼ãƒ³é‡è¦–ã«èª¿æ•´")
            # Random Forestã®é‡ã¿ã‚’å¢—åŠ ï¼ˆçŸ­æœŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¼·ã„ï¼‰
            self.model_weights['random_forest'] *= (1 + adjustment_rate)
            self.model_weights['neural_network'] *= (1 - adjustment_rate * 0.5)
        else:
            print("ğŸ“ˆ ç´¯ç©çª“å„ªä½ã®ãŸã‚ã€é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰é‡è¦–ã«èª¿æ•´")
            # Gradient Boostingã®é‡ã¿ã‚’å¢—åŠ ï¼ˆé•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã«å¼·ã„ï¼‰
            self.model_weights['gradient_boost'] *= (1 + adjustment_rate)
            self.model_weights['random_forest'] *= (1 - adjustment_rate * 0.5)
        
        # Neural NetworkãŒæœ‰åŠ¹ãªå ´åˆã¯é‡ã¿ã‚’ç¶­æŒ
        if 'neural_network' in self.model_scores and self.model_scores['neural_network'] > 0.3:
            print("ğŸ§  Neural Networkæ€§èƒ½è‰¯å¥½ã®ãŸã‚é‡ã¿ã‚’ç¶­æŒ")
        
        # é‡ã¿ã®æ­£è¦åŒ–
        total_weight = sum(self.model_weights.values())
        for model in self.model_weights:
            self.model_weights[model] /= total_weight
        
        print("\nèª¿æ•´å¾Œã®ãƒ¢ãƒ‡ãƒ«é‡ã¿:")
        for model, weight in self.model_weights.items():
            print(f"  {model}: {weight:.3f}")
    
    def predict_next_round_advanced(self, count=20):
        """æ¬¡å›é–‹å‚¬å›ã®é«˜åº¦äºˆæ¸¬"""
        try:
            # æ¬¡å›æƒ…å ±å–å¾—
            next_info = self.data_fetcher.get_next_round_info()
            if not next_info:
                print("âŒ æ¬¡å›é–‹å‚¬å›æƒ…å ±å–å¾—å¤±æ•—")
                return [], {}
            
            print(f"ğŸ¯ === {next_info['prediction_target']}ã®é«˜åº¦äºˆæ¸¬é–‹å§‹ ===")
            print(f"ğŸ“… äºˆæ¸¬æ—¥æ™‚: {next_info['current_date']}")
            print(f"ğŸ“Š æœ€æ–°ãƒ‡ãƒ¼ã‚¿: ç¬¬{next_info['latest_round']}å›ã¾ã§")
            
            # é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
            predictions = self.advanced_predict(count)
            
            if predictions:
                # äºˆæ¸¬ã‚’é–‹å‚¬å›ä»˜ãã§è¨˜éŒ²
                self.history.add_prediction_with_round(
                    predictions, 
                    next_info['next_round'], 
                    next_info['current_date']
                )
                
                print(f"ğŸ“ ç¬¬{next_info['next_round']}å›ã®é«˜åº¦äºˆæ¸¬ã¨ã—ã¦è¨˜éŒ²")
            
            return predictions, next_info
            
        except Exception as e:
            print(f"âŒ æ¬¡å›é«˜åº¦äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return [], {}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚·ã‚¹ãƒ†ãƒ 
advanced_system = MiniLotoAdvancedPredictor()

# ãƒ‘ãƒ¼ãƒˆ2å®Ÿè¡Œé–¢æ•°
def run_miniloto_advanced_prediction():
    try:
        print("\nğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆé«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—ç¢ºèª
        if not advanced_system.data_fetcher.latest_data is None:
            training_data = advanced_system.data_fetcher.latest_data
        else:
            print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒå¿…è¦ã§ã™")
            if not advanced_system.data_fetcher.fetch_latest_data():
                return "FAILED"
            training_data = advanced_system.data_fetcher.latest_data
        
        # é«˜åº¦ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        success = advanced_system.train_advanced_models(training_data)
        if not success:
            return "FAILED"
        
        # é«˜åº¦äºˆæ¸¬å®Ÿè¡Œ
        predictions, next_info = advanced_system.predict_next_round_advanced(20)
        
        if predictions:
            # çµæœè¡¨ç¤º
            print("\n" + "="*80)
            print(f"ğŸ¯ {next_info['prediction_target']}ã®é«˜åº¦äºˆæ¸¬çµæœï¼ˆ20ã‚»ãƒƒãƒˆï¼‰")
            print("ğŸ¤– 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« + 14æ¬¡å…ƒç‰¹å¾´é‡")
            print("="*80)
            
            for i, pred in enumerate(predictions, 1):
                clean_pred = [int(x) for x in pred]
                print(f"ç¬¬{next_info['next_round']}å›é«˜åº¦äºˆæ¸¬ {i:2d}: {clean_pred}")
            
            print("\nğŸ‰ ãƒ‘ãƒ¼ãƒˆ2: é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œäº†!")
            return "SUCCESS"
        else:
            return "FAILED"
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

def run_miniloto_timeseries_validation():
    try:
        print("\nğŸ”„ ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Ÿè¡Œ")
        
        # æ™‚ç³»åˆ—æ¤œè¨¼å®Ÿè¡Œ
        result = advanced_system.run_timeseries_validation()
        
        if result:
            print("\nâœ… æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Œäº†ï¼")
            return "SUCCESS"
        else:
            return "FAILED"
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

# ãƒ‘ãƒ¼ãƒˆ2ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
print("\n" + "="*80)
print("ğŸ§ª ãƒ‘ãƒ¼ãƒˆ2: é«˜åº¦ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
print("="*80)

# é«˜åº¦äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
test_result = run_miniloto_advanced_prediction()
print(f"\nğŸ ãƒ‘ãƒ¼ãƒˆ2é«˜åº¦äºˆæ¸¬ãƒ†ã‚¹ãƒˆçµæœ: {test_result}")

if test_result == "SUCCESS":
    print("âœ… ãƒ‘ãƒ¼ãƒˆ2é«˜åº¦äºˆæ¸¬å®Œäº†")
    
    # æ™‚ç³»åˆ—æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    validation_result = run_miniloto_timeseries_validation()
    print(f"\nğŸ ãƒ‘ãƒ¼ãƒˆ2æ™‚ç³»åˆ—æ¤œè¨¼ãƒ†ã‚¹ãƒˆçµæœ: {validation_result}")
    
    if validation_result == "SUCCESS":
        print("âœ… ãƒ‘ãƒ¼ãƒˆ2å®Œäº† - ãƒ‘ãƒ¼ãƒˆ3ã«é€²ã‚€æº–å‚™å®Œäº†")
        
        # ãƒ‘ãƒ¼ãƒˆ2å®Œäº†çµ±è¨ˆè¡¨ç¤º
        if advanced_system.trained_models:
            print(f"\nğŸ“Š ãƒ‘ãƒ¼ãƒˆ2å®Œäº†çµ±è¨ˆ:")
            print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {advanced_system.data_count}ä»¶")
            print(f"  ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒï¼ˆé«˜åº¦ç‰ˆï¼‰")
            print(f"  å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ•°: {len(advanced_system.trained_models)}å€‹ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰")
            print(f"  é »å‡ºæ•°å­—æ•°: {len(advanced_system.freq_counter)}å€‹")
            print(f"  æ™‚ç³»åˆ—æ¤œè¨¼: å®Œäº†")
    else:
        print("âš ï¸ æ™‚ç³»åˆ—æ¤œè¨¼ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€äºˆæ¸¬æ©Ÿèƒ½ã¯æ­£å¸¸ã§ã™")
else:
    print("âŒ ãƒ‘ãƒ¼ãƒˆ2ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")

print("\n" + "="*80)
print("ğŸ¯ ãƒ‘ãƒ¼ãƒˆ2: é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œäº†")
print("æ¬¡å›: ãƒ‘ãƒ¼ãƒˆ3 - è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç¶™ç¶šæ”¹å–„ï¼‰")
print("="*80)

# ========================= ãƒ‘ãƒ¼ãƒˆ2Cã“ã“ã¾ã§ =========================

# ========================= ãƒ‘ãƒ¼ãƒˆ3Cé–‹å§‹ =========================

    def auto_setup_and_predict_with_persistence(self, force_new=False):
        """æ°¸ç¶šåŒ–å¯¾å¿œã®è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»äºˆæ¸¬å®Ÿè¡Œ"""
        try:
            print("\n" + "="*80)
            print("ğŸŒ ãƒŸãƒ‹ãƒ­ãƒˆçµ±åˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œé–‹å§‹ï¼ˆæ°¸ç¶šåŒ–å¯¾å¿œç‰ˆï¼‰")
            print("="*80)
            
            # 1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
            if not self.data_fetcher.latest_data is None:
                latest_data = self.data_fetcher.latest_data
                latest_round = self.data_fetcher.latest_round
            else:
                if not self.data_fetcher.fetch_latest_data():
                    print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                    return [], {}
                latest_data = self.data_fetcher.latest_data
                latest_round = self.data_fetcher.latest_round
            
            next_round = latest_round + 1
            next_info = self.data_fetcher.get_next_round_info()
            
            print(f"ğŸ“Š æœ€æ–°ãƒ‡ãƒ¼ã‚¿: ç¬¬{latest_round}å›ã¾ã§å–å¾—æ¸ˆã¿")
            print(f"ğŸ¯ äºˆæ¸¬å¯¾è±¡: ç¬¬{next_round}å›")
            
            # 2. æ—¢å­˜äºˆæ¸¬ã®ãƒã‚§ãƒƒã‚¯
            if not force_new and self.persistence.is_prediction_exists(next_round):
                print(f"\nğŸ“‚ ç¬¬{next_round}å›ã®äºˆæ¸¬ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ï¼ˆæ°¸ç¶šåŒ–æ¸ˆã¿ï¼‰")
                existing_prediction = self.persistence.load_prediction(next_round)
                
                self.display_existing_prediction(existing_prediction, next_round)
                self.analyze_and_display_previous_results(latest_data, latest_round)
                
                return existing_prediction['predictions'], next_info
            
            # 3. æ–°ã—ã„äºˆæ¸¬ãŒå¿…è¦ãªå ´åˆ
            print(f"\nğŸ†• ç¬¬{next_round}å›ã®æ–°è¦äºˆæ¸¬ã‚’é–‹å§‹ã—ã¾ã™")
            
            # 4. å‰å›çµæœã¨ã®ç…§åˆãƒ»å­¦ç¿’
            learning_applied = self.check_and_apply_learning(latest_data, latest_round)
            
            # 5. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç¢ºèªï¼ˆå¿…è¦ã«å¿œã˜ã¦å†å­¦ç¿’ï¼‰
            if not self.trained_models:
                print("ğŸ”§ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒå¿…è¦ã§ã™")
                success = self.train_models_if_needed(latest_data)
                if not success:
                    print("âŒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å¤±æ•—")
                    return [], {}
            
            # 6. æ–°ã—ã„äºˆæ¸¬ç”Ÿæˆ
            predictions = self.predict_with_learning(20, use_learning=learning_applied)
            if not predictions:
                print("âŒ äºˆæ¸¬ç”Ÿæˆå¤±æ•—")
                return [], {}
            
            # 7. äºˆæ¸¬ã‚’æ°¸ç¶šåŒ–ä¿å­˜
            metadata = {
                'learning_applied': learning_applied,
                'model_count': len(self.trained_models),
                'feature_dimensions': 14,
                'data_count': self.data_count,
                'model_weights': self.model_weights.copy()
            }
            
            self.persistence.save_prediction_permanently(next_round, predictions, metadata)
            
            # 8. äºˆæ¸¬çµæœè¡¨ç¤º
            self.display_new_prediction_results(predictions, next_info, learning_applied)
            
            # 9. å‰å›çµæœã®åˆ†æãƒ»è¡¨ç¤º
            self.analyze_and_display_previous_results(latest_data, latest_round)
            
            print("\n" + "="*80)
            print("ğŸ‰ çµ±åˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†!")
            print(f"ğŸ“ ç¬¬{next_round}å›äºˆæ¸¬ã¨ã—ã¦æ°¸ç¶šåŒ–æ¸ˆã¿")
            print("ğŸ”„ æ¬¡å›å®Ÿè¡Œæ™‚ã¯ä¿å­˜æ¸ˆã¿äºˆæ¸¬ã‚’è¡¨ç¤ºã—ã¾ã™")
            print("="*80)
            
            return predictions, next_info
            
        except Exception as e:
            print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            print(f"è©³ç´°: {traceback.format_exc()}")
            return [], {}
    
    def train_models_if_needed(self, data):
        """å¿…è¦ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
        if self.trained_models and len(self.trained_models) >= 2:
            print("âœ… æ—¢å­˜ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
            return True
        
        # ãƒ‘ãƒ¼ãƒˆ2ã®é«˜åº¦å­¦ç¿’ã‚’å®Ÿè¡Œ
        return advanced_system.train_advanced_models(data)
    
    def display_existing_prediction(self, prediction_data, round_number):
        """æ—¢å­˜ã®äºˆæ¸¬ã‚’è¡¨ç¤º"""
        print(f"ğŸ“… äºˆæ¸¬ä½œæˆæ—¥æ™‚: {prediction_data['timestamp']}")
        print(f"ğŸ“Š äºˆæ¸¬ã‚»ãƒƒãƒˆæ•°: {len(prediction_data['predictions'])}ã‚»ãƒƒãƒˆ")
        
        if prediction_data['metadata']['learning_applied']:
            print("ğŸ’¡ å­¦ç¿’æ”¹å–„ãŒé©ç”¨ã•ã‚ŒãŸäºˆæ¸¬")
        
        print("-"*80)
        
        for i, pred in enumerate(prediction_data['predictions'], 1):
            clean_pred = [int(x) for x in pred]
            print(f"ç¬¬{round_number}å›äºˆæ¸¬ {i:2d}: {clean_pred}")
        
        # æ¤œè¨¼æ¸ˆã¿ã®å ´åˆã¯çµæœã‚‚è¡¨ç¤º
        if prediction_data['verified'] and prediction_data['actual_result']:
            print(f"\nâœ… æ¤œè¨¼æ¸ˆã¿ - å½“é¸ç•ªå·: {prediction_data['actual_result']}")
            print("ä¸€è‡´çµæœ:")
            for i, matches in enumerate(prediction_data['matches'], 1):
                print(f"  äºˆæ¸¬{i:2d}: {matches}å€‹ä¸€è‡´")
            print(f"æœ€é«˜ä¸€è‡´: {prediction_data['best_match']}å€‹")
    
    def display_new_prediction_results(self, predictions, next_info, learning_applied):
        """æ–°ã—ã„äºˆæ¸¬çµæœã®è¡¨ç¤º"""
        print("\n" + "="*80)
        print(f"ğŸ¯ {next_info['prediction_target']}ã®äºˆæ¸¬çµæœï¼ˆ20ã‚»ãƒƒãƒˆï¼‰")
        if learning_applied:
            print("ğŸ’¡ å­¦ç¿’æ”¹å–„ã‚’é©ç”¨ã—ãŸäºˆæ¸¬")
        print("ğŸ¤– 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« + 14æ¬¡å…ƒç‰¹å¾´é‡ + è‡ªå‹•å­¦ç¿’")
        print("="*80)
        print(f"ğŸ“… äºˆæ¸¬ä½œæˆæ—¥æ™‚: {next_info['current_date']}")
        print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: ç¬¬1å›ã€œç¬¬{next_info['latest_round']}å›ï¼ˆ{self.data_count}ä»¶ï¼‰")
        print("-"*80)
        
        for i, pred in enumerate(predictions, 1):
            clean_pred = [int(x) for x in pred]
            print(f"ç¬¬{next_info['next_round']}å›äºˆæ¸¬ {i:2d}: {clean_pred}")
        
        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è¡¨ç¤º
        print("\n" + "="*80)
        print("ğŸ¤– çµ±åˆãƒ¢ãƒ‡ãƒ«æ€§èƒ½")
        if learning_applied:
            print("ğŸ’¡ å­¦ç¿’æ”¹å–„é©ç”¨å¾Œã®æ€§èƒ½")
        print("="*80)
        
        for name, score in self.model_scores.items():
            weight = self.model_weights.get(name, 0)
            print(f"{name:15s}: CVç²¾åº¦ {score*100:5.2f}% | é‡ã¿ {weight:.3f}")
        
        # çµ±è¨ˆæƒ…å ±
        print("\n" + "="*80)
        print("ğŸ“Š åˆ†æçµæœ")
        print("="*80)
        print(f"ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒï¼ˆãƒŸãƒ‹ãƒ­ãƒˆæœ€é©åŒ–ç‰ˆï¼‰")
        
        if hasattr(self, 'pattern_stats') and self.pattern_stats:
            print(f"å¹³å‡åˆè¨ˆå€¤: {self.pattern_stats.get('avg_sum', 0):.1f}")
        
        print(f"\nğŸ”¥ é »å‡ºæ•°å­—TOP10:")
        for i, (num, count) in enumerate(self.freq_counter.most_common(10)):
            if i % 5 == 0:
                print("")
            print(f"{int(num)}ç•ª({int(count)}å›)", end="  ")
        
        # å­¦ç¿’æ”¹å–„æƒ…å ±ã®è¡¨ç¤º
        if learning_applied and hasattr(self.auto_learner, 'improvement_metrics'):
            self.display_learning_improvements()
    
    def display_learning_improvements(self):
        """å­¦ç¿’æ”¹å–„æƒ…å ±ã®è¡¨ç¤º"""
        print("\n\nğŸ’¡ === å­¦ç¿’æ”¹å–„æƒ…å ± ===")
        
        metrics = self.auto_learner.improvement_metrics
        
        if 'frequently_missed' in metrics:
            print("ğŸ¯ è¦‹é€ƒã—é »åº¦ã®é«˜ã„ç•ªå·ï¼ˆãƒ–ãƒ¼ã‚¹ãƒˆå¯¾è±¡ï¼‰:")
            for num, count in metrics['frequently_missed'][:5]:
                print(f"    {num}ç•ª: {count}å›è¦‹é€ƒã— â†’ ãƒ–ãƒ¼ã‚¹ãƒˆé©ç”¨")
        
        if 'high_accuracy_patterns' in metrics:
            patterns = metrics['high_accuracy_patterns']
            print(f"ğŸ“Š é«˜ç²¾åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’:")
            print(f"    ç›®æ¨™åˆè¨ˆå€¤: {patterns['avg_sum']:.1f}")
            print(f"    ç›®æ¨™å¥‡æ•°å€‹æ•°: {patterns['avg_odd_count']:.1f}")
            print(f"    ç›®æ¨™å°æ•°å­—å€‹æ•°: {patterns['avg_small_count']:.1f}")
            print(f"    å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {patterns['sample_size']}ä»¶")
        
        if 'small_number_importance' in metrics:
            importance = metrics['small_number_importance']
            print(f"ğŸ”¢ å°æ•°å­—é‡è¦åº¦: {importance:.1f}å€‹ï¼ˆâ‰¤15ã®æ•°å­—ãŒé‡è¦ï¼‰")
    
    def analyze_and_display_previous_results(self, latest_data, current_round):
        """å‰å›çµæœã®åˆ†æãƒ»è¡¨ç¤º"""
        previous_prediction = self.persistence.load_prediction(current_round)
        
        if not previous_prediction or not previous_prediction['verified']:
            return
        
        print(f"\n" + "="*80)
        print(f"ğŸ“Š ç¬¬{current_round}å› çµæœåˆ†æ")
        print("="*80)
        
        actual_numbers = previous_prediction['actual_result']
        matches = previous_prediction['matches']
        
        print(f"ğŸ¯ å½“é¸ç•ªå·: {actual_numbers}")
        print(f"ğŸ“ˆ äºˆæ¸¬çµæœ:")
        print("-"*50)
        
        for i, (pred, match_count) in enumerate(zip(previous_prediction['predictions'], matches), 1):
            pred_numbers = [int(x) for x in pred]
            matched = sorted(list(set(pred_numbers) & set(actual_numbers)))
            
            status = "ğŸ‰" if match_count >= 4 else "â­" if match_count >= 3 else "ğŸ“Š"
            print(f"{status} äºˆæ¸¬{i:2d}: {pred_numbers} â†’ {match_count}å€‹ä¸€è‡´ {matched}")
        
        # çµ±è¨ˆè¡¨ç¤º
        avg_matches = np.mean(matches)
        max_matches = max(matches)
        match_3_plus = sum(1 for m in matches if m >= 3)
        match_4_plus = sum(1 for m in matches if m >= 4)
        
        print("-"*50)
        print(f"ğŸ“Š çµæœçµ±è¨ˆ:")
        print(f"    å¹³å‡ä¸€è‡´æ•°: {avg_matches:.2f}å€‹")
        print(f"    æœ€é«˜ä¸€è‡´æ•°: {max_matches}å€‹")
        print(f"    3å€‹ä»¥ä¸Šä¸€è‡´: {match_3_plus}ã‚»ãƒƒãƒˆ")
        print(f"    4å€‹ä»¥ä¸Šä¸€è‡´: {match_4_plus}ã‚»ãƒƒãƒˆ")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚·ã‚¹ãƒ†ãƒ 
integrated_system = MiniLotoIntegratedSystem()

# ãƒ‘ãƒ¼ãƒˆ3å®Ÿè¡Œé–¢æ•°
def run_miniloto_integrated_prediction():
    try:
        print("\nğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆçµ±åˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ")
        
        # çµ±åˆäºˆæ¸¬å®Ÿè¡Œ
        predictions, next_info = integrated_system.auto_setup_and_predict_with_persistence()
        
        if predictions:
            print("\nğŸ‰ ãƒ‘ãƒ¼ãƒˆ3: çµ±åˆã‚·ã‚¹ãƒ†ãƒ å®Œäº†!")
            print("ğŸ“ äºˆæ¸¬çµæœãŒæ°¸ç¶šåŒ–ã•ã‚Œã¾ã—ãŸ")
            return "SUCCESS"
        else:
            print("âŒ çµ±åˆäºˆæ¸¬å¤±æ•—")
            return "FAILED"
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

def run_miniloto_auto_verification():
    try:
        print("\nğŸ”„ ãƒŸãƒ‹ãƒ­ãƒˆè‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„å®Ÿè¡Œ")
        
        # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        if not integrated_system.data_fetcher.latest_data is None:
            latest_data = integrated_system.data_fetcher.latest_data
        else:
            print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒå¿…è¦ã§ã™")
            if not integrated_system.data_fetcher.fetch_latest_data():
                return "FAILED"
            latest_data = integrated_system.data_fetcher.latest_data
        
        # è‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„å®Ÿè¡Œ
        # éå»ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡æ“¬çš„ã«ä½œæˆã—ã¦æ¤œè¨¼
        all_predictions = integrated_system.persistence.get_all_predictions()
        
        if all_predictions:
            print(f"ğŸ“Š {len(all_predictions)}ä»¶ã®äºˆæ¸¬ã‚’ç¢ºèªä¸­...")
            
            # å­¦ç¿’æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = integrated_system.auto_learner.generate_improvement_report()
            print(report)
            
            print("\nâœ… è‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„å®Œäº†ï¼")
            return "SUCCESS"
        else:
            print("ğŸ“Š ç…§åˆå¯¾è±¡ã®äºˆæ¸¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return "SUCCESS"  # ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

def export_prediction_data():
    """äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        json_data = integrated_system.persistence.export_to_json()
        if json_data:
            print("âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
            print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(json_data)}æ–‡å­—")
            return "SUCCESS"
        else:
            return "FAILED"
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return "ERROR"

# ãƒ‘ãƒ¼ãƒˆ3ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
print("\n" + "="*80)
print("ğŸ§ª ãƒ‘ãƒ¼ãƒˆ3: çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
print("="*80)

# çµ±åˆäºˆæ¸¬ãƒ†ã‚¹ãƒˆ
test_result = run_miniloto_integrated_prediction()
print(f"\nğŸ ãƒ‘ãƒ¼ãƒˆ3çµ±åˆäºˆæ¸¬ãƒ†ã‚¹ãƒˆçµæœ: {test_result}")

if test_result == "SUCCESS":
    print("âœ… ãƒ‘ãƒ¼ãƒˆ3çµ±åˆäºˆæ¸¬å®Œäº†")
    
    # è‡ªå‹•ç…§åˆãƒ†ã‚¹ãƒˆ
    verification_result = run_miniloto_auto_verification()
    print(f"\nğŸ ãƒ‘ãƒ¼ãƒˆ3è‡ªå‹•ç…§åˆãƒ†ã‚¹ãƒˆçµæœ: {verification_result}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
    export_result = export_prediction_data()
    print(f"\nğŸ ãƒ‘ãƒ¼ãƒˆ3ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆçµæœ: {export_result}")
    
    if verification_result == "SUCCESS" and export_result == "SUCCESS":
        print("âœ… ãƒ‘ãƒ¼ãƒˆ3å®Œäº† - å…¨æ©Ÿèƒ½æ­£å¸¸å‹•ä½œ")
        
        # ãƒ‘ãƒ¼ãƒˆ3å®Œäº†çµ±è¨ˆè¡¨ç¤º
        if integrated_system.trained_models:
            print(f"\nğŸ“Š ãƒ‘ãƒ¼ãƒˆ3å®Œäº†çµ±è¨ˆ:")
            print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {integrated_system.data_count}ä»¶")
            print(f"  ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒï¼ˆæœ€çµ‚ç‰ˆï¼‰")
            print(f"  å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ•°: {len(integrated_system.trained_models)}å€‹ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰")
            print(f"  æ°¸ç¶šåŒ–äºˆæ¸¬æ•°: {len(integrated_system.persistence.get_all_predictions())}ä»¶")
            print(f"  è‡ªå‹•å­¦ç¿’: æœ‰åŠ¹")
            print(f"  äºˆæ¸¬æ°¸ç¶šåŒ–: æœ‰åŠ¹")
    else:
        print("âš ï¸ ä¸€éƒ¨æ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€åŸºæœ¬äºˆæ¸¬æ©Ÿèƒ½ã¯æ­£å¸¸ã§ã™")
else:
    print("âŒ ãƒ‘ãƒ¼ãƒˆ3ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")

print("\n" + "="*80)
print("ğŸ¯ ãƒ‘ãƒ¼ãƒˆ3: è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å®Œäº†")
print("æ¬¡å›: ãƒ‘ãƒ¼ãƒˆ4 - çµ±åˆãƒ»å®Œæˆç‰ˆ")
print("="*80)

# ========================= ãƒ‘ãƒ¼ãƒˆ3Cã“ã“ã¾ã§ =========================# ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  ãƒ‘ãƒ¼ãƒˆ3: è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç¶™ç¶šæ”¹å–„ï¼‰
# ========================= ãƒ‘ãƒ¼ãƒˆ3Aé–‹å§‹ =========================

import pandas as pd
import numpy as np
from collections import Counter, defaultdict
import json
import traceback
from datetime import datetime

print("ğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‘ãƒ¼ãƒˆ3: è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
print("ğŸ”„ è‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„ + äºˆæ¸¬æ°¸ç¶šåŒ– + ç¶™ç¶šçš„æ”¹å–„")
print("ğŸ§  è¦‹é€ƒã—ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ + æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")

# è‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„ã‚¯ãƒ©ã‚¹ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆç‰ˆï¼‰
class MiniLotoAutoVerificationLearner:
    """ãƒŸãƒ‹ãƒ­ãƒˆç”¨è‡ªå‹•ç…§åˆã¨ç¶™ç¶šçš„å­¦ç¿’æ”¹å–„ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    def __init__(self):
        self.verification_results = []
        self.learning_history = []
        self.improvement_metrics = {}
        self.feature_weights = {}
        
    def verify_and_learn(self, prediction_history, latest_data):
        """äºˆæ¸¬å±¥æ­´ã¨å®Ÿéš›ã®çµæœã‚’ç…§åˆã—ã€å­¦ç¿’ã‚’æ”¹å–„"""
        print("\nğŸ”„ === ãƒŸãƒ‹ãƒ­ãƒˆè‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„é–‹å§‹ ===")
        
        verified_count = 0
        total_improvements = []
        main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
        round_col = 'é–‹å‚¬å›'
        
        for entry in prediction_history.predictions:
            if entry['verified']:
                continue
                
            # è©²å½“ã™ã‚‹é–‹å‚¬å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            matching_data = latest_data[latest_data[round_col] == entry['round']]
            
            if len(matching_data) > 0:
                actual_row = matching_data.iloc[0]
                actual_numbers = []
                for col in main_cols:
                    if col in actual_row.index:
                        actual_numbers.append(int(actual_row[col]))
                
                if len(actual_numbers) == 5:
                    # ç…§åˆã¨åˆ†æ
                    verification_result = self._analyze_prediction(
                        entry['predictions'], 
                        actual_numbers,
                        entry['round']
                    )
                    
                    self.verification_results.append(verification_result)
                    verified_count += 1
                    
                    # å­¦ç¿’æ”¹å–„
                    improvements = self._improve_from_result(verification_result, actual_row, main_cols)
                    total_improvements.extend(improvements)
        
        if verified_count > 0:
            print(f"\nâœ… {verified_count}ä»¶ã®äºˆæ¸¬ã‚’ç…§åˆãƒ»åˆ†æ")
            self._aggregate_improvements(total_improvements)
        
        return verified_count
    
    def _analyze_prediction(self, predictions, actual, round_num):
        """äºˆæ¸¬çµæœã®è©³ç´°åˆ†æ"""
        analysis = {
            'round': round_num,
            'actual': actual,
            'predictions': predictions,
            'match_details': [],
            'patterns': {}
        }
        
        # å„äºˆæ¸¬ã‚»ãƒƒãƒˆã®åˆ†æ
        for i, pred in enumerate(predictions):
            pred_set = set(pred)
            actual_set = set(actual)
            matches = pred_set & actual_set
            
            detail = {
                'prediction_idx': i,
                'matches': len(matches),
                'matched_numbers': sorted(list(matches)),
                'missed_numbers': sorted(list(actual_set - pred_set)),
                'extra_numbers': sorted(list(pred_set - actual_set))
            }
            analysis['match_details'].append(detail)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        analysis['patterns'] = {
            'actual_sum': sum(actual),
            'actual_odd_count': sum(1 for n in actual if n % 2 == 1),
            'actual_range': max(actual) - min(actual),
            'actual_consecutive': self._count_consecutive(sorted(actual)),
            'best_match_count': max(d['matches'] for d in analysis['match_details']),
            'actual_small_count': sum(1 for n in actual if n <= 15)  # ãƒŸãƒ‹ãƒ­ãƒˆç”¨
        }
        
        return analysis
    
    def _count_consecutive(self, sorted_nums):
        """é€£ç¶šæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        count = 0
        for i in range(len(sorted_nums) - 1):
            if sorted_nums[i+1] - sorted_nums[i] == 1:
                count += 1
        return count
    
    def _improve_from_result(self, verification_result, actual_row, main_cols):
        """ç…§åˆçµæœã‹ã‚‰å­¦ç¿’æ”¹å–„ç‚¹ã‚’æŠ½å‡º"""
        improvements = []
        
        # é«˜ç²¾åº¦äºˆæ¸¬ï¼ˆ3å€‹ä»¥ä¸Šä¸€è‡´ï¼‰ã®ç‰¹å¾´ã‚’å­¦ç¿’
        high_accuracy_preds = [
            d for d in verification_result['match_details'] 
            if d['matches'] >= 3
        ]
        
        if high_accuracy_preds:
            improvement = {
                'type': 'high_accuracy_pattern',
                'round': verification_result['round'],
                'patterns': verification_result['patterns'],
                'match_count': high_accuracy_preds[0]['matches']
            }
            improvements.append(improvement)
        
        # é »ç¹ã«è¦‹é€ƒã™æ•°å­—ã®å­¦ç¿’
        all_missed = []
        for detail in verification_result['match_details']:
            all_missed.extend(detail['missed_numbers'])
        
        if all_missed:
            missed_freq = Counter(all_missed)
            improvement = {
                'type': 'frequently_missed',
                'numbers': missed_freq.most_common(5),
                'round': verification_result['round']
            }
            improvements.append(improvement)
        
        # ãƒŸãƒ‹ãƒ­ãƒˆç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        patterns = verification_result['patterns']
        if patterns['actual_small_count'] >= 3:  # å°æ•°å­—ãŒå¤šã„å ´åˆ
            improvement = {
                'type': 'small_number_pattern',
                'small_count': patterns['actual_small_count'],
                'round': verification_result['round']
            }
            improvements.append(improvement)
        
        return improvements
    
    def _aggregate_improvements(self, improvements):
        """æ”¹å–„ç‚¹ã‚’é›†ç´„ã—ã¦å­¦ç¿’æˆ¦ç•¥ã‚’æ›´æ–°"""
        print("\nğŸ“ˆ === ãƒŸãƒ‹ãƒ­ãƒˆå­¦ç¿’æ”¹å–„ç‚¹ã®é›†ç´„ ===")
        
        # é«˜ç²¾åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é›†ç´„
        high_acc_patterns = [imp for imp in improvements if imp['type'] == 'high_accuracy_pattern']
        if high_acc_patterns:
            avg_sum = np.mean([p['patterns']['actual_sum'] for p in high_acc_patterns])
            avg_odd = np.mean([p['patterns']['actual_odd_count'] for p in high_acc_patterns])
            avg_small = np.mean([p['patterns']['actual_small_count'] for p in high_acc_patterns])
            print(f"é«˜ç²¾åº¦äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³: å¹³å‡åˆè¨ˆ {avg_sum:.1f}, å¹³å‡å¥‡æ•° {avg_odd:.1f}, å¹³å‡å°æ•°å­— {avg_small:.1f}")
            
            self.improvement_metrics['high_accuracy_patterns'] = {
                'avg_sum': avg_sum,
                'avg_odd_count': avg_odd,
                'avg_small_count': avg_small,
                'sample_size': len(high_acc_patterns)
            }
        
        # é »ç¹ã«è¦‹é€ƒã™æ•°å­—ã®é›†ç´„
        missed_patterns = [imp for imp in improvements if imp['type'] == 'frequently_missed']
        if missed_patterns:
            all_missed_nums = Counter()
            for pattern in missed_patterns:
                for num, count in pattern['numbers']:
                    all_missed_nums[num] += count
            
            print(f"é »ç¹ã«è¦‹é€ƒã™æ•°å­—TOP5: {all_missed_nums.most_common(5)}")
            self.improvement_metrics['frequently_missed'] = all_missed_nums.most_common(10)
        
        # å°æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é›†ç´„
        small_patterns = [imp for imp in improvements if imp['type'] == 'small_number_pattern']
        if small_patterns:
            avg_small_count = np.mean([p['small_count'] for p in small_patterns])
            print(f"å°æ•°å­—é‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³: å¹³å‡å°æ•°å­—æ•° {avg_small_count:.1f}")
            self.improvement_metrics['small_number_importance'] = avg_small_count
    
    def generate_improvement_report(self):
        """å­¦ç¿’æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not self.verification_results:
            return "ã¾ã ç…§åˆçµæœãŒã‚ã‚Šã¾ã›ã‚“"
        
        report = []
        report.append("\nğŸ“Š === ãƒŸãƒ‹ãƒ­ãƒˆè‡ªå‹•ç…§åˆãƒ»å­¦ç¿’æ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆ ===")
        report.append(f"ç…§åˆæ¸ˆã¿äºˆæ¸¬: {len(self.verification_results)}ä»¶")
        
        # å…¨ä½“çš„ãªç²¾åº¦
        all_matches = []
        for result in self.verification_results:
            for detail in result['match_details']:
                all_matches.append(detail['matches'])
        
        if all_matches:
            report.append(f"å¹³å‡ä¸€è‡´æ•°: {np.mean(all_matches):.2f}å€‹")
            report.append(f"æœ€é«˜ä¸€è‡´æ•°: {max(all_matches)}å€‹")
        
        # æ”¹å–„ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if self.improvement_metrics:
            report.append("\nã€å­¦ç¿’ã«ã‚ˆã‚‹æ”¹å–„ç‚¹ã€‘")
            
            if 'high_accuracy_patterns' in self.improvement_metrics:
                patterns = self.improvement_metrics['high_accuracy_patterns']
                report.append(f"é«˜ç²¾åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹:")
                report.append(f"  - ç†æƒ³çš„ãªåˆè¨ˆå€¤: {patterns['avg_sum']:.0f}")
                report.append(f"  - ç†æƒ³çš„ãªå¥‡æ•°å€‹æ•°: {patterns['avg_odd_count']:.0f}")
                report.append(f"  - ç†æƒ³çš„ãªå°æ•°å­—å€‹æ•°: {patterns['avg_small_count']:.0f}")
            
            if 'frequently_missed' in self.improvement_metrics:
                report.append("é »å‡ºè¦‹é€ƒã—æ•°å­—:")
                for num, count in self.improvement_metrics['frequently_missed'][:5]:
                    report.append(f"  - {num}ç•ª: {count}å›è¦‹é€ƒã—")
            
            if 'small_number_importance' in self.improvement_metrics:
                importance = self.improvement_metrics['small_number_importance']
                report.append(f"å°æ•°å­—é‡è¦åº¦: {importance:.1f}å€‹ï¼ˆâ‰¤15ã®æ•°å­—ï¼‰")
        
        return "\n".join(report)
    
    def get_learning_adjustments(self):
        """å­¦ç¿’èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—"""
        adjustments = {
            'boost_numbers': [],
            'pattern_targets': {},
            'weight_adjustments': {}
        }
        
        # é »ç¹ã«è¦‹é€ƒã™æ•°å­—ã‚’ãƒ–ãƒ¼ã‚¹ãƒˆ
        if 'frequently_missed' in self.improvement_metrics:
            adjustments['boost_numbers'] = [
                num for num, _ in self.improvement_metrics['frequently_missed'][:5]
            ]
        
        # é«˜ç²¾åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        if 'high_accuracy_patterns' in self.improvement_metrics:
            adjustments['pattern_targets'] = self.improvement_metrics['high_accuracy_patterns']
        
        # å°æ•°å­—é‡è¦åº¦èª¿æ•´
        if 'small_number_importance' in self.improvement_metrics:
            adjustments['small_number_boost'] = self.improvement_metrics['small_number_importance']
        
        return adjustments

# ========================= ãƒ‘ãƒ¼ãƒˆ3Aã“ã“ã¾ã§ =========================

# ========================= ãƒ‘ãƒ¼ãƒˆ3Bé–‹å§‹ =========================

# äºˆæ¸¬æ°¸ç¶šåŒ–ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆç‰ˆï¼‰
class MiniLotoPredictionPersistence:
    """ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã®æ°¸ç¶šåŒ–ã¨å±¥æ­´ç®¡ç†"""
    def __init__(self):
        self.memory_storage = {}
        self.session_predictions = {}
        self.prediction_metadata = {}
        
    def save_prediction_permanently(self, round_number, predictions, metadata):
        """äºˆæ¸¬ã‚’æ°¸ç¶šåŒ–ä¿å­˜"""
        try:
            prediction_data = {
                'round': round_number,
                'predictions': predictions,
                'metadata': metadata,
                'timestamp': datetime.now().isoformat(),
                'verified': False,
                'actual_result': None
            }
            
            # ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–
            self.memory_storage[round_number] = prediction_data
            self.session_predictions[round_number] = prediction_data
            
            print(f"ğŸ’¾ ç¬¬{round_number}å›äºˆæ¸¬ã‚’æ°¸ç¶šåŒ–ä¿å­˜å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ æ°¸ç¶šåŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_prediction(self, round_number):
        """æŒ‡å®šå›ã®äºˆæ¸¬ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if round_number in self.memory_storage:
                return self.memory_storage[round_number]
            elif round_number in self.session_predictions:
                return self.session_predictions[round_number]
            else:
                return None
        except Exception as e:
            print(f"âŒ äºˆæ¸¬èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def is_prediction_exists(self, round_number):
        """äºˆæ¸¬ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        return round_number in self.memory_storage or round_number in self.session_predictions
    
    def update_with_actual_result(self, round_number, actual_numbers):
        """å®Ÿéš›ã®çµæœã§äºˆæ¸¬ã‚’æ›´æ–°"""
        try:
            prediction_data = self.load_prediction(round_number)
            if prediction_data:
                prediction_data['actual_result'] = actual_numbers
                prediction_data['verified'] = True
                
                # ä¸€è‡´æ•°è¨ˆç®—
                matches = []
                for pred_set in prediction_data['predictions']:
                    match_count = len(set(pred_set) & set(actual_numbers))
                    matches.append(match_count)
                
                prediction_data['matches'] = matches
                prediction_data['best_match'] = max(matches)
                
                # ä¿å­˜æ›´æ–°
                self.memory_storage[round_number] = prediction_data
                self.session_predictions[round_number] = prediction_data
                
                print(f"âœ… ç¬¬{round_number}å›äºˆæ¸¬ã‚’å®Ÿéš›ã®çµæœã§æ›´æ–°")
                return True
                
        except Exception as e:
            print(f"âŒ å®Ÿéš›çµæœæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_all_predictions(self):
        """å…¨ã¦ã®äºˆæ¸¬ã‚’å–å¾—"""
        all_predictions = {}
        all_predictions.update(self.memory_storage)
        all_predictions.update(self.session_predictions)
        return all_predictions
    
    def export_to_json(self):
        """JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            export_data = {
                'predictions': self.get_all_predictions(),
                'export_timestamp': datetime.now().isoformat()
            }
            return json.dumps(export_data, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

# çµ±åˆãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæœ€çµ‚ç‰ˆï¼‰
class MiniLotoIntegratedSystem:
    def __init__(self):
        print("ğŸ”§ MiniLotoIntegratedSystemåˆæœŸåŒ–")
        
        # ä»–ã®ãƒ‘ãƒ¼ãƒˆã‹ã‚‰ç¶™æ‰¿
        from __main__ import advanced_system
        self.data_fetcher = advanced_system.data_fetcher
        self.models = advanced_system.models
        self.scalers = advanced_system.scalers
        self.model_weights = advanced_system.model_weights.copy()
        self.freq_counter = advanced_system.freq_counter
        self.pair_freq = advanced_system.pair_freq
        self.pattern_stats = advanced_system.pattern_stats
        self.trained_models = advanced_system.trained_models
        self.model_scores = advanced_system.model_scores
        self.data_count = advanced_system.data_count
        
        # ãƒ‘ãƒ¼ãƒˆ3å°‚ç”¨æ©Ÿèƒ½
        self.auto_learner = MiniLotoAutoVerificationLearner()
        self.persistence = MiniLotoPredictionPersistence()
        self.learning_enabled = True
        
        print("âœ… çµ±åˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def check_and_apply_learning(self, latest_data, current_round):
        """å‰å›çµæœã¨ã®ç…§åˆãƒ»å­¦ç¿’ã‚’å®Ÿè¡Œ"""
        print("\nğŸ” === å‰å›çµæœã¨ã®ç…§åˆãƒ»å­¦ç¿’ãƒã‚§ãƒƒã‚¯ ===")
        
        # å‰å›ã®äºˆæ¸¬ã‚’å–å¾—
        previous_round = current_round
        previous_prediction = self.persistence.load_prediction(previous_round)
        
        if not previous_prediction:
            print(f"ğŸ“Š ç¬¬{previous_round}å›ã®äºˆæ¸¬è¨˜éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        if previous_prediction['verified']:
            print(f"âœ… ç¬¬{previous_round}å›ã¯æ—¢ã«å­¦ç¿’æ¸ˆã¿ã§ã™")
            return True
        
        # å½“é¸çµæœã‚’æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
        main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
        round_col = 'é–‹å‚¬å›'
        
        matching_data = latest_data[latest_data[round_col] == previous_round]
        
        if len(matching_data) == 0:
            print(f"ğŸ“Š ç¬¬{previous_round}å›ã®å½“é¸çµæœãŒã¾ã æœªå…¬é–‹ã§ã™")
            return False
        
        # å½“é¸ç•ªå·ã‚’å–å¾—
        actual_row = matching_data.iloc[0]
        actual_numbers = []
        for col in main_cols:
            if col in actual_row.index:
                actual_numbers.append(int(actual_row[col]))
        
        if len(actual_numbers) != 5:
            print(f"âŒ ç¬¬{previous_round}å›ã®å½“é¸ç•ªå·ãŒä¸å®Œå…¨ã§ã™")
            return False
        
        # äºˆæ¸¬çµæœã¨ã®ç…§åˆ
        print(f"\nğŸ¯ ç¬¬{previous_round}å›ã®çµæœåˆ†æãƒ»å­¦ç¿’ã‚’å®Ÿè¡Œ")
        print(f"å½“é¸ç•ªå·: {actual_numbers}")
        
        # æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ã§çµæœæ›´æ–°
        self.persistence.update_with_actual_result(previous_round, actual_numbers)
        
        # å­¦ç¿’åˆ†æã‚’å®Ÿè¡Œ
        self.perform_detailed_learning_analysis(previous_prediction, actual_numbers, previous_round)
        
        print(f"âœ… ç¬¬{previous_round}å›ã®å­¦ç¿’åˆ†æå®Œäº†")
        return True
    
    def perform_detailed_learning_analysis(self, prediction_data, actual_numbers, round_number):
        """è©³ç´°ãªå­¦ç¿’åˆ†æã‚’å®Ÿè¡Œ"""
        print(f"\nğŸ§  === ç¬¬{round_number}å›è©³ç´°å­¦ç¿’åˆ†æ ===")
        
        predictions = prediction_data['predictions']
        
        # ä¸€è‡´æ•°ã®çµ±è¨ˆ
        matches = []
        detailed_analysis = []
        
        for i, pred_set in enumerate(predictions):
            pred_numbers = [int(x) for x in pred_set]
            match_count = len(set(pred_numbers) & set(actual_numbers))
            matches.append(match_count)
            
            matched_nums = sorted(list(set(pred_numbers) & set(actual_numbers)))
            missed_nums = sorted(list(set(actual_numbers) - set(pred_numbers)))
            extra_nums = sorted(list(set(pred_numbers) - set(actual_numbers)))
            
            detailed_analysis.append({
                'prediction': pred_numbers,
                'matches': match_count,
                'matched_numbers': matched_nums,
                'missed_numbers': missed_nums,
                'extra_numbers': extra_nums
            })
        
        avg_matches = np.mean(matches)
        max_matches = max(matches)
        
        print(f"å¹³å‡ä¸€è‡´æ•°: {avg_matches:.2f}å€‹")
        print(f"æœ€é«˜ä¸€è‡´æ•°: {max_matches}å€‹")
        
        # é«˜ç²¾åº¦äºˆæ¸¬ã®åˆ†æï¼ˆ3å€‹ä»¥ä¸Šä¸€è‡´ï¼‰
        high_accuracy = [analysis for analysis in detailed_analysis if analysis['matches'] >= 3]
        if high_accuracy:
            print(f"\nğŸ¯ é«˜ç²¾åº¦äºˆæ¸¬: {len(high_accuracy)}ã‚»ãƒƒãƒˆ")
            for i, analysis in enumerate(high_accuracy):
                idx = detailed_analysis.index(analysis) + 1
                print(f"  ã‚»ãƒƒãƒˆ{idx}: {analysis['matches']}å€‹ä¸€è‡´")
                print(f"    ä¸€è‡´ç•ªå·: {analysis['matched_numbers']}")
        
        # é »ç¹ã«è¦‹é€ƒã—ãŸç•ªå·ã®åˆ†æ
        all_missed = []
        for analysis in detailed_analysis:
            all_missed.extend(analysis['missed_numbers'])
        
        if all_missed:
            missed_freq = Counter(all_missed)
            print(f"\nâŒ é »ç¹ã«è¦‹é€ƒã—ãŸç•ªå·TOP5:")
            for num, count in missed_freq.most_common(5):
                print(f"    {num}ç•ª: {count}å›è¦‹é€ƒã—")
            
            # å­¦ç¿’æ”¹å–„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«åæ˜ 
            if not hasattr(self.auto_learner, 'improvement_metrics'):
                self.auto_learner.improvement_metrics = {}
            
            self.auto_learner.improvement_metrics['frequently_missed'] = missed_freq.most_common(10)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        actual_sum = sum(actual_numbers)
        actual_odd_count = sum(1 for n in actual_numbers if n % 2 == 1)
        actual_small_count = sum(1 for n in actual_numbers if n <= 15)
        
        print(f"\nğŸ“Š å½“é¸ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:")
        print(f"    åˆè¨ˆå€¤: {actual_sum}")
        print(f"    å¥‡æ•°å€‹æ•°: {actual_odd_count}å€‹")
        print(f"    å°æ•°å­—å€‹æ•°: {actual_small_count}å€‹")
        print(f"    ç¯„å›²: {min(actual_numbers)}-{max(actual_numbers)}")
        
        # é«˜ç²¾åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
        if high_accuracy:
            high_acc_predictions = [analysis['prediction'] for analysis in high_accuracy]
            pattern_analysis = self.analyze_successful_patterns(high_acc_predictions, actual_numbers)
            
            if not hasattr(self.auto_learner, 'improvement_metrics'):
                self.auto_learner.improvement_metrics = {}
            
            self.auto_learner.improvement_metrics['high_accuracy_patterns'] = pattern_analysis
    
    def analyze_successful_patterns(self, successful_predictions, actual_numbers):
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        if not successful_predictions:
            return {}
        
        sums = [sum(pred) for pred in successful_predictions]
        odd_counts = [sum(1 for n in pred if n % 2 == 1) for pred in successful_predictions]
        small_counts = [sum(1 for n in pred if n <= 15) for pred in successful_predictions]
        
        pattern_analysis = {
            'avg_sum': np.mean(sums),
            'avg_odd_count': np.mean(odd_counts),
            'avg_small_count': np.mean(small_counts),
            'sample_size': len(successful_predictions),
            'actual_sum': sum(actual_numbers),
            'actual_odd_count': sum(1 for n in actual_numbers if n % 2 == 1),
            'actual_small_count': sum(1 for n in actual_numbers if n <= 15)
        }
        
        print(f"\nğŸ’¡ æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’:")
        print(f"    ç†æƒ³çš„ãªåˆè¨ˆå€¤: {pattern_analysis['avg_sum']:.1f} (å®Ÿéš›: {pattern_analysis['actual_sum']})")
        print(f"    ç†æƒ³çš„ãªå¥‡æ•°å€‹æ•°: {pattern_analysis['avg_odd_count']:.1f} (å®Ÿéš›: {pattern_analysis['actual_odd_count']})")
        print(f"    ç†æƒ³çš„ãªå°æ•°å­—å€‹æ•°: {pattern_analysis['avg_small_count']:.1f} (å®Ÿéš›: {pattern_analysis['actual_small_count']})")
        
        return pattern_analysis
    
    def predict_with_learning(self, count=20, use_learning=True):
        """å­¦ç¿’æ”¹å–„ã‚’é©ç”¨ã—ãŸäºˆæ¸¬"""
        try:
            if not self.trained_models:
                print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãªã—")
                return []
            
            # å­¦ç¿’èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            if use_learning and hasattr(self.auto_learner, 'improvement_metrics'):
                adjustments = self.auto_learner.get_learning_adjustments()
                boost_numbers = adjustments.get('boost_numbers', [])
                pattern_targets = adjustments.get('pattern_targets', {})
                small_boost = adjustments.get('small_number_boost', 0)
                
                print(f"ğŸ’¡ å­¦ç¿’æ”¹å–„é©ç”¨: è¦‹é€ƒã—ãƒ–ãƒ¼ã‚¹ãƒˆ{len(boost_numbers)}å€‹, ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’æ¸ˆã¿")
            else:
                boost_numbers = []
                pattern_targets = {}
                small_boost = 0
            
            # åŸºæº–ç‰¹å¾´é‡ï¼ˆå­¦ç¿’æ”¹å–„ã‚’åæ˜ ï¼‰
            if pattern_targets:
                target_sum = pattern_targets.get('avg_sum', 80)
                target_odd = pattern_targets.get('avg_odd_count', 2.5)
                target_small = pattern_targets.get('avg_small_count', 2.5)
                base_features = [
                    target_sum / 5, 6.0, target_sum, target_odd, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, target_small
                ]
            else:
                base_features = [16.0, 6.0, 80.0, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5]
            
            predictions = []
            
            for i in range(count):
                # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’åé›†
                ensemble_votes = Counter()
                
                for name, model in self.trained_models.items():
                    try:
                        scaler = self.scalers[name]
                        X_scaled = scaler.transform([base_features])
                        
                        # è¤‡æ•°å›äºˆæ¸¬
                        for _ in range(8):
                            if hasattr(model, 'predict_proba'):
                                proba = model.predict_proba(X_scaled)[0]
                                classes = model.classes_
                                if len(classes) > 0:
                                    selected = np.random.choice(classes, p=proba/proba.sum())
                                    if 1 <= selected <= 31:
                                        weight = self.model_weights.get(name, 0.33)
                                        ensemble_votes[int(selected)] += weight
                            else:
                                pred = model.predict(X_scaled)[0]
                                if 1 <= pred <= 31:
                                    weight = self.model_weights.get(name, 0.33)
                                    ensemble_votes[int(pred)] += weight
                                    
                    except Exception as e:
                        continue
                
                # é »å‡ºæ•°å­—ã¨çµ„ã¿åˆã‚ã›
                frequent_nums = [num for num, _ in self.freq_counter.most_common(15)]
                for num in frequent_nums[:10]:
                    ensemble_votes[num] += 0.12
                
                # å­¦ç¿’æ”¹å–„ï¼šé »ç¹ã«è¦‹é€ƒã™æ•°å­—ã‚’ãƒ–ãƒ¼ã‚¹ãƒˆ
                for num in boost_numbers:
                    if 1 <= num <= 31:
                        ensemble_votes[num] += 0.25
                        if i == 0:  # æœ€åˆã®äºˆæ¸¬æ™‚ã®ã¿è¡¨ç¤º
                            print(f"  ğŸ’¡ {num}ç•ªã‚’ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆé »å‡ºè¦‹é€ƒã—ï¼‰")
                
                # å°æ•°å­—ãƒ–ãƒ¼ã‚¹ãƒˆ
                if small_boost > 2:
                    for num in range(1, 16):
                        ensemble_votes[num] += 0.05
                
                # ä¸Šä½5å€‹ã‚’é¸æŠ
                top_numbers = [num for num, _ in ensemble_votes.most_common(5)]
                
                # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ è£œå®Œ
                while len(top_numbers) < 5:
                    candidate = np.random.randint(1, 32)
                    if candidate not in top_numbers:
                        top_numbers.append(candidate)
                
                final_pred = sorted([int(x) for x in top_numbers[:5]])
                predictions.append(final_pred)
            
            return predictions
            
        except Exception as e:
            print(f"âŒ å­¦ç¿’æ”¹å–„äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []

# ========================= ãƒ‘ãƒ¼ãƒˆ3Bã“ã“ã¾ã§ =========================

# ========================= ãƒ‘ãƒ¼ãƒˆ4Cé–‹å§‹ =========================

# ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ 
final_system = MiniLotoFinalSystem()

# å®Œå…¨ç‰ˆå®Ÿè¡Œé–¢æ•°
def run_miniloto_final_prediction():
    """ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ"""
    try:
        print("\nğŸŒŸ ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œé–‹å§‹")
        
        # å®Œå…¨ç‰ˆäºˆæ¸¬å®Ÿè¡Œ
        predictions, next_info = final_system.run_complete_prediction()
        
        if predictions:
            print("\nğŸ‰ ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†!")
            return "SUCCESS"
        else:
            print("âŒ å®Œå…¨ç‰ˆäºˆæ¸¬å¤±æ•—")
            return "FAILED"
            
    except Exception as e:
        print(f"âŒ å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

def run_miniloto_health_check():
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
    try:
        print("\nğŸ” ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ")
        
        health = final_system.system_health_check()
        
        if health and health['overall']:
            print("\nâœ… ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: æ­£å¸¸")
            return "SUCCESS"
        else:
            print("\nâš ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: è¦æ³¨æ„")
            
            # è‡ªå‹•å›å¾©è©¦è¡Œ
            recovery = final_system.auto_recovery()
            if recovery:
                print("âœ… è‡ªå‹•å›å¾©æˆåŠŸ")
                return "SUCCESS"
            else:
                print("âŒ è‡ªå‹•å›å¾©å¤±æ•—")
                return "FAILED"
            
    except Exception as e:
        print(f"âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return "ERROR"

def run_miniloto_timeseries_validation_final():
    """å®Œå…¨ç‰ˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Ÿè¡Œ"""
    try:
        print("\nğŸ“Š ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Ÿè¡Œ")
        
        # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        if not final_system.data_fetcher.latest_data is None:
            data = final_system.data_fetcher.latest_data
        else:
            if not final_system.data_fetcher.fetch_latest_data():
                return "FAILED"
            data = final_system.data_fetcher.latest_data
        
        # ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œ
        from __main__ import MiniLotoTimeSeriesValidator
        validator = MiniLotoTimeSeriesValidator()
        
        # å›ºå®šçª“æ¤œè¨¼ï¼ˆ30, 50, 70å›åˆ†ï¼‰
        print("ğŸ”„ å›ºå®šçª“æ¤œè¨¼å®Ÿè¡Œä¸­...")
        fixed_results = validator.fixed_window_validation(data)
        
        # ç´¯ç©çª“æ¤œè¨¼
        print("ğŸ”„ ç´¯ç©çª“æ¤œè¨¼å®Ÿè¡Œä¸­...")
        expanding_results = validator.expanding_window_validation(data)
        
        # çµæœæ¯”è¼ƒ
        comparison = validator.compare_validation_methods()
        
        if comparison:
            print(f"\nâœ… æ™‚ç³»åˆ—æ¤œè¨¼å®Œäº†!")
            print(f"æœ€é©æ‰‹æ³•: {comparison['best_method']}")
            print(f"æ”¹å–„å¹…: {comparison['improvement']:.3f}")
            return "SUCCESS"
        else:
            return "FAILED"
            
    except Exception as e:
        print(f"âŒ æ™‚ç³»åˆ—æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        print(traceback.format_exc())
        return "ERROR"

def export_complete_system_data():
    """å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        print("\nğŸ’¾ å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ")
        
        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        prediction_json = final_system.persistence.export_to_json()
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        system_data = {
            'system_version': 'MiniLoto_Final_v1.0',
            'export_timestamp': datetime.now().isoformat(),
            'system_ready': final_system.system_ready,
            'model_count': len(final_system.trained_models),
            'data_count': final_system.data_count,
            'performance_metrics': final_system.performance_metrics,
            'last_error': final_system.last_error
        }
        
        if prediction_json:
            print(f"âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {len(prediction_json)}æ–‡å­—")
        
        system_json = json.dumps(system_data, ensure_ascii=False, indent=2)
        print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {len(system_json)}æ–‡å­—")
        
        return "SUCCESS"
        
    except Exception as e:
        print(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return "ERROR"

# æœ€çµ‚ç‰ˆçµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
def show_final_interface():
    """æœ€çµ‚ç‰ˆçµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¡¨ç¤º"""
    html_content = '''
    <div style="
        font-family: -apple-system, BlinkMacSystemFont, sans-serif;
        max-width: 1200px; 
        margin: 20px auto; 
        padding: 25px; 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px; 
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    ">
        <h1 style="text-align: center; margin-bottom: 10px; font-size: 28px;">
            ğŸŒŸ ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - å®Œå…¨ç‰ˆ
        </h1>
        <p style="text-align: center; font-size: 16px; margin-bottom: 25px; opacity: 0.9;">
            ğŸ¯ 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« | ğŸ§  è‡ªå‹•å­¦ç¿’ | ğŸ’¾ æ°¸ç¶šåŒ– | ğŸ“Š æ™‚ç³»åˆ—æ¤œè¨¼ | ğŸ”„ ç¶™ç¶šæ”¹å–„
        </p>
        
        <div style="background: rgba(255,255,255,0.1); border-radius: 10px; padding: 20px; margin-bottom: 25px; backdrop-filter: blur(10px);">
            <h3 style="margin-top: 0; color: #fff; font-size: 20px;">ğŸ‰ å®Œå…¨ç‰ˆã®ç‰¹å¾´</h3>
            <ul style="margin: 15px 0; font-size: 14px; line-height: 1.6;">
                <li><strong>æ°¸ç¶šåŒ–äºˆæ¸¬</strong>: ä¸€åº¦äºˆæ¸¬ã—ãŸã‚‰çµæœãŒå¤‰ã‚ã‚‰ãªã„å®‰å®šã‚·ã‚¹ãƒ†ãƒ </li>
                <li><strong>è‡ªå‹•çµæœç…§åˆ</strong>: æ–°ã—ã„å½“é¸ç•ªå·ã§è‡ªå‹•çš„ã«å‰å›äºˆæ¸¬ã‚’æ¤œè¨¼ãƒ»å­¦ç¿’</li>
                <li><strong>è¦‹é€ƒã—å­¦ç¿’</strong>: é »ç¹ã«è¦‹é€ƒã™ç•ªå·ã‚’ç‰¹å®šã—ã¦æ¬¡å›äºˆæ¸¬ã§ãƒ–ãƒ¼ã‚¹ãƒˆ</li>
                <li><strong>æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’</strong>: é«˜ç²¾åº¦äºˆæ¸¬ã®ç‰¹å¾´ã‚’åˆ†æã—ã¦åæ˜ </li>
                <li><strong>æ™‚ç³»åˆ—æ¤œè¨¼</strong>: 50å›åˆ†å›ºå®šçª“ã§æœ€é©ãªå­¦ç¿’æ–¹æ³•ã‚’æ¤œè¨¼</li>
                <li><strong>è‡ªå‹•å›å¾©æ©Ÿèƒ½</strong>: ã‚·ã‚¹ãƒ†ãƒ å•é¡Œã‚’è‡ªå‹•æ¤œå‡ºãƒ»ä¿®å¾©</li>
                <li><strong>è©³ç´°åˆ†æè¡¨ç¤º</strong>: å‰å›çµæœã®å®Œå…¨åˆ†æãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º</li>
            </ul>
        </div>
        
        <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; margin-bottom: 25px;">
            <!-- ãƒ¡ã‚¤ãƒ³äºˆæ¸¬æ©Ÿèƒ½ -->
            <div style="background: rgba(255,255,255,0.15); border-radius: 12px; padding: 25px;">
                <h3 style="margin-top: 0; color: #fff; font-size: 18px; display: flex; align-items: center;">
                    ğŸ¯ ãƒ¡ã‚¤ãƒ³äºˆæ¸¬æ©Ÿèƒ½
                </h3>
                <p style="font-size: 13px; margin: 15px 0; opacity: 0.9;">
                    âœ¨ æ°¸ç¶šåŒ–å¯¾å¿œ<br>
                    ğŸ¤– 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«<br>
                    ğŸ’¡ è‡ªå‹•å­¦ç¿’æ”¹å–„<br>
                    ğŸ“Š 14æ¬¡å…ƒç‰¹å¾´é‡
                </p>
                <button onclick="runFinalPrediction()" style="
                    width: 100%; 
                    padding: 18px; 
                    background: linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%); 
                    color: white; 
                    border: none; 
                    border-radius: 10px; 
                    font-size: 16px; 
                    cursor: pointer;
                    font-weight: bold;
                    transition: transform 0.2s;
                " onmouseover="this.style.transform='scale(1.05)'" onmouseout="this.style.transform='scale(1)'">
                    ğŸš€ å®Œå…¨ç‰ˆäºˆæ¸¬å®Ÿè¡Œ
                </button>
            </div>
            
            <!-- ã‚·ã‚¹ãƒ†ãƒ ç®¡ç† -->
            <div style="background: rgba(255,255,255,0.15); border-radius: 12px; padding: 25px;">
                <h3 style="margin-top: 0; color: #fff; font-size: 18px; display: flex; align-items: center;">
                    ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
                </h3>
                <p style="font-size: 13px; margin: 15px 0; opacity: 0.9;">
                    ğŸ” ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯<br>
                    ğŸ”„ è‡ªå‹•å›å¾©<br>
                    ğŸ“Š æ€§èƒ½ç›£è¦–<br>
                    ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†
                </p>
                <button onclick="runHealthCheck()" style="
                    width: 100%; 
                    padding: 18px; 
                    background: linear-gradient(135deg, #4ecdc4 0%, #44a08d 100%); 
                    color: white; 
                    border: none; 
                    border-radius: 10px; 
                    font-size: 16px; 
                    cursor: pointer;
                    font-weight: bold;
                    transition: transform 0.2s;
                " onmouseover="this.style.transform='scale(1.05)'" onmouseout="this.style.transform='scale(1)'">
                    ğŸ” ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
                </button>
            </div>
        </div>
        
        <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; margin-bottom: 25px;">
            <!-- æ™‚ç³»åˆ—æ¤œè¨¼ -->
            <div style="background: rgba(255,255,255,0.15); border-radius: 12px; padding: 25px;">
                <h3 style="margin-top: 0; color: #fff; font-size: 18px;">ğŸ“Š æ™‚ç³»åˆ—æ¤œè¨¼</h3>
                <p style="font-size: 13px; margin: 15px 0; opacity: 0.9;">
                    ğŸ”„ å›ºå®šçª“æ¤œè¨¼ï¼ˆ50å›åˆ†ï¼‰<br>
                    ğŸ“ˆ ç´¯ç©çª“æ¤œè¨¼<br>
                    âš–ï¸ æ‰‹æ³•æ¯”è¼ƒåˆ†æ<br>
                    ğŸ¯ æœ€é©åŒ–æ¨å¥¨
                </p>
                <button onclick="runTimeseriesValidation()" style="
                    width: 100%; 
                    padding: 15px; 
                    background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); 
                    color: #333; 
                    border: none; 
                    border-radius: 10px; 
                    font-size: 15px; 
                    cursor: pointer;
                    font-weight: bold;
                ">
                    ğŸ“Š æ¤œè¨¼å®Ÿè¡Œ
                </button>
            </div>
            
            <!-- ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ -->
            <div style="background: rgba(255,255,255,0.15); border-radius: 12px; padding: 25px;">
                <h3 style="margin-top: 0; color: #fff; font-size: 18px;">ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†</h3>
                <p style="font-size: 13px; margin: 15px 0; opacity: 0.9;">
                    ğŸ“ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ä¿å­˜<br>
                    ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ä¿å­˜<br>
                    ğŸ“Š æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹<br>
                    ğŸ“¤ JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                </p>
                <button onclick="exportSystemData()" style="
                    width: 100%; 
                    padding: 15px; 
                    background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); 
                    color: #333; 
                    border: none; 
                    border-radius: 10px; 
                    font-size: 15px; 
                    cursor: pointer;
                    font-weight: bold;
                ">
                    ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                </button>
            </div>
        </div>
        
        <div id="status" style="
            padding: 20px; 
            background: rgba(255,255,255,0.1); 
            border-radius: 10px; 
            margin: 15px 0;
            border-left: 4px solid #fff;
            display: none;
            backdrop-filter: blur(5px);
        "></div>
        
        <div style="background: rgba(255,255,255,0.1); border-radius: 10px; padding: 20px; margin-top: 25px;">
            <h4 style="margin-top: 0; color: #fff;">ğŸ¯ å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ã„æ–¹</h4>
            <div style="display: flex; align-items: center; justify-content: space-between; margin: 20px 0;">
                <div style="text-align: center; flex: 1;">
                    <div style="background: rgba(255,255,255,0.2); color: white; width: 45px; height: 45px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin: 0 auto 8px; font-size: 18px; font-weight: bold;">1</div>
                    <small style="font-size: 12px;"><strong>äºˆæ¸¬å®Ÿè¡Œ</strong><br>æ°¸ç¶šåŒ–å¯¾å¿œ<br>è‡ªå‹•å­¦ç¿’é©ç”¨</small>
                </div>
                <div style="flex: 0.3; text-align: center; font-size: 20px;">â†’</div>
                <div style="text-align: center; flex: 1;">
                    <div style="background: rgba(255,255,255,0.2); color: white; width: 45px; height: 45px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin: 0 auto 8px; font-size: 18px; font-weight: bold;">2</div>
                    <small style="font-size: 12px;"><strong>çµæœå…¬é–‹å¾…ã¡</strong><br>å½“é¸ç•ªå·ãŒ<br>å…¬é–‹ã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ</small>
                </div>
                <div style="flex: 0.3; text-align: center; font-size: 20px;">â†’</div>
                <div style="text-align: center; flex: 1;">
                    <div style="background: rgba(255,255,255,0.2); color: white; width: 45px; height: 45px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin: 0 auto 8px; font-size: 18px; font-weight: bold;">3</div>
                    <small style="font-size: 12px;"><strong>è‡ªå‹•å­¦ç¿’</strong><br>çµæœç…§åˆ<br>æ”¹å–„ç‚¹åæ˜ </small>
                </div>
                <div style="flex: 0.3; text-align: center; font-size: 20px;">â†’</div>
                <div style="text-align: center; flex: 1;">
                    <div style="background: rgba(255,255,255,0.2); color: white; width: 45px; height: 45px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin: 0 auto 8px; font-size: 18px; font-weight: bold;">4</div>
                    <small style="font-size: 12px;"><strong>ç¶™ç¶šæ”¹å–„</strong><br>å­¦ç¿’çµæœã‚’<br>æ¬¡å›äºˆæ¸¬ã«åæ˜ </small>
                </div>
            </div>
            <p style="font-size: 12px; color: rgba(255,255,255,0.8); margin: 15px 0 0; text-align: center;">
                âœ¨ <strong>å®Œå…¨è‡ªå‹•åŒ–</strong>: äºˆæ¸¬â†’ä¿å­˜â†’å­¦ç¿’â†’æ”¹å–„ã®ã‚µã‚¤ã‚¯ãƒ«ãŒå…¨è‡ªå‹•ã§å®Ÿè¡Œã•ã‚Œã¾ã™
            </p>
        </div>
        
        <div style="background: rgba(255,255,255,0.1); border-radius: 10px; padding: 20px; margin-top: 20px;">
            <h4 style="margin-top: 0; color: #fff;">ğŸŒŸ å®Œå…¨ç‰ˆã®é©æ–°çš„æ©Ÿèƒ½</h4>
            <ul style="margin: 15px 0; padding-left: 20px; font-size: 13px; line-height: 1.8;">
                <li><strong>äºˆæ¸¬æ°¸ç¶šåŒ–</strong>: ä¸€åº¦äºˆæ¸¬ã—ãŸã‚‰å†…å®¹ãŒå¤‰ã‚ã‚‰ãªã„ä¿¡é ¼æ€§</li>
                <li><strong>è‡ªå‹•çµæœç…§åˆ</strong>: æ–°ã—ã„å½“é¸ç•ªå·ã§éå»äºˆæ¸¬ã‚’è‡ªå‹•æ¤œè¨¼</li>
                <li><strong>è¦‹é€ƒã—ç•ªå·å­¦ç¿’</strong>: ã‚ˆãè¦‹é€ƒã™ç•ªå·ã‚’ç‰¹å®šã—ã¦æ¬¡å›ãƒ–ãƒ¼ã‚¹ãƒˆ</li>
                <li><strong>æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’</strong>: é«˜ç²¾åº¦äºˆæ¸¬ã®ç‰¹å¾´ã‚’æŠ½å‡ºãƒ»é©ç”¨</li>
                <li><strong>å°æ•°å­—é‡è¦åº¦å­¦ç¿’</strong>: 1-15ç•ªã®å‡ºç¾å‚¾å‘ã‚’å­¦ç¿’</li>
                <li><strong>ã‚·ã‚¹ãƒ†ãƒ è‡ªå‹•å›å¾©</strong>: å•é¡Œæ¤œå‡ºæ™‚ã®è‡ªå‹•ä¿®å¾©æ©Ÿèƒ½</li>
                <li><strong>å®Œå…¨åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</strong>: å‰å›çµæœã®è©³ç´°åˆ†æè¡¨ç¤º</li>
                <li><strong>æ™‚ç³»åˆ—æœ€é©åŒ–</strong>: 50å›åˆ†å›ºå®šçª“ã§ã®æœ€é©å­¦ç¿’</li>
            </ul>
        </div>
    </div>
    
    <script>
        async function runFinalPrediction() {
            const statusDiv = document.getElementById('status');
            
            statusDiv.style.display = 'block';
            statusDiv.innerHTML = 'ğŸŒŸ å®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œä¸­...';
            statusDiv.style.borderColor = '#ff6b6b';
            
            try {
                statusDiv.innerHTML = 'ğŸ” ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèªâ†’ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—â†’ğŸ§  å­¦ç¿’æ”¹å–„â†’ğŸ¯ äºˆæ¸¬ç”Ÿæˆâ†’ğŸ’¾ æ°¸ç¶šåŒ–ä¿å­˜<br><small style="opacity:0.8;">å®Œå…¨ç‰ˆå‡¦ç†ã®ãŸã‚ç´„2-3åˆ†ã‹ã‹ã‚Šã¾ã™</small>';
                
                const result = await google.colab.kernel.invokeFunction(
                    'run_miniloto_final_prediction', 
                    [], 
                    {}
                );
                
                if (result === 'SUCCESS') {
                    statusDiv.innerHTML = 'ğŸ‰ å®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†!<br><strong>ğŸ‘† ä¸Šéƒ¨ã®Pythonã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§å®Œå…¨ç‰ˆäºˆæ¸¬çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„</strong><br><small style="opacity:0.8;">æ°¸ç¶šåŒ–ä¿å­˜æ¸ˆã¿ãƒ»è‡ªå‹•å­¦ç¿’é©ç”¨æ¸ˆã¿</small>';
                } else {
                    statusDiv.innerHTML = 'âŒ å®Œå…¨ç‰ˆäºˆæ¸¬ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ';
                    statusDiv.style.background = 'rgba(255,255,255,0.1)';
                    statusDiv.style.borderColor = '#ff4757';
                }
                
            } catch (error) {
                statusDiv.innerHTML = 'âŒ ã‚¨ãƒ©ãƒ¼: ' + error.message;
                statusDiv.style.background = 'rgba(255,255,255,0.1)';
                statusDiv.style.borderColor = '#ff4757';
            }
        }
        
        async function runHealthCheck() {
            const statusDiv = document.getElementById('status');
            
            statusDiv.style.display = 'block';
            statusDiv.innerHTML = 'ğŸ” ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...';
            statusDiv.style.borderColor = '#4ecdc4';
            
            try {
                statusDiv.innerHTML = 'ğŸ”§ ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨â†’ğŸ¤– ãƒ¢ãƒ‡ãƒ«â†’ğŸ§  å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ â†’ğŸ’¾ æ°¸ç¶šåŒ–ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...<br><small style="opacity:0.8;">å•é¡Œæ¤œå‡ºæ™‚ã¯è‡ªå‹•å›å¾©ã‚’å®Ÿè¡Œã—ã¾ã™</small>';
                
                const result = await google.colab.kernel.invokeFunction(
                    'run_miniloto_health_check', 
                    [], 
                    {}
                );
                
                if (result === 'SUCCESS') {
                    statusDiv.innerHTML = 'âœ… ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: æ­£å¸¸<br><strong>ğŸ‘† ä¸Šéƒ¨ã®Pythonã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§è©³ç´°çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„</strong>';
                } else {
                    statusDiv.innerHTML = 'âš ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: è¦æ³¨æ„ï¼ˆè‡ªå‹•å›å¾©ã‚’è©¦è¡Œã—ã¾ã—ãŸï¼‰';
                    statusDiv.style.borderColor = '#ffa726';
                }
                
            } catch (error) {
                statusDiv.innerHTML = 'âŒ ã‚¨ãƒ©ãƒ¼: ' + error.message;
                statusDiv.style.background = 'rgba(255,255,255,0.1)';
                statusDiv.style.borderColor = '#ff4757';
            }
        }
        
        async function runTimeseriesValidation() {
            const statusDiv = document.getElementById('status');
            
            statusDiv.style.display = 'block';
            statusDiv.innerHTML = 'ğŸ“Š æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Ÿè¡Œä¸­...';
            statusDiv.style.borderColor = '#a8edea';
            
            try {
                statusDiv.innerHTML = 'ğŸ”„ å›ºå®šçª“æ¤œè¨¼ï¼ˆ50å›åˆ†ï¼‰â†’ğŸ“ˆ ç´¯ç©çª“æ¤œè¨¼â†’âš–ï¸ æ‰‹æ³•æ¯”è¼ƒåˆ†æä¸­...<br><small style="opacity:0.8;">å‡¦ç†æ™‚é–“: ç´„3-5åˆ†</small>';
                
                const result = await google.colab.kernel.invokeFunction(
                    'run_miniloto_timeseries_validation_final', 
                    [], 
                    {}
                );
                
                statusDiv.innerHTML = 'âœ… æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Œäº†!<br><strong>ğŸ‘† ä¸Šéƒ¨ã®Pythonã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§æ¤œè¨¼çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„</strong>';
                
            } catch (error) {
                statusDiv.innerHTML = 'âŒ ã‚¨ãƒ©ãƒ¼: ' + error.message;
                statusDiv.style.background = 'rgba(255,255,255,0.1)';
                statusDiv.style.borderColor = '#ff4757';
            }
        }
        
        async function exportSystemData() {
            const statusDiv = document.getElementById('status');
            
            statusDiv.style.display = 'block';
            statusDiv.innerHTML = 'ğŸ’¾ ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...';
            statusDiv.style.borderColor = '#ffecd2';
            
            try {
                statusDiv.innerHTML = 'ğŸ“ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿â†’ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹â†’ğŸ“Š æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...';
                
                const result = await google.colab.kernel.invokeFunction(
                    'export_complete_system_data', 
                    [], 
                    {}
                );
                
                statusDiv.innerHTML = 'âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†!<br>JSONå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ãŒæº–å‚™ã•ã‚Œã¾ã—ãŸ';
                
            } catch (error) {
                statusDiv.innerHTML = 'âŒ ã‚¨ãƒ©ãƒ¼: ' + error.message;
                statusDiv.style.background = 'rgba(255,255,255,0.1)';
                statusDiv.style.borderColor = '#ff4757';
            }
        }
    </script>'''
    
    return html_content

# ãƒ‘ãƒ¼ãƒˆ4æœ€çµ‚ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
print("\n" + "="*80)
print("ğŸ§ª ãƒ‘ãƒ¼ãƒˆ4: å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ æœ€çµ‚ãƒ†ã‚¹ãƒˆ")
print("="*80)

# å®Œå…¨ç‰ˆäºˆæ¸¬ãƒ†ã‚¹ãƒˆ
final_test_result = run_miniloto_final_prediction()
print(f"\nğŸ å®Œå…¨ç‰ˆäºˆæ¸¬ãƒ†ã‚¹ãƒˆçµæœ: {final_test_result}")

if final_test_result == "SUCCESS":
    print("âœ… å®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸å‹•ä½œ")
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    health_test_result = run_miniloto_health_check()
    print(f"\nğŸ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ: {health_test_result}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
    export_test_result = export_complete_system_data()
    print(f"\nğŸ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆçµæœ: {export_test_result}")
    
    if health_test_result == "SUCCESS" and export_test_result == "SUCCESS":
        print("\nğŸ‰ === ãƒ‘ãƒ¼ãƒˆ4å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ  å…¨æ©Ÿèƒ½å‹•ä½œç¢ºèªå®Œäº† ===")
        
        # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
        print(f"\nğŸ“Š ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ç‰ˆ æœ€çµ‚çµ±è¨ˆ:")
        print(f"  ã‚·ã‚¹ãƒ†ãƒ å: MiniLoto_Final_v1.0")
        print(f"  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {final_system.data_count}ä»¶")
        print(f"  ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒï¼ˆãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨æœ€é©åŒ–ï¼‰")
        print(f"  å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ•°: {len(final_system.trained_models)}å€‹")
        print(f"  æ°¸ç¶šåŒ–äºˆæ¸¬æ•°: {len(final_system.persistence.get_all_predictions())}ä»¶")
        print(f"  ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {'æ­£å¸¸' if final_system.system_ready else 'è¦æ³¨æ„'}")
        print(f"  è‡ªå‹•å­¦ç¿’: æœ‰åŠ¹")
        print(f"  æ°¸ç¶šåŒ–: æœ‰åŠ¹")
        print(f"  è‡ªå‹•å›å¾©: æœ‰åŠ¹")
        print(f"  æ™‚ç³»åˆ—æ¤œè¨¼: å¯¾å¿œ")
        
        print(f"\nğŸŒŸ å®Œå…¨ç‰ˆã®ä¸»è¦æ©Ÿèƒ½:")
        print(f"  âœ… 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆRF + GB + NNï¼‰")
        print(f"  âœ… 14æ¬¡å…ƒæœ€é©åŒ–ç‰¹å¾´é‡")
        print(f"  âœ… äºˆæ¸¬æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ")
        print(f"  âœ… è‡ªå‹•çµæœç…§åˆãƒ»å­¦ç¿’æ”¹å–„")
        print(f"  âœ… è¦‹é€ƒã—ç•ªå·ãƒ–ãƒ¼ã‚¹ãƒˆå­¦ç¿’")
        print(f"  âœ… æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’")
        print(f"  âœ… æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ï¼ˆ50å›åˆ†å›ºå®šçª“ï¼‰")
        print(f"  âœ… ã‚·ã‚¹ãƒ†ãƒ è‡ªå‹•å›å¾©æ©Ÿèƒ½")
        print(f"  âœ… å®Œå…¨åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print(f"  âœ… ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
        
    else:
        print("âš ï¸ ä¸€éƒ¨æ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€ãƒ¡ã‚¤ãƒ³äºˆæ¸¬æ©Ÿèƒ½ã¯æ­£å¸¸ã§ã™")
else:
    print("âŒ å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")

print("\n" + "="*80)
print("ğŸ¯ ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºå®Œäº†")
print("ğŸŒŸ ãƒ‘ãƒ¼ãƒˆ1: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ  âœ…")
print("ğŸŒŸ ãƒ‘ãƒ¼ãƒˆ2: é«˜åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  âœ…") 
print("ğŸŒŸ ãƒ‘ãƒ¼ãƒˆ3: è‡ªå‹•å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  âœ…")
print("ğŸŒŸ ãƒ‘ãƒ¼ãƒˆ4: çµ±åˆãƒ»å®Œæˆç‰ˆ âœ…")
print("="*80)

# æœ€çµ‚ç‰ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¡¨ç¤º
print("\nğŸ‰ === ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ç‰ˆ å®Œæˆ! ===")
print("ğŸ“± å®Œå…¨ç‰ˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’è¡¨ç¤ºã—ã¾ã™...")

# ãƒ‘ãƒ¼ãƒˆ4ã®é–¢æ•°ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ç™»éŒ²
import sys
current_module = sys.modules[__name__]

# å®Ÿè¡Œé–¢æ•°ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã«è¿½åŠ 
setattr(current_module, 'run_miniloto_final_prediction', run_miniloto_final_prediction)
setattr(current_module, 'run_miniloto_health_check', run_miniloto_health_check) 
setattr(current_module, 'run_miniloto_timeseries_validation_final', run_miniloto_timeseries_validation_final)
setattr(current_module, 'export_complete_system_data', export_complete_system_data)

# HTMLã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¡¨ç¤º
final_interface_html = show_final_interface()

print("\n" + "="*80)
print("ğŸ“± å®Œå…¨ç‰ˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’è¡¨ç¤ºä¸­...")
print("ğŸ‘† ä¸Šéƒ¨ã«è¡¨ç¤ºã•ã‚Œã‚‹å®Œå…¨ç‰ˆUIã‚’ã”åˆ©ç”¨ãã ã•ã„")
print("="*80)

# ========================= ãƒ‘ãƒ¼ãƒˆ4Cã“ã“ã¾ã§ =========================# ========================= ãƒ‘ãƒ¼ãƒˆ4Bé–‹å§‹ =========================

    def _check_and_apply_complete_learning(self, latest_data, current_round):
        """å®Œå…¨ç‰ˆå­¦ç¿’æ”¹å–„ãƒã‚§ãƒƒã‚¯ãƒ»é©ç”¨"""
        try:
            print("\nğŸ§  === å®Œå…¨ç‰ˆå­¦ç¿’æ”¹å–„ãƒã‚§ãƒƒã‚¯ ===")
            
            # å‰å›äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—
            previous_prediction = self.persistence.load_prediction(current_round)
            
            if not previous_prediction:
                print(f"ğŸ“Š ç¬¬{current_round}å›ã®äºˆæ¸¬è¨˜éŒ²ãªã—")
                return False
            
            if previous_prediction['verified']:
                print(f"âœ… ç¬¬{current_round}å›ã¯æ—¢ã«å­¦ç¿’é©ç”¨æ¸ˆã¿")
                return True
            
            # å½“é¸çµæœç¢ºèª
            main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
            round_col = 'é–‹å‚¬å›'
            
            matching_data = latest_data[latest_data[round_col] == current_round]
            
            if len(matching_data) == 0:
                print(f"ğŸ“Š ç¬¬{current_round}å›ã®å½“é¸çµæœæœªå…¬é–‹")
                return False
            
            # è©³ç´°å­¦ç¿’åˆ†æå®Ÿè¡Œ
            actual_row = matching_data.iloc[0]
            actual_numbers = [int(actual_row[col]) for col in main_cols if col in actual_row.index]
            
            if len(actual_numbers) == 5:
                print(f"ğŸ¯ ç¬¬{current_round}å›å­¦ç¿’åˆ†æå®Ÿè¡Œ: {actual_numbers}")
                
                # æ°¸ç¶šåŒ–æ›´æ–°
                self.persistence.update_with_actual_result(current_round, actual_numbers)
                
                # é«˜åº¦å­¦ç¿’åˆ†æ
                self._perform_advanced_learning_analysis(previous_prediction, actual_numbers, current_round)
                
                print(f"âœ… ç¬¬{current_round}å›å®Œå…¨å­¦ç¿’åˆ†æå®Œäº†")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ å®Œå…¨å­¦ç¿’ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _perform_advanced_learning_analysis(self, prediction_data, actual_numbers, round_number):
        """é«˜åº¦å­¦ç¿’åˆ†æå®Ÿè¡Œ"""
        try:
            print(f"\nğŸ”¬ === ç¬¬{round_number}å›é«˜åº¦å­¦ç¿’åˆ†æ ===")
            
            predictions = prediction_data['predictions']
            
            # è©³ç´°ä¸€è‡´åˆ†æ
            match_analysis = []
            for i, pred_set in enumerate(predictions):
                pred_numbers = [int(x) for x in pred_set]
                matched = set(pred_numbers) & set(actual_numbers)
                missed = set(actual_numbers) - set(pred_numbers)
                extra = set(pred_numbers) - set(actual_numbers)
                
                analysis = {
                    'index': i + 1,
                    'prediction': pred_numbers,
                    'matches': len(matched),
                    'matched_numbers': sorted(list(matched)),
                    'missed_numbers': sorted(list(missed)),
                    'extra_numbers': sorted(list(extra))
                }
                match_analysis.append(analysis)
            
            # çµ±è¨ˆè¨ˆç®—
            all_matches = [a['matches'] for a in match_analysis]
            avg_matches = np.mean(all_matches)
            max_matches = max(all_matches)
            
            print(f"å¹³å‡ä¸€è‡´æ•°: {avg_matches:.2f}å€‹ | æœ€é«˜ä¸€è‡´æ•°: {max_matches}å€‹")
            
            # é«˜ç²¾åº¦ã‚»ãƒƒãƒˆåˆ†æ
            high_accuracy = [a for a in match_analysis if a['matches'] >= 3]
            if high_accuracy:
                print(f"ğŸ¯ é«˜ç²¾åº¦ã‚»ãƒƒãƒˆ: {len(high_accuracy)}å€‹")
                for analysis in high_accuracy:
                    print(f"  ã‚»ãƒƒãƒˆ{analysis['index']}: {analysis['matches']}å€‹ä¸€è‡´ {analysis['matched_numbers']}")
                
                # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
                success_patterns = self._analyze_success_patterns(high_accuracy, actual_numbers)
                if success_patterns:
                    self.auto_learner.improvement_metrics['high_accuracy_patterns'] = success_patterns
            
            # è¦‹é€ƒã—åˆ†æ
            all_missed = []
            for analysis in match_analysis:
                all_missed.extend(analysis['missed_numbers'])
            
            if all_missed:
                missed_freq = Counter(all_missed)
                print(f"âŒ é »å‡ºè¦‹é€ƒã—ç•ªå·: {missed_freq.most_common(5)}")
                self.auto_learner.improvement_metrics['frequently_missed'] = missed_freq.most_common(10)
            
            # å½“é¸ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            self._analyze_winning_patterns(actual_numbers)
            
        except Exception as e:
            print(f"âŒ é«˜åº¦å­¦ç¿’åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _analyze_success_patterns(self, high_accuracy_sets, actual_numbers):
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ"""
        if not high_accuracy_sets:
            return None
        
        predictions = [s['prediction'] for s in high_accuracy_sets]
        
        # å„ç¨®çµ±è¨ˆ
        sums = [sum(pred) for pred in predictions]
        odd_counts = [sum(1 for n in pred if n % 2 == 1) for pred in predictions]
        small_counts = [sum(1 for n in pred if n <= 15) for pred in predictions]
        ranges = [max(pred) - min(pred) for pred in predictions]
        
        patterns = {
            'avg_sum': np.mean(sums),
            'avg_odd_count': np.mean(odd_counts),
            'avg_small_count': np.mean(small_counts),
            'avg_range': np.mean(ranges),
            'sample_size': len(predictions),
            'actual_sum': sum(actual_numbers),
            'actual_odd_count': sum(1 for n in actual_numbers if n % 2 == 1),
            'actual_small_count': sum(1 for n in actual_numbers if n <= 15),
            'actual_range': max(actual_numbers) - min(actual_numbers)
        }
        
        print(f"ğŸ’¡ æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’:")
        print(f"  ç†æƒ³åˆè¨ˆ: {patterns['avg_sum']:.1f} (å®Ÿéš›: {patterns['actual_sum']})")
        print(f"  ç†æƒ³å¥‡æ•°: {patterns['avg_odd_count']:.1f} (å®Ÿéš›: {patterns['actual_odd_count']})")
        print(f"  ç†æƒ³å°æ•°å­—: {patterns['avg_small_count']:.1f} (å®Ÿéš›: {patterns['actual_small_count']})")
        print(f"  ç†æƒ³ç¯„å›²: {patterns['avg_range']:.1f} (å®Ÿéš›: {patterns['actual_range']})")
        
        return patterns
    
    def _analyze_winning_patterns(self, actual_numbers):
        """å½“é¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        patterns = {
            'sum': sum(actual_numbers),
            'odd_count': sum(1 for n in actual_numbers if n % 2 == 1),
            'small_count': sum(1 for n in actual_numbers if n <= 15),
            'range': max(actual_numbers) - min(actual_numbers),
            'consecutive': self._count_consecutive_numbers(sorted(actual_numbers)),
            'decade_distribution': self._analyze_decade_distribution(actual_numbers)
        }
        
        print(f"ğŸ“Š å½“é¸ãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°:")
        print(f"  åˆè¨ˆ: {patterns['sum']} | å¥‡æ•°: {patterns['odd_count']}å€‹ | å°æ•°å­—: {patterns['small_count']}å€‹")
        print(f"  ç¯„å›²: {patterns['range']} | é€£ç¶š: {patterns['consecutive']}çµ„")
        print(f"  åã®ä½åˆ†å¸ƒ: {patterns['decade_distribution']}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«ä¿å­˜
        self.auto_learner.improvement_metrics['latest_winning_pattern'] = patterns
        
        return patterns
    
    def _count_consecutive_numbers(self, sorted_nums):
        """é€£ç¶šæ•°ã®çµ„ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        consecutive_groups = 0
        for i in range(len(sorted_nums) - 1):
            if sorted_nums[i+1] - sorted_nums[i] == 1:
                consecutive_groups += 1
        return consecutive_groups
    
    def _analyze_decade_distribution(self, numbers):
        """åã®ä½åˆ†å¸ƒåˆ†æ"""
        distribution = {'1-10': 0, '11-20': 0, '21-31': 0}
        for num in numbers:
            if 1 <= num <= 10:
                distribution['1-10'] += 1
            elif 11 <= num <= 20:
                distribution['11-20'] += 1
            elif 21 <= num <= 31:
                distribution['21-31'] += 1
        return distribution
    
    def _ensure_models_ready(self, data):
        """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æº–å‚™ç¢ºä¿"""
        try:
            if self.trained_models and len(self.trained_models) >= 2:
                print("âœ… æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
                return True
            
            print("ğŸ”§ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒå¿…è¦ã§ã™...")
            
            # ãƒ‘ãƒ¼ãƒˆ2ã®é«˜åº¦å­¦ç¿’ã‚’ä½¿ç”¨
            if hasattr(integrated_system, 'train_advanced_models'):
                success = integrated_system.train_advanced_models(data)
                if success:
                    # ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
                    self.trained_models = integrated_system.trained_models.copy()
                    self.scalers = integrated_system.scalers.copy()
                    self.model_scores = integrated_system.model_scores.copy()
                    return True
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¯ã‚¤ãƒƒã‚¯å­¦ç¿’
            return self._quick_model_training()
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _generate_complete_predictions(self, count=20, use_learning=True):
        """å®Œå…¨ç‰ˆäºˆæ¸¬ç”Ÿæˆ"""
        try:
            if not self.trained_models:
                print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãªã—")
                return []
            
            print(f"ğŸ¯ å®Œå…¨ç‰ˆäºˆæ¸¬ç”Ÿæˆé–‹å§‹ï¼ˆ{count}ã‚»ãƒƒãƒˆï¼‰")
            if use_learning:
                print("ğŸ’¡ å­¦ç¿’æ”¹å–„ã‚’é©ç”¨")
            
            # å­¦ç¿’èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
            boost_numbers = []
            pattern_targets = {}
            small_boost = 0
            
            if use_learning and hasattr(self.auto_learner, 'improvement_metrics'):
                adjustments = self.auto_learner.get_learning_adjustments()
                boost_numbers = adjustments.get('boost_numbers', [])
                pattern_targets = adjustments.get('pattern_targets', {})
                small_boost = adjustments.get('small_number_boost', 0)
            
            # åŸºæº–ç‰¹å¾´é‡ï¼ˆå­¦ç¿’æ”¹å–„åæ˜ ï¼‰
            if pattern_targets and use_learning:
                target_sum = pattern_targets.get('avg_sum', 80)
                target_odd = pattern_targets.get('avg_odd_count', 2.5)
                target_small = pattern_targets.get('avg_small_count', 2.5)
                base_features = [
                    target_sum / 5, 6.0, target_sum, target_odd, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, target_small
                ]
                print(f"ğŸ“Š å­¦ç¿’æ”¹å–„åŸºæº–: åˆè¨ˆ{target_sum:.0f}, å¥‡æ•°{target_odd:.1f}, å°æ•°å­—{target_small:.1f}")
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŸºæº–ç‰¹å¾´é‡
                if hasattr(self, 'pattern_stats') and self.pattern_stats:
                    avg_sum = self.pattern_stats.get('avg_sum', 80)
                    base_features = [avg_sum / 5, 6.0, avg_sum, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5]
                else:
                    base_features = [16.0, 6.0, 80.0, 2.5, 28.0, 5.0, 16.0, 23.0, 1.0, 8.0, 16.0, 24.0, 5.5, 2.5]
            
            predictions = []
            
            for i in range(count):
                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æŠ•ç¥¨
                ensemble_votes = Counter()
                
                # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬
                for name, model in self.trained_models.items():
                    try:
                        scaler = self.scalers[name]
                        X_scaled = scaler.transform([base_features])
                        
                        # è¤‡æ•°å›äºˆæ¸¬ã§å®‰å®šåŒ–
                        for _ in range(10):  # å®Œå…¨ç‰ˆã§ã¯å¤šã‚ã«äºˆæ¸¬
                            if hasattr(model, 'predict_proba'):
                                proba = model.predict_proba(X_scaled)[0]
                                classes = model.classes_
                                if len(classes) > 0:
                                    selected = np.random.choice(classes, p=proba/proba.sum())
                                    if 1 <= selected <= 31:
                                        weight = self.model_weights.get(name, 0.33)
                                        ensemble_votes[int(selected)] += weight
                            else:
                                pred = model.predict(X_scaled)[0]
                                if 1 <= pred <= 31:
                                    weight = self.model_weights.get(name, 0.33)
                                    ensemble_votes[int(pred)] += weight
                    except Exception as e:
                        continue
                
                # é »å‡ºæ•°å­—ãƒ–ãƒ¼ã‚¹ãƒˆ
                frequent_nums = [num for num, _ in self.freq_counter.most_common(15)]
                for num in frequent_nums[:10]:
                    ensemble_votes[num] += 0.15
                
                # å­¦ç¿’æ”¹å–„ãƒ–ãƒ¼ã‚¹ãƒˆ
                if use_learning:
                    # è¦‹é€ƒã—ç•ªå·ãƒ–ãƒ¼ã‚¹ãƒˆ
                    for num in boost_numbers:
                        if 1 <= num <= 31:
                            ensemble_votes[num] += 0.3
                    
                    # å°æ•°å­—ãƒ–ãƒ¼ã‚¹ãƒˆ
                    if small_boost > 2:
                        for num in range(1, 16):
                            ensemble_votes[num] += 0.08
                
                # ä¸Šä½5å€‹é¸æŠ
                top_numbers = [num for num, _ in ensemble_votes.most_common(5)]
                
                # ä¸è¶³åˆ†è£œå®Œ
                while len(top_numbers) < 5:
                    candidate = np.random.randint(1, 32)
                    if candidate not in top_numbers:
                        top_numbers.append(candidate)
                
                final_pred = sorted([int(x) for x in top_numbers[:5]])
                predictions.append(final_pred)
            
            print(f"âœ… å®Œå…¨ç‰ˆäºˆæ¸¬ç”Ÿæˆå®Œäº†: {len(predictions)}ã‚»ãƒƒãƒˆ")
            return predictions
            
        except Exception as e:
            print(f"âŒ å®Œå…¨ç‰ˆäºˆæ¸¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _create_complete_metadata(self, learning_applied):
        """å®Œå…¨ç‰ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        metadata = {
            'system_version': 'MiniLoto_Final_v1.0',
            'learning_applied': learning_applied,
            'model_count': len(self.trained_models),
            'feature_dimensions': 14,
            'data_count': self.data_count,
            'model_weights': self.model_weights.copy(),
            'model_scores': self.model_scores.copy(),
            'system_ready': self.system_ready,
            'generation_method': 'complete_ensemble',
            'boost_applied': learning_applied and hasattr(self.auto_learner, 'improvement_metrics')
        }
        
        if learning_applied and hasattr(self.auto_learner, 'improvement_metrics'):
            metadata['learning_metrics'] = self.auto_learner.improvement_metrics.copy()
        
        return metadata
    
    def _display_complete_existing_prediction(self, prediction_data, round_number):
        """å®Œå…¨ç‰ˆæ—¢å­˜äºˆæ¸¬è¡¨ç¤º"""
        print(f"\n" + "="*80)
        print(f"ğŸ“‚ ç¬¬{round_number}å› æ°¸ç¶šåŒ–æ¸ˆã¿äºˆæ¸¬")
        print("="*80)
        print(f"ğŸ“… ä½œæˆæ—¥æ™‚: {prediction_data['timestamp']}")
        print(f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ : {prediction_data['metadata'].get('system_version', 'Unknown')}")
        print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«æ•°: {prediction_data['metadata'].get('model_count', 'Unknown')}")
        
        if prediction_data['metadata'].get('learning_applied', False):
            print("ğŸ’¡ å­¦ç¿’æ”¹å–„é©ç”¨æ¸ˆã¿")
        
        if prediction_data['metadata'].get('boost_applied', False):
            print("ğŸš€ ãƒ–ãƒ¼ã‚¹ãƒˆæ©Ÿèƒ½é©ç”¨æ¸ˆã¿")
        
        print("-"*80)
        
        for i, pred in enumerate(prediction_data['predictions'], 1):
            clean_pred = [int(x) for x in pred]
            print(f"ç¬¬{round_number}å›äºˆæ¸¬ {i:2d}: {clean_pred}")
        
        # æ¤œè¨¼çµæœè¡¨ç¤º
        if prediction_data['verified'] and prediction_data['actual_result']:
            print(f"\nâœ… æ¤œè¨¼å®Œäº† - å½“é¸ç•ªå·: {prediction_data['actual_result']}")
            print("ğŸ“Š ä¸€è‡´çµæœ:")
            
            matches = prediction_data['matches']
            best_match = max(matches)
            avg_match = np.mean(matches)
            
            for i, match_count in enumerate(matches, 1):
                status = "ğŸ‰" if match_count >= 4 else "â­" if match_count >= 3 else "ğŸ“Š"
                print(f"  {status} äºˆæ¸¬{i:2d}: {match_count}å€‹ä¸€è‡´")
            
            print(f"\nğŸ“ˆ çµ±è¨ˆ: å¹³å‡{avg_match:.2f}å€‹ä¸€è‡´ | æœ€é«˜{best_match}å€‹ä¸€è‡´")
    
    def _display_complete_results(self, predictions, next_info, learning_applied):
        """å®Œå…¨ç‰ˆçµæœè¡¨ç¤º"""
        print(f"\n" + "="*80)
        print(f"ğŸŒŸ {next_info['prediction_target']} å®Œå…¨ç‰ˆäºˆæ¸¬çµæœ")
        print("ğŸ¯ 3ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« + 14æ¬¡å…ƒç‰¹å¾´é‡ + è‡ªå‹•å­¦ç¿’ + æ°¸ç¶šåŒ–")
        print("="*80)
        print(f"ğŸ“… äºˆæ¸¬æ—¥æ™‚: {next_info['current_date']}")
        print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: ç¬¬1å›ã€œç¬¬{next_info['latest_round']}å›ï¼ˆ{self.data_count}ä»¶ï¼‰")
        
        if learning_applied:
            print("ğŸ’¡ å­¦ç¿’æ”¹å–„æ©Ÿèƒ½: æœ‰åŠ¹")
        
        print("-"*80)
        
        for i, pred in enumerate(predictions, 1):
            clean_pred = [int(x) for x in pred]
            print(f"ç¬¬{next_info['next_round']}å›äºˆæ¸¬ {i:2d}: {clean_pred}")
        
        # ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½è¡¨ç¤º
        print(f"\n" + "="*80)
        print("ğŸ¤– ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½è©³ç´°")
        print("="*80)
        
        print(f"ãƒ¢ãƒ‡ãƒ«æ§‹æˆ:")
        for name, score in self.model_scores.items():
            weight = self.model_weights.get(name, 0)
            print(f"  {name:15s}: CVç²¾åº¦{score*100:5.2f}% | é‡ã¿{weight:.3f}")
        
        print(f"\nã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹:")
        print(f"  æº–å‚™çŠ¶æ…‹: {'âœ… æ­£å¸¸' if self.system_ready else 'âš ï¸ è¦æ³¨æ„'}")
        print(f"  æ°¸ç¶šåŒ–: âœ… æœ‰åŠ¹")
        print(f"  è‡ªå‹•å­¦ç¿’: {'âœ… æœ‰åŠ¹' if learning_applied else 'âš ï¸ ç„¡åŠ¹'}")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†æè¡¨ç¤º
        print(f"\n" + "="*80)
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœ")
        print("="*80)
        print(f"ç‰¹å¾´é‡æ¬¡å…ƒ: 14æ¬¡å…ƒï¼ˆãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨æœ€é©åŒ–ç‰ˆï¼‰")
        
        if hasattr(self, 'pattern_stats') and self.pattern_stats:
            print(f"ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ: å¹³å‡åˆè¨ˆ{self.pattern_stats.get('avg_sum', 0):.1f}")
        
        print(f"\nğŸ”¥ é »å‡ºæ•°å­—TOP10:")
        top_frequent = self.freq_counter.most_common(10)
        for i, (num, count) in enumerate(top_frequent):
            if i % 5 == 0:
                print("")
            print(f"{int(num)}ç•ª({int(count)}å›)", end="  ")
        
        # å­¦ç¿’æ”¹å–„æƒ…å ±è¡¨ç¤º
        if learning_applied and hasattr(self.auto_learner, 'improvement_metrics'):
            self._display_complete_learning_info()
    
    def _display_complete_learning_info(self):
        """å®Œå…¨ç‰ˆå­¦ç¿’æ”¹å–„æƒ…å ±è¡¨ç¤º"""
        print(f"\n\nğŸ’¡ === å­¦ç¿’æ”¹å–„è©³ç´°æƒ…å ± ===")
        
        metrics = self.auto_learner.improvement_metrics
        
        if 'frequently_missed' in metrics:
            print("ğŸ¯ è¦‹é€ƒã—é »åº¦é«˜æ•°å­—ï¼ˆå¼·åŒ–ãƒ–ãƒ¼ã‚¹ãƒˆå¯¾è±¡ï¼‰:")
            for num, count in metrics['frequently_missed'][:5]:
                print(f"    {num}ç•ª: {count}å›è¦‹é€ƒã— â†’ +30%ãƒ–ãƒ¼ã‚¹ãƒˆ")
        
        if 'high_accuracy_patterns' in metrics:
            patterns = metrics['high_accuracy_patterns']
            print(f"ğŸ“Š é«˜ç²¾åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’é©ç”¨:")
            print(f"    ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆè¨ˆå€¤: {patterns['avg_sum']:.1f}")
            print(f"    ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¥‡æ•°å€‹æ•°: {patterns['avg_odd_count']:.1f}")
            print(f"    ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå°æ•°å­—å€‹æ•°: {patterns['avg_small_count']:.1f}")
            print(f"    å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«: {patterns['sample_size']}ä»¶ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³")
        
        if 'small_number_importance' in metrics:
            importance = metrics['small_number_importance']
            print(f"ğŸ”¢ å°æ•°å­—é‡è¦åº¦å­¦ç¿’: {importance:.1f}å€‹")
            print(f"    1-15ç•ªã«+8%ãƒ–ãƒ¼ã‚¹ãƒˆé©ç”¨")
        
        if 'latest_winning_pattern' in metrics:
            pattern = metrics['latest_winning_pattern']
            print(f"ğŸ“ˆ æœ€æ–°å½“é¸ãƒ‘ã‚¿ãƒ¼ãƒ³å‚è€ƒ:")
            print(f"    åˆè¨ˆ{pattern['sum']} | å¥‡æ•°{pattern['odd_count']}å€‹ | ç¯„å›²{pattern['range']}")
    
    def _display_complete_previous_analysis(self, latest_data, current_round):
        """å®Œå…¨ç‰ˆå‰å›çµæœåˆ†æè¡¨ç¤º"""
        previous_prediction = self.persistence.load_prediction(current_round)
        
        if not previous_prediction or not previous_prediction['verified']:
            return
        
        print(f"\n" + "="*80)
        print(f"ğŸ“Š ç¬¬{current_round}å› å®Œå…¨çµæœåˆ†æ")
        print("="*80)
        
        actual_numbers = previous_prediction['actual_result']
        matches = previous_prediction['matches']
        metadata = previous_prediction.get('metadata', {})
        
        print(f"ğŸ¯ å½“é¸ç•ªå·: {actual_numbers}")
        print(f"ğŸ“… äºˆæ¸¬æ—¥æ™‚: {previous_prediction['timestamp']}")
        print(f"ğŸ¤– ä½¿ç”¨ã‚·ã‚¹ãƒ†ãƒ : {metadata.get('system_version', 'Unknown')}")
        
        if metadata.get('learning_applied', False):
            print("ğŸ’¡ å­¦ç¿’æ”¹å–„: é©ç”¨æ¸ˆã¿")
        
        print(f"\nğŸ“ˆ è©³ç´°äºˆæ¸¬çµæœ:")
        print("-"*50)
        
        # è©³ç´°çµæœè¡¨ç¤º
        match_3_plus = 0
        match_4_plus = 0
        
        for i, (pred, match_count) in enumerate(zip(previous_prediction['predictions'], matches), 1):
            pred_numbers = [int(x) for x in pred]
            matched_nums = sorted(list(set(pred_numbers) & set(actual_numbers)))
            
            if match_count >= 3:
                match_3_plus += 1
            if match_count >= 4:
                match_4_plus += 1
            
            if match_count >= 4:
                status = "ğŸ‰ å®Œå…¨çš„ä¸­ç´š"
            elif match_count >= 3:
                status = "â­ é«˜ç²¾åº¦"
            elif match_count >= 2:
                status = "ğŸ“Š ä¸­ç²¾åº¦"
            else:
                status = "ğŸ“Š åŸºæœ¬"
            
            print(f"{status} äºˆæ¸¬{i:2d}: {pred_numbers} â†’ {match_count}å€‹ä¸€è‡´ {matched_nums}")
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        avg_matches = np.mean(matches)
        max_matches = max(matches)
        
        print("-"*50)
        print(f"ğŸ“Š å®Œå…¨çµ±è¨ˆã‚µãƒãƒªãƒ¼:")
        print(f"    å¹³å‡ä¸€è‡´æ•°: {avg_matches:.2f}å€‹")
        print(f"    æœ€é«˜ä¸€è‡´æ•°: {max_matches}å€‹")
        print(f"    3å€‹ä»¥ä¸Šä¸€è‡´: {match_3_plus}ã‚»ãƒƒãƒˆ")
        print(f"    4å€‹ä»¥ä¸Šä¸€è‡´: {match_4_plus}ã‚»ãƒƒãƒˆ")
        print(f"    äºˆæ¸¬ç²¾åº¦: {(avg_matches/5)*100:.1f}%")
        
        # å­¦ç¿’ã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœ
        if metadata.get('learning_applied', False):
            print(f"ğŸ’¡ å­¦ç¿’æ”¹å–„åŠ¹æœ: è¦‹é€ƒã—ãƒ–ãƒ¼ã‚¹ãƒˆãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’é©ç”¨æ¸ˆã¿")
    
    def _update_performance_metrics(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
        try:
            all_predictions = self.persistence.get_all_predictions()
            verified_predictions = [p for p in all_predictions.values() if p['verified']]
            
            if verified_predictions:
                all_matches = []
                for pred in verified_predictions:
                    all_matches.extend(pred['matches'])
                
                self.performance_metrics = {
                    'total_predictions': len(all_predictions),
                    'verified_predictions': len(verified_predictions),
                    'avg_accuracy': np.mean(all_matches),
                    'max_accuracy': max(all_matches),
                    'high_accuracy_rate': sum(1 for m in all_matches if m >= 3) / len(all_matches),
                    'last_updated': datetime.now().isoformat()
                }
        except Exception as e:
            print(f"âš ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

# ========================= ãƒ‘ãƒ¼ãƒˆ4Bã“ã“ã¾ã§ =========================# ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  ãƒ‘ãƒ¼ãƒˆ4: çµ±åˆãƒ»å®Œæˆç‰ˆ
# ========================= ãƒ‘ãƒ¼ãƒˆ4Aé–‹å§‹ =========================

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from collections import Counter, defaultdict
import json
import traceback
from datetime import datetime

print("ğŸš€ ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‘ãƒ¼ãƒˆ4: çµ±åˆãƒ»å®Œæˆç‰ˆ")
print("ğŸ‰ å…¨æ©Ÿèƒ½çµ±åˆ + æœ€çµ‚ç‰ˆUI + ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")
print("ğŸŒ å®Œå…¨ç‰ˆãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ")

# æœ€çµ‚ç‰ˆçµ±åˆã‚¯ãƒ©ã‚¹
class MiniLotoFinalSystem:
    """ãƒŸãƒ‹ãƒ­ãƒˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æœ€çµ‚ç‰ˆ - å…¨æ©Ÿèƒ½çµ±åˆ"""
    def __init__(self):
        print("ğŸ”§ MiniLotoFinalSystemåˆæœŸåŒ–ä¸­...")
        
        # ä»–ã®ãƒ‘ãƒ¼ãƒˆã‹ã‚‰ç¶™æ‰¿
        from __main__ import integrated_system
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨
        self.data_fetcher = integrated_system.data_fetcher
        
        # ãƒ¢ãƒ‡ãƒ«é–¢é€£
        self.models = integrated_system.models
        self.scalers = integrated_system.scalers
        self.model_weights = integrated_system.model_weights.copy()
        self.trained_models = integrated_system.trained_models
        self.model_scores = integrated_system.model_scores
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†æ
        self.freq_counter = integrated_system.freq_counter
        self.pair_freq = integrated_system.pair_freq
        self.pattern_stats = integrated_system.pattern_stats
        self.data_count = integrated_system.data_count
        
        # é«˜åº¦æ©Ÿèƒ½
        self.auto_learner = integrated_system.auto_learner
        self.persistence = integrated_system.persistence
        self.validator = None
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        self.system_ready = False
        self.last_error = None
        self.performance_metrics = {}
        
        print("âœ… æœ€çµ‚ç‰ˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def system_health_check(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            print("\nğŸ” === ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ ===")
            
            health_status = {
                'data_fetcher': False,
                'models': False,
                'learning': False,
                'persistence': False,
                'overall': False
            }
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨ãƒã‚§ãƒƒã‚¯
            try:
                if hasattr(self.data_fetcher, 'latest_data') and self.data_fetcher.latest_data is not None:
                    health_status['data_fetcher'] = True
                    print("âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨: æ­£å¸¸")
                else:
                    print("âš ï¸ ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨: ãƒ‡ãƒ¼ã‚¿æœªå–å¾—")
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å™¨: ã‚¨ãƒ©ãƒ¼ - {e}")
            
            # ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯
            try:
                if self.trained_models and len(self.trained_models) >= 2:
                    health_status['models'] = True
                    print(f"âœ… ãƒ¢ãƒ‡ãƒ«: æ­£å¸¸ ({len(self.trained_models)}å€‹)")
                else:
                    print("âš ï¸ ãƒ¢ãƒ‡ãƒ«: æœªå­¦ç¿’")
            except Exception as e:
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«: ã‚¨ãƒ©ãƒ¼ - {e}")
            
            # å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯
            try:
                if hasattr(self.auto_learner, 'improvement_metrics'):
                    health_status['learning'] = True
                    print("âœ… å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ : æ­£å¸¸")
                else:
                    print("âš ï¸ å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ : æœªåˆæœŸåŒ–")
            except Exception as e:
                print(f"âŒ å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ : ã‚¨ãƒ©ãƒ¼ - {e}")
            
            # æ°¸ç¶šåŒ–ãƒã‚§ãƒƒã‚¯
            try:
                if hasattr(self.persistence, 'memory_storage'):
                    health_status['persistence'] = True
                    predictions_count = len(self.persistence.get_all_predictions())
                    print(f"âœ… æ°¸ç¶šåŒ–: æ­£å¸¸ ({predictions_count}ä»¶ä¿å­˜)")
                else:
                    print("âš ï¸ æ°¸ç¶šåŒ–: æœªåˆæœŸåŒ–")
            except Exception as e:
                print(f"âŒ æ°¸ç¶šåŒ–: ã‚¨ãƒ©ãƒ¼ - {e}")
            
            # ç·åˆåˆ¤å®š
            working_components = sum(health_status.values())
            if working_components >= 3:
                health_status['overall'] = True
                self.system_ready = True
                print(f"\nğŸ‰ ã‚·ã‚¹ãƒ†ãƒ ç·åˆçŠ¶æ…‹: æ­£å¸¸ ({working_components}/4)")
            else:
                print(f"\nâš ï¸ ã‚·ã‚¹ãƒ†ãƒ ç·åˆçŠ¶æ…‹: è¦æ³¨æ„ ({working_components}/4)")
            
            return health_status
            
        except Exception as e:
            print(f"âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            self.last_error = str(e)
            return None
    
    def auto_recovery(self):
        """è‡ªå‹•å›å¾©å‡¦ç†"""
        try:
            print("\nğŸ”§ === è‡ªå‹•å›å¾©å‡¦ç†é–‹å§‹ ===")
            
            recovery_success = False
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å›å¾©
            if not hasattr(self.data_fetcher, 'latest_data') or self.data_fetcher.latest_data is None:
                print("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å›å¾©ã‚’è©¦è¡Œ...")
                if self.data_fetcher.fetch_latest_data():
                    print("âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å›å¾©æˆåŠŸ")
                    recovery_success = True
                else:
                    print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å›å¾©å¤±æ•—")
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å›å¾©
            if not self.trained_models and hasattr(self.data_fetcher, 'latest_data'):
                print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å›å¾©ã‚’è©¦è¡Œ...")
                try:
                    # ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                    success = self._quick_model_training()
                    if success:
                        print("âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å›å¾©æˆåŠŸ")
                        recovery_success = True
                    else:
                        print("âŒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å›å¾©å¤±æ•—")
                except Exception as e:
                    print(f"âŒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å›å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            
            if recovery_success:
                print("\nğŸ‰ è‡ªå‹•å›å¾©å‡¦ç†å®Œäº†")
                self.system_ready = True
            else:
                print("\nâš ï¸ è‡ªå‹•å›å¾©å‡¦ç†ã§ä¸€éƒ¨å•é¡ŒãŒæ®‹ã£ã¦ã„ã¾ã™")
            
            return recovery_success
            
        except Exception as e:
            print(f"âŒ è‡ªå‹•å›å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            self.last_error = str(e)
            return False
    
    def _quick_model_training(self):
        """ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        try:
            if not hasattr(self.data_fetcher, 'latest_data') or self.data_fetcher.latest_data is None:
                return False
            
            # åŸºæœ¬çš„ãª2ãƒ¢ãƒ‡ãƒ«ã®ã¿ã§é«˜é€Ÿå­¦ç¿’
            quick_models = {
                'random_forest': RandomForestClassifier(
                    n_estimators=50, max_depth=8, random_state=42, n_jobs=-1
                ),
                'gradient_boost': GradientBoostingClassifier(
                    n_estimators=40, max_depth=4, random_state=42
                )
            }
            
            # ç°¡æ˜“ç‰¹å¾´é‡ä½œæˆ
            X, y = self._create_simple_features(self.data_fetcher.latest_data)
            if X is None or len(X) < 50:
                return False
            
            # å­¦ç¿’å®Ÿè¡Œ
            for name, model in quick_models.items():
                try:
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    self.scalers[name] = scaler
                    
                    model.fit(X_scaled, y)
                    cv_score = np.mean(cross_val_score(model, X_scaled, y, cv=2))
                    
                    self.trained_models[name] = model
                    self.model_scores[name] = cv_score
                    
                except Exception as e:
                    continue
            
            if self.trained_models:
                self.model_weights = {
                    'random_forest': 0.6,
                    'gradient_boost': 0.4
                }
                return True
            
            return False
            
        except Exception as e:
            return False
    
    def _create_simple_features(self, data):
        """ç°¡æ˜“ç‰¹å¾´é‡ä½œæˆï¼ˆå›å¾©ç”¨ï¼‰"""
        try:
            features = []
            targets = []
            main_cols = ['ç¬¬1æ•°å­—', 'ç¬¬2æ•°å­—', 'ç¬¬3æ•°å­—', 'ç¬¬4æ•°å­—', 'ç¬¬5æ•°å­—']
            
            for i in range(min(len(data), 500)):  # åŠ¹ç‡åŒ–ã®ãŸã‚500ä»¶ã¾ã§
                try:
                    current = []
                    for col in main_cols:
                        if col in data.columns:
                            current.append(int(data.iloc[i][col]))
                    
                    if len(current) != 5 or not all(1 <= x <= 31 for x in current) or len(set(current)) != 5:
                        continue
                    
                    # ç°¡æ˜“8æ¬¡å…ƒç‰¹å¾´é‡
                    feat = [
                        float(np.mean(current)),           # å¹³å‡å€¤
                        float(np.std(current)),            # æ¨™æº–åå·®
                        float(np.sum(current)),            # åˆè¨ˆå€¤
                        float(sum(1 for x in current if x % 2 == 1)),  # å¥‡æ•°å€‹æ•°
                        float(max(current)),               # æœ€å¤§å€¤
                        float(min(current)),               # æœ€å°å€¤
                        float(max(current) - min(current)), # ç¯„å›²
                        float(len([x for x in current if x <= 15])), # å°æ•°å­—æ•°
                    ]
                    
                    # æ¬¡å›äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                    if i < len(data) - 1:
                        next_nums = []
                        for col in main_cols:
                            if col in data.columns:
                                next_nums.append(int(data.iloc[i+1][col]))
                        
                        if len(next_nums) == 5:
                            for target_num in next_nums:
                                features.append(feat.copy())
                                targets.append(target_num)
                        
                except Exception as e:
                    continue
            
            return np.array(features), np.array(targets)
            
        except Exception as e:
            return None, None
    
    def run_complete_prediction(self, force_new=False):
        """å®Œå…¨ç‰ˆäºˆæ¸¬å®Ÿè¡Œ"""
        try:
            print("\n" + "="*80)
            print("ğŸŒŸ ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ")
            print("="*80)
            
            # 1. ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            health = self.system_health_check()
            if not health or not health['overall']:
                print("\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ å•é¡Œã‚’æ¤œå‡ºã€‚è‡ªå‹•å›å¾©ã‚’å®Ÿè¡Œ...")
                recovery_success = self.auto_recovery()
                if not recovery_success:
                    print("âŒ è‡ªå‹•å›å¾©å¤±æ•—ã€‚æ‰‹å‹•å¯¾å¿œãŒå¿…è¦ã§ã™ã€‚")
                    return [], {}
            
            # 2. ãƒ‡ãƒ¼ã‚¿ç¢ºèªãƒ»å–å¾—
            if not hasattr(self.data_fetcher, 'latest_data') or self.data_fetcher.latest_data is None:
                print("ğŸ“Š æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
                if not self.data_fetcher.fetch_latest_data():
                    print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                    return [], {}
            
            latest_data = self.data_fetcher.latest_data
            latest_round = self.data_fetcher.latest_round
            next_round = latest_round + 1
            next_info = self.data_fetcher.get_next_round_info()
            
            print(f"ğŸ“Š æœ€æ–°ãƒ‡ãƒ¼ã‚¿: ç¬¬{latest_round}å›ã¾ã§ï¼ˆ{len(latest_data)}ä»¶ï¼‰")
            print(f"ğŸ¯ äºˆæ¸¬å¯¾è±¡: ç¬¬{next_round}å›")
            
            # 3. æ°¸ç¶šåŒ–ãƒã‚§ãƒƒã‚¯
            if not force_new and self.persistence.is_prediction_exists(next_round):
                print(f"\nğŸ“‚ ç¬¬{next_round}å›ã®äºˆæ¸¬ã¯æ—¢ã«æ°¸ç¶šåŒ–ã•ã‚Œã¦ã„ã¾ã™")
                existing_prediction = self.persistence.load_prediction(next_round)
                
                self._display_complete_existing_prediction(existing_prediction, next_round)
                self._display_complete_previous_analysis(latest_data, latest_round)
                
                return existing_prediction['predictions'], next_info
            
            # 4. æ–°è¦äºˆæ¸¬ç”Ÿæˆ
            print(f"\nğŸ†• ç¬¬{next_round}å›ã®æ–°è¦äºˆæ¸¬ã‚’ç”Ÿæˆã—ã¾ã™")
            
            # 5. å­¦ç¿’æ”¹å–„ãƒã‚§ãƒƒã‚¯
            learning_applied = self._check_and_apply_complete_learning(latest_data, latest_round)
            
            # 6. æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ç¢ºä¿
            if not self._ensure_models_ready(latest_data):
                print("âŒ ãƒ¢ãƒ‡ãƒ«æº–å‚™å¤±æ•—")
                return [], {}
            
            # 7. å®Œå…¨ç‰ˆäºˆæ¸¬ç”Ÿæˆ
            predictions = self._generate_complete_predictions(20, learning_applied)
            if not predictions:
                print("âŒ äºˆæ¸¬ç”Ÿæˆå¤±æ•—")
                return [], {}
            
            # 8. æ°¸ç¶šåŒ–ä¿å­˜
            metadata = self._create_complete_metadata(learning_applied)
            self.persistence.save_prediction_permanently(next_round, predictions, metadata)
            
            # 9. å®Œå…¨ç‰ˆçµæœè¡¨ç¤º
            self._display_complete_results(predictions, next_info, learning_applied)
            
            # 10. å‰å›çµæœåˆ†æè¡¨ç¤º
            self._display_complete_previous_analysis(latest_data, latest_round)
            
            # 11. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°
            self._update_performance_metrics()
            
            print("\n" + "="*80)
            print("ğŸ‰ ãƒŸãƒ‹ãƒ­ãƒˆå®Œå…¨ç‰ˆäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†!")
            print(f"ğŸ“ ç¬¬{next_round}å›äºˆæ¸¬ã¨ã—ã¦æ°¸ç¶šåŒ–ä¿å­˜æ¸ˆã¿")
            print("ğŸ”„ æ¬¡å›å®Ÿè¡Œæ™‚ã¯ä¿å­˜æ¸ˆã¿äºˆæ¸¬ã‚’è¡¨ç¤ºã—ã¾ã™")
            print("="*80)
            
            return predictions, next_info
            
        except Exception as e:
            print(f"âŒ å®Œå…¨ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            print(f"è©³ç´°: {traceback.format_exc()}")
            self.last_error = str(e)
            return [], {}

# ========================= ãƒ‘ãƒ¼ãƒˆ4Aã“ã“ã¾ã§ =========================