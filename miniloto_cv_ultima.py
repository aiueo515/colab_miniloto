# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part1: åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ 
# æ”¹ä¿®ç‰ˆ: æ®µéšçš„ä¿å­˜ãƒ»ç¶™ç¶šå®Ÿè¡Œãƒ»ã‚¹ã‚³ã‚¢é †å®Ÿè¡Œå¯¾å¿œ

import pandas as pd
import numpy as np
import os
import pickle
import time
import traceback
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, log_loss
from sklearn.multioutput import MultiOutputClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.base import clone
import json


# ======================================================================
# 1. æ®µéšçš„æ™‚ç³»åˆ—CVä¿å­˜ã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================

class IncrementalTimeSeriesCV:
    def __init__(self, save_interval=10):
        self.save_interval = save_interval  # 10ä»¶ã”ã¨ã«ä¿å­˜
        self.cv_dir = "miniloto_models/cv_results"
        self.models_dir = "miniloto_models/models"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.cv_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)
        
        # Google Driveé€£æº
        try:
            from google.colab import drive
            self.drive_available = True
            self.drive_cv_dir = "/content/drive/MyDrive/miniloto_models/cv_results"
            self.drive_models_dir = "/content/drive/MyDrive/miniloto_models/models"
            os.makedirs(self.drive_cv_dir, exist_ok=True)
            os.makedirs(self.drive_models_dir, exist_ok=True)
        except ImportError:
            self.drive_available = False

    def check_drive_mount_status(self):
        """Driveãƒã‚¦ãƒ³ãƒˆçŠ¶æ…‹ã®æ­£ç¢ºãªç¢ºèªï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            print("ğŸ” Driveèªè¨¼ãƒ»ãƒã‚¦ãƒ³ãƒˆçŠ¶æ…‹ã®è©³ç´°ç¢ºèª...")
            
            # Step 1: /content/drive ã®å­˜åœ¨ç¢ºèª
            drive_path = '/content/drive'
            mydrive_path = '/content/drive/MyDrive'
            
            print(f"ğŸ“ {drive_path} å­˜åœ¨: {'âœ…' if os.path.exists(drive_path) else 'âŒ'}")
            print(f"ğŸ“ {mydrive_path} å­˜åœ¨: {'âœ…' if os.path.exists(mydrive_path) else 'âŒ'}")
            
            if not os.path.exists(mydrive_path):
                print("âŒ MyDriveãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False
            
            # Step 2: MyDriveãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ç¢ºèª
            try:
                items = os.listdir(mydrive_path)
                print(f"ğŸ“‚ MyDriveå†…ã®ã‚¢ã‚¤ãƒ†ãƒ æ•°: {len(items)}")
                
                # å†…å®¹ã‚’å°‘ã—è¡¨ç¤ºï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ã¦æœ€åˆã®3å€‹ã¾ã§ï¼‰
                if items:
                    print(f"ğŸ“‹ å†…å®¹ä¾‹: {items[:3]}")
                
                # Step 3: å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
                print("ğŸ” å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
                
                # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ»å‰Šé™¤ãƒ†ã‚¹ãƒˆ
                test_file_path = os.path.join(mydrive_path, 'test_mount_check.tmp')
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ
                    with open(test_file_path, 'w') as f:
                        f.write('test')
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
                    with open(test_file_path, 'r') as f:
                        content = f.read()
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    os.remove(test_file_path)
                    
                    if content == 'test':
                        print("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ: æˆåŠŸ")
                        return True
                    else:
                        print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ: èª­ã¿æ›¸ãä¸æ•´åˆ")
                        return False
                        
                except PermissionError as e:
                    print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ: æ¨©é™ã‚¨ãƒ©ãƒ¼ ({e})")
                    return False
                except Exception as e:
                    print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ: ã‚¨ãƒ©ãƒ¼ ({e})")
                    return False
                
            except PermissionError as e:
                print(f"âŒ MyDriveã‚¢ã‚¯ã‚»ã‚¹: æ¨©é™ã‚¨ãƒ©ãƒ¼ ({e})")
                return False
            except Exception as e:
                print(f"âŒ MyDriveã‚¢ã‚¯ã‚»ã‚¹: ã‚¨ãƒ©ãƒ¼ ({e})")
                return False
                
        except Exception as e:
            print(f"âŒ ãƒã‚¦ãƒ³ãƒˆçŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return False

    

    def debug_find_features_file(self):
        """ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©³ç´°æ¤œç´¢ã—ã¦ãƒ‘ã‚¹ã‚’ç‰¹å®š"""
        import os
        
        print("ğŸ” ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°æ¤œç´¢ãƒ‡ãƒãƒƒã‚°")
        print("=" * 50)
        
        # 1. åŸºæœ¬ãƒ‘ã‚¹ç¢ºèª
        print("ğŸ“‚ åŸºæœ¬ãƒ‘ã‚¹ç¢ºèª:")
        base_paths = [
            "/content/drive/MyDrive/",
            "/content/drive/MyDrive/miniloto_predictor_ultra/",
            "/content/drive/MyDrive/miniloto_models/",
        ]
        
        for base_path in base_paths:
            exists = os.path.exists(base_path)
            print(f"  {base_path}: {'âœ…' if exists else 'âŒ'}")
            
            if exists:
                try:
                    contents = os.listdir(base_path)
                    miniloto_items = [item for item in contents if 'miniloto' in item.lower()]
                    print(f"    ãƒŸãƒ‹ãƒ­ãƒˆé–¢é€£: {miniloto_items}")
                except Exception as e:
                    print(f"    ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 2. ç¾åœ¨è©¦ã—ã¦ã„ã‚‹ãƒ‘ã‚¹ç¢ºèª
        print(f"\nğŸ“ ç¾åœ¨è©¦ã—ã¦ã„ã‚‹ãƒ‘ã‚¹:")
        current_paths = [
            "/content/drive/MyDrive/miniloto_predictor_ultra/miniloto_models/features/features_cache.pkl",
            "/content/drive/MyDrive/miniloto_models/features/features_cache.pkl",
        ]
        
        for path in current_paths:
            exists = os.path.exists(path)
            print(f"  {path}")
            print(f"    å­˜åœ¨: {'âœ…' if exists else 'âŒ'}")
            
            # æ®µéšçš„ã«ãƒ‘ã‚¹ã‚’ç¢ºèª
            path_parts = path.split('/')
            for i in range(3, len(path_parts)):
                partial_path = '/'.join(path_parts[:i+1])
                partial_exists = os.path.exists(partial_path)
                print(f"    {partial_path}: {'âœ…' if partial_exists else 'âŒ'}")
                if not partial_exists:
                    break
        
        # 3. features_cache.pklãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢
        print(f"\nğŸ” features_cache.pklå†å¸°æ¤œç´¢:")
        search_roots = [
            "/content/drive/MyDrive/",
        ]
        
        found_files = []
        for root_path in search_roots:
            if os.path.exists(root_path):
                for root, dirs, files in os.walk(root_path):
                    for file in files:
                        if file == "features_cache.pkl":
                            full_path = os.path.join(root, file)
                            found_files.append(full_path)
                            print(f"  âœ… ç™ºè¦‹: {full_path}")
        
        if found_files:
            print(f"\nğŸ‰ {len(found_files)}å€‹ã®features_cache.pklãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹!")
            return found_files
        else:
            print(f"\nğŸ˜¥ features_cache.pklãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return []
    

    def force_mount_drive(self):
        """CVç”¨Driveå¼·åˆ¶ãƒã‚¦ãƒ³ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            from google.colab import drive
            import os
            from datetime import datetime
            
            print("ğŸ”§ CVç”¨Driveå¼·åˆ¶ãƒã‚¦ãƒ³ãƒˆé–‹å§‹...")
            
            # Step 1: ç¾åœ¨ã®çŠ¶æ…‹ç¢ºèª
            mount_status = self.check_drive_mount_status()
            print(f"ğŸ“Š ç¾åœ¨ã®ãƒã‚¦ãƒ³ãƒˆçŠ¶æ…‹: {'âœ…ãƒã‚¦ãƒ³ãƒˆæ¸ˆã¿' if mount_status else 'âŒæœªãƒã‚¦ãƒ³ãƒˆ'}")
            
            if mount_status:
                print("âœ… Drive ã¯æ­£å¸¸ã«ãƒã‚¦ãƒ³ãƒˆæ¸ˆã¿ã§ã™")
                return True
            
            # Step 2: æ—¢å­˜ã®driveãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‡¦ç†
            if os.path.exists('/content/drive'):
                print("ğŸ”§ æ—¢å­˜ã®driveãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†ä¸­...")
                
                # æ—¢å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ç§»å‹•
                backup_name = f'/content/drive_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
                try:
                    os.rename('/content/drive', backup_name)
                    print(f"ğŸ“¦ æ—¢å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ {backup_name} ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
                except Exception as e:
                    print(f"âš ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
                    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ãŸå ´åˆã¯å‰Šé™¤ã‚’è©¦è¡Œ
                    try:
                        import shutil
                        shutil.rmtree('/content/drive')
                        print("ğŸ—‘ï¸ æ—¢å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤")
                    except Exception as e2:
                        print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤ã‚‚å¤±æ•—: {e2}")
                        print("ğŸ”„ æ‰‹å‹•ã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
                        return False
            
            # Step 3: æ–°è¦ãƒã‚¦ãƒ³ãƒˆå®Ÿè¡Œ
            print("ğŸ” Drive èªè¨¼ã¨ãƒã‚¦ãƒ³ãƒˆã‚’å®Ÿè¡Œ...")
            print("ğŸ“± ãƒ–ãƒ©ã‚¦ã‚¶ã§èªè¨¼ç”»é¢ãŒé–‹ãã¾ã™ã€‚Google ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
            
            try:
                drive.mount('/content/drive', force_remount=True)
                print("âœ… ãƒã‚¦ãƒ³ãƒˆã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå®Œäº†")
            except Exception as e:
                print(f"âŒ ãƒã‚¦ãƒ³ãƒˆã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                return False
            
            # Step 4: ãƒã‚¦ãƒ³ãƒˆæˆåŠŸç¢ºèª
            final_status = self.check_drive_mount_status()
            
            if final_status:
                print("ğŸ‰ Drive ãƒã‚¦ãƒ³ãƒˆæˆåŠŸ!")
                
                # ãƒŸãƒ‹ãƒ­ãƒˆé–¢é€£ãƒ•ã‚©ãƒ«ãƒ€ç¢ºèª
                try:
                    items = os.listdir('/content/drive/MyDrive')
                    miniloto_items = [item for item in items if 'miniloto' in item.lower()]
                    
                    if miniloto_items:
                        print(f"ğŸ“ ãƒŸãƒ‹ãƒ­ãƒˆé–¢é€£ãƒ•ã‚©ãƒ«ãƒ€: {miniloto_items}")
                    else:
                        print("âš ï¸ ãƒŸãƒ‹ãƒ­ãƒˆé–¢é€£ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        print("ğŸ’¡ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ãã ã•ã„")
                except Exception as e:
                    print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
                
                return True
            else:
                print("âŒ Drive ãƒã‚¦ãƒ³ãƒˆå¾Œã‚‚æ­£å¸¸ã«èªè­˜ã•ã‚Œã¾ã›ã‚“")
                print("ğŸ”„ æ‰‹å‹•ã§ãƒã‚¦ãƒ³ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                return False
                
        except ImportError:
            print("âŒ Google Colabç’°å¢ƒã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            return False
        except Exception as e:
            print(f"âŒ Drive ãƒã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def load_features_for_cv(self):
        """CVç”¨ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆyå½¢çŠ¶ä¿®æ­£ç‰ˆï¼‰"""
        try:
            print(f"ğŸ“‚ ç¾åœ¨ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
            
            # Step 1: Drive ãƒã‚¦ãƒ³ãƒˆç¢ºèªãƒ»å®Ÿè¡Œ
            if not self.force_mount_drive():
                print("âŒ Drive ãƒã‚¦ãƒ³ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None, None
            
            # Step 2: main_v4ã®å®Ÿéš›ã®ä¿å­˜å…ˆã«åˆã‚ã›ãŸæ¤œç´¢ãƒ‘ã‚¹ï¼ˆå„ªå…ˆé †ä¿®æ­£ï¼‰
            search_files = [
                # â˜…â˜…â˜… main_v4ã®å®Ÿéš›ã®ä¿å­˜ãƒ‘ã‚¹ï¼ˆæœ€å„ªå…ˆï¼‰â˜…â˜…â˜…
                "/content/drive/MyDrive/miniloto_models/features/features_cache.pkl",
                
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ï¼ˆmain_v4æº–æ‹ ï¼‰
                "miniloto_models/features/features_cache.pkl",
                
                # å¾“æ¥ã®æ¤œç´¢ãƒ‘ã‚¹ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
                "/content/drive/MyDrive/miniloto_predictor_ultra/miniloto_models/features/features_cache.pkl",
                "/content/drive/MyDrive/miniloto_predictor_ultra/features/features_cache.pkl",
                "/content/drive/MyDrive/features/features_cache.pkl",
            ]
            
            print("\nğŸ” ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ï¼ˆmain_v4æº–æ‹ ãƒ‘ã‚¹å„ªå…ˆï¼‰:")
            
            # å†å¸°æ¤œç´¢ã‚‚è¿½åŠ 
            found_files = []
            
            # ã¾ãšå›ºå®šãƒ‘ã‚¹ã‚’ç¢ºèª
            for i, file_path in enumerate(search_files, 1):
                print(f"  {i}. è©¦è¡Œ: {file_path}")
                if os.path.exists(file_path):
                    abs_path = os.path.abspath(file_path)
                    if abs_path not in found_files:
                        found_files.append(abs_path)
                    print(f"     âœ… å­˜åœ¨ã—ã¾ã™")
                else:
                    print(f"     âŒ å­˜åœ¨ã—ã¾ã›ã‚“")
            
            # å†å¸°æ¤œç´¢ï¼ˆå¿µã®ãŸã‚ï¼‰
            print("\nğŸ” å†å¸°æ¤œç´¢å®Ÿè¡Œ:")
            search_roots = [
                "/content/drive/MyDrive/miniloto_models",  # main_v4ã®å®Ÿéš›ã®ä¿å­˜å…ˆ
                "/content/drive/MyDrive/miniloto_predictor_ultra",
                "/content/drive/MyDrive"
            ]
            
            for search_root in search_roots:
                if os.path.exists(search_root):
                    print(f"  æ¤œç´¢ä¸­: {search_root}")
                    try:
                        for root, dirs, files in os.walk(search_root):
                            if "features_cache.pkl" in files:
                                full_path = os.path.join(root, "features_cache.pkl")
                                if full_path not in found_files:
                                    found_files.append(full_path)
                                print(f"    âœ… ç™ºè¦‹: {full_path}")
                    except Exception as e:
                        print(f"    âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            
            # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            if not found_files:
                print("âŒ ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                print("ğŸ”§ å…ˆã«ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆrun_ultra_maximum_precision_predictionï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
                return None, None
            
            print(f"\nğŸ“– {len(found_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿è©¦è¡Œ:")
            
            for i, file_path in enumerate(found_files, 1):
                print(f"\n  {i}. èª­ã¿è¾¼ã¿è©¦è¡Œ: {file_path}")
                
                try:
                    with open(file_path, 'rb') as f:
                        features_data = pickle.load(f)
                    
                    X = features_data["X"]
                    y = features_data["y"]
                    
                    # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ç¢ºèªãƒ»ä¿®æ­£
                    print(f"    ğŸ“Š èª­ã¿è¾¼ã¿æˆåŠŸ! X: {X.shape}, y: {y.shape}")
                    
                    # ===== yã®å½¢çŠ¶ç¢ºèªãƒ»ä¿®æ­£ï¼ˆãƒŸãƒ‹ãƒ­ãƒˆç”¨ï¼‰=====
                    if hasattr(y, 'ndim'):
                        if y.ndim == 1:
                            print(f"    âš ï¸ yãŒ1æ¬¡å…ƒã§ã™: {y.shape}")
                            print(f"    ğŸ”§ ãƒŸãƒ‹ãƒ­ãƒˆç”¨31æ¬¡å…ƒãƒã‚¤ãƒŠãƒªãƒ©ãƒ™ãƒ«ã«å¤‰æ›ä¸­...")
                            
                            # 1æ¬¡å…ƒã®å ´åˆã€æ­£ã—ã„å½¢çŠ¶ã«å¤‰æ›ã§ããªã„ãŸã‚è­¦å‘Š
                            print(f"    âŒ 1æ¬¡å…ƒã®yã¯31æ¬¡å…ƒãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã«å¤‰æ›ä¸å¯")
                            print(f"    ğŸ’¡ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ç‰¹å¾´é‡ã‚’å†ç”Ÿæˆã—ã¦ãã ã•ã„")
                            print(f"    ğŸ”§ run_ultra_maximum_precision_prediction() ã‚’å®Ÿè¡Œ")
                            return None, None
                            
                        elif y.ndim == 2:
                            if y.shape[1] == 31:
                                print(f"    âœ… æ­£ã—ã„å½¢çŠ¶: {y.shape} (31æ¬¡å…ƒãƒãƒ«ãƒãƒ©ãƒ™ãƒ«)")
                            elif y.shape[1] == 1:
                                print(f"    âš ï¸ yãŒ2æ¬¡å…ƒã ãŒåˆ—æ•°ãŒ1: {y.shape}")
                                print(f"    âŒ 31æ¬¡å…ƒãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                                print(f"    ğŸ’¡ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ç‰¹å¾´é‡ã‚’å†ç”Ÿæˆã—ã¦ãã ã•ã„")
                                return None, None
                            else:
                                print(f"    âš ï¸ äºˆæœŸã—ãªã„å½¢çŠ¶: {y.shape}")
                                print(f"    âŒ ãƒŸãƒ‹ãƒ­ãƒˆç”¨31æ¬¡å…ƒã¨ä¸€è‡´ã—ã¾ã›ã‚“")
                                print(f"    ğŸ’¡ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ç‰¹å¾´é‡ã‚’å†ç”Ÿæˆã—ã¦ãã ã•ã„")
                                return None, None
                        else:
                            print(f"    âŒ äºˆæœŸã—ãªã„æ¬¡å…ƒæ•°: {y.ndim}æ¬¡å…ƒ")
                            print(f"    ğŸ’¡ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ç‰¹å¾´é‡ã‚’å†ç”Ÿæˆã—ã¦ãã ã•ã„")
                            return None, None
                    else:
                        print(f"    âŒ yã«ndimå±æ€§ãŒã‚ã‚Šã¾ã›ã‚“")
                        print(f"    ğŸ’¡ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ç‰¹å¾´é‡ã‚’å†ç”Ÿæˆã—ã¦ãã ã•ã„")
                        return None, None
                    
                    # ãƒ¡ã‚¿æƒ…å ±
                    feature_version = features_data.get("feature_version", "unknown")
                    timestamp = features_data.get("timestamp", "unknown")
                    print(f"    ğŸ“Š ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {feature_version}")
                    print(f"    ğŸ•’ ä½œæˆæ—¥æ™‚: {timestamp}")
                    print(f"    ğŸ’¾ ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
                    print(f"    âœ… CVç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: X{X.shape}, y{y.shape}")
                    
                    return X, y
                    
                except Exception as e:
                    print(f"    âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            print("âŒ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None, None
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            print(f"è©³ç´°: {traceback.format_exc()}")
            return None, None

    def debug_path_investigation(self):
        """ãƒ‘ã‚¹å•é¡Œã®è©³ç´°èª¿æŸ»"""
        try:
            print("ğŸ” === ãƒ‘ã‚¹å•é¡Œè©³ç´°èª¿æŸ» ===")
            
            # main_v4ã®å®Ÿéš›ã®ä¿å­˜å…ˆç¢ºèª
            main_v4_paths = [
                "/content/drive/MyDrive/miniloto_models/features/features_cache.pkl",
                "/content/miniloto_models/features/features_cache.pkl"
            ]
            
            print("ğŸ“ main_v4æº–æ‹ ãƒ‘ã‚¹ç¢ºèª:")
            for path in main_v4_paths:
                exists = os.path.exists(path)
                print(f"  {path}")
                print(f"    å­˜åœ¨: {'âœ…' if exists else 'âŒ'}")
                
                if exists:
                    try:
                        size = os.path.getsize(path)
                        mtime = datetime.fromtimestamp(os.path.getmtime(path))
                        print(f"    ã‚µã‚¤ã‚º: {size:,} bytes")
                        print(f"    æ›´æ–°: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
                    except Exception as e:
                        print(f"    è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
            print("\nğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª:")
            check_dirs = [
                "/content/drive/MyDrive/miniloto_models",
                "/content/drive/MyDrive/miniloto_predictor_ultra",
                "/content/miniloto_models"
            ]
            
            for check_dir in check_dirs:
                print(f"\n  {check_dir}:")
                if os.path.exists(check_dir):
                    try:
                        items = os.listdir(check_dir)
                        print(f"    âœ… å­˜åœ¨ ({len(items)}å€‹ã®ã‚¢ã‚¤ãƒ†ãƒ )")
                        for item in items:
                            item_path = os.path.join(check_dir, item)
                            if os.path.isdir(item_path):
                                print(f"      ğŸ“ {item}/")
                            else:
                                print(f"      ğŸ“„ {item}")
                    except Exception as e:
                        print(f"    âŒ ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    print(f"    âŒ å­˜åœ¨ã—ã¾ã›ã‚“")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‘ã‚¹èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def continue_cv_from_checkpoint(self, model_name):
        """ä¸­æ–­ç‚¹ã‹ã‚‰CVç¶™ç¶šï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""
        try:
            # ç‰¹å¾´é‡ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ãƒã‚§ãƒƒã‚¯
            is_compatible, start_split, current_results = self.check_feature_version_compatibility(model_name)
            
            if is_compatible and start_split > 0:
                print(f"ğŸ”„ {model_name} ç¶™ç¶šå®Ÿè¡Œ: {start_split}ä»¶ç›®ã‹ã‚‰å†é–‹")
                return start_split, current_results
            else:
                print(f"ğŸ†• {model_name} æ–°è¦CVé–‹å§‹")
                return 0, []
                
        except Exception as e:
            print(f"âš ï¸ {model_name} é€²æ—èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return 0, []

    

    def save_cv_progress(self, model_name, current_results, completed_splits, total_splits):
        """CVé€²æ—ä¿å­˜ï¼ˆç‰¹å¾´é‡ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä»˜ãï¼‰"""
        try:
            current_version = self._calculate_feature_version()
            
            progress_data = {
                'model_name': model_name,
                'current_results': current_results,
                'completed_splits': completed_splits,
                'total_splits': total_splits,
                'timestamp': datetime.now(),
                'completion_rate': completed_splits / total_splits if total_splits > 0 else 0,
                'feature_version': current_version  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¿½åŠ 
            }
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
            progress_file = os.path.join(self.cv_dir, f"{model_name}_cv_progress.pkl")
            with open(progress_file, 'wb') as f:
                pickle.dump(progress_data, f)
            
            # Driveä¿å­˜
            if self.drive_available:
                drive_progress_file = os.path.join(self.drive_cv_dir, f"{model_name}_cv_progress.pkl")
                try:
                    with open(drive_progress_file, 'wb') as f:
                        pickle.dump(progress_data, f)
                except Exception as e:
                    print(f"âš ï¸ Driveä¿å­˜å¤±æ•—: {e}")
            
            print(f"ğŸ’¾ {model_name} é€²æ—ä¿å­˜: {completed_splits}/{total_splits} ({progress_data['completion_rate']*100:.1f}%) v{current_version}")
            return True
            
        except Exception as e:
            print(f"âŒ {model_name} é€²æ—ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    
    def update_model_with_cv_results(self, model_name, enhanced_model_data):
        """CVçµæœã§ãƒ¢ãƒ‡ãƒ«æ›´æ–°"""
        try:
            # å…ƒã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            original_model_file = os.path.join(self.models_dir, f"{model_name}.pkl")
            
            if not os.path.exists(original_model_file):
                print(f"âŒ {model_name} å…ƒãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            with open(original_model_file, 'rb') as f:
                original_data = pickle.load(f)
            
            # CVçµæœã§å¼·åŒ–
            enhanced_data = original_data.copy()
            enhanced_data.update({
                'cv_enhanced': True,
                'cv_score': enhanced_model_data.get('cv_score', 0),
                'cv_std': enhanced_model_data.get('cv_std', 0),
                'cv_results': enhanced_model_data.get('cv_results', []),
                'enhanced_model': enhanced_model_data.get('model', original_data['model']),
                'enhanced_scaler': enhanced_model_data.get('scaler', original_data['scaler']),
                'enhancement_timestamp': datetime.now()
            })
            
            # å¼·åŒ–ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            enhanced_file = os.path.join(self.models_dir, f"{model_name}_cv_enhanced.pkl")
            with open(enhanced_file, 'wb') as f:
                pickle.dump(enhanced_data, f)
            
            # Driveä¿å­˜
            if self.drive_available:
                drive_enhanced_file = os.path.join(self.drive_models_dir, f"{model_name}_cv_enhanced.pkl")
                try:
                    with open(drive_enhanced_file, 'wb') as f:
                        pickle.dump(enhanced_data, f)
                except Exception as e:
                    print(f"âš ï¸ Driveä¿å­˜å¤±æ•—: {e}")
            
            cv_score = enhanced_model_data.get('cv_score', 0)
            print(f"âœ… {model_name} CVå¼·åŒ–å®Œäº† (CVã‚¹ã‚³ã‚¢: {cv_score:.4f})")
            return True
            
        except Exception as e:
            print(f"âŒ {model_name} ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_available_models_for_cv(self):
        """CVå®Ÿè¡Œç”¨ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            models_data = {}

            models_dir_to_use = self.drive_models_dir if self.drive_available else self.models_dir
            
            # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            for filename in os.listdir(models_dir_to_use):
                if filename.endswith('.pkl') and not filename.endswith('_cv_enhanced.pkl'):
                    model_name = filename.replace('.pkl', '')
                    model_file = os.path.join(models_dir_to_use, filename)
                    
                    try:
                        with open(model_file, 'rb') as f:
                            model_data = pickle.load(f)
                        
                        models_data[model_name] = {
                            'model': model_data['model'],
                            'scaler': model_data['scaler'],
                            'score': model_data['score'],
                            'model_type': model_data.get('model_type', 'classification')
                        }
                        
                    except Exception as e:
                        print(f"âš ï¸ {model_name} èª­ã¿è¾¼ã¿ã‚¹ã‚­ãƒƒãƒ—: {e}")
                        continue
            
            print(f"ğŸ“¥ CVç”¨ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {len(models_data)}å€‹")
            return models_data
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _calculate_feature_version(self):
        """ç‰¹å¾´é‡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨ˆç®—ï¼ˆãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰"""
        try:
            import hashlib
            # ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´æ™‚åˆ»ãƒ™ãƒ¼ã‚¹ã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¨ˆç®—
            features_file = "miniloto_models/features/features_cache.pkl"
            if os.path.exists(features_file):
                mtime = os.path.getmtime(features_file)
                version_string = str(mtime)
                return hashlib.md5(version_string.encode()).hexdigest()[:8]
            else:
                return "unknown"
        except:
            return "unknown"

    def check_feature_version_compatibility(self, model_name):
        """ç‰¹å¾´é‡ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            current_version = self._calculate_feature_version()
            
            # é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¿å­˜æ¸ˆã¿ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèª
            progress_file = os.path.join(self.cv_dir, f"{model_name}_cv_progress.pkl")
            
            if os.path.exists(progress_file):
                with open(progress_file, 'rb') as f:
                    progress_data = pickle.load(f)
                
                saved_version = progress_data.get('feature_version', 'unknown')
                
                if saved_version != current_version:
                    print(f"âš ï¸ {model_name} ç‰¹å¾´é‡ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´")
                    print(f"    ä¿å­˜æ¸ˆã¿: {saved_version}")
                    print(f"    ç¾åœ¨: {current_version}")
                    
                    # å¤ã„é€²æ—ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ç§»å‹•
                    backup_file = progress_file.replace('.pkl', f'_v{saved_version}.pkl.bak')
                    os.rename(progress_file, backup_file)
                    print(f"    ğŸ“¦ å¤ã„é€²æ—ã‚’ {backup_file} ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
                    
                    return False, 0, []  # æ–°è¦é–‹å§‹
                else:
                    print(f"âœ… {model_name} ç‰¹å¾´é‡ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸€è‡´: {current_version}")
                    return True, progress_data.get('completed_splits', 0), progress_data.get('current_results', [])
            else:
                print(f"ğŸ†• {model_name} æ–°è¦CVé–‹å§‹ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³: {current_version}ï¼‰")
                return True, 0, []
                
        except Exception as e:
            print(f"âš ï¸ {model_name} ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return True, 0, []  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ–°è¦é–‹å§‹


# ======================================================================
# 2. ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œç®¡ç†
# ======================================================================

class ScoreBasedCVManager:
    def __init__(self):
        self.cv_system = IncrementalTimeSeriesCV()
        

    def get_models_sorted_by_score(self):
        """æ–°æŒ‡æ¨™ãƒ™ãƒ¼ã‚¹å„ªå…ˆåº¦é †ã§ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            models_data = self.cv_system.load_available_models_for_cv()
            
            if not models_data:
                print("âŒ CVå¯¾è±¡ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            # æ–°æŒ‡æ¨™ãƒ™ãƒ¼ã‚¹å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
            model_priorities = []
            
            for model_name, model_info in models_data.items():
                try:
                    # æ–°æŒ‡æ¨™ã‚’å–å¾—ï¼ˆä¿®æ­£: max_match_scoreè¿½åŠ ï¼‰
                    avg_match = model_info.get('avg_match_score', 0.0)
                    max_match = model_info.get('max_match_score', 0)  # â˜…ä¿®æ­£: è¿½åŠ 
                    recall = model_info.get('recall_score', 0.0)
                    
                    # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—: avg_match * 0.4 + max_match * 0.5 + recall * 0.1
                    priority_score = avg_match * 0.4 + max_match * 0.5 + recall * 0.1
                    
                    # æ–°æŒ‡æ¨™ãŒãªã„å ´åˆã¯å¾“æ¥ã®accuracyã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨
                    if priority_score <= 0:
                        priority_score = model_info.get('score', 0.0) * 0.1  # ä½ã‚ã®é‡ã¿
                    
                    model_priorities.append((model_name, model_info, priority_score))
                    
                except Exception as e:
                    print(f"âš ï¸ {model_name} å„ªå…ˆåº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æœ€ä½å„ªå…ˆåº¦
                    model_priorities.append((model_name, model_info, 0.0))
            
            # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
            sorted_models = sorted(model_priorities, key=lambda x: x[2], reverse=True)
            
            print("ğŸ“Š CVå®Ÿè¡Œé †åºï¼ˆæ–°æŒ‡æ¨™ãƒ™ãƒ¼ã‚¹å„ªå…ˆåº¦é †ï¼‰:")
            for rank, (model_name, model_info, priority_score) in enumerate(sorted_models, 1):
                avg_match = model_info.get('avg_match_score', 0.0)
                max_match = model_info.get('max_match_score', 0)  # â˜…ä¿®æ­£: è¿½åŠ 
                recall = model_info.get('recall_score', 0.0)
                print(f"  {rank:2d}ä½: {model_name:15s} å„ªå…ˆåº¦: {priority_score:.4f} "
                      f"(å¹³å‡ä¸€è‡´: {avg_match:.2f}, æœ€å¤§ä¸€è‡´: {max_match}, Recall: {recall:.3f})")
            
            # å…ƒã®å½¢å¼ã«æˆ»ã™
            result = [(name, info) for name, info, _ in sorted_models]
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã‚½ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

    
    def execute_cv_in_score_order(self, X, y, max_models=None, splits_per_batch=10):
        """ã‚¹ã‚³ã‚¢é †ã§CVå®Ÿè¡Œ"""
        try:
            print("ğŸ” === ã‚¹ã‚³ã‚¢é †æ™‚ç³»åˆ—CVå®Ÿè¡Œé–‹å§‹ ===")
            print(f"âš¡ é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å„ªå…ˆãƒ»æ®µéšçš„ä¿å­˜ãƒ¢ãƒ¼ãƒ‰")
            
            sorted_models = self.get_models_sorted_by_score()
            
            if not sorted_models:
                return {}
            
            if max_models:
                sorted_models = sorted_models[:max_models]
                print(f"ğŸ¯ å®Ÿè¡Œå¯¾è±¡: ä¸Šä½{max_models}ãƒ¢ãƒ‡ãƒ«")
            
            cv_results = {}
            total_models = len(sorted_models)
            
            for model_idx, (model_name, model_info) in enumerate(sorted_models, 1):
                print(f"\nğŸ¤– [{model_idx}/{total_models}] {model_name} CVå®Ÿè¡Œä¸­...")
                
                try:
                    # æ®µéšçš„CVå®Ÿè¡Œ
                    model_cv_result = self.execute_incremental_cv_for_model(
                        model_name, model_info, X, y, splits_per_batch
                    )
                    
                    if model_cv_result:
                        cv_results[model_name] = model_cv_result
                        print(f"âœ… {model_name} CVå®Œäº†")
                    else:
                        print(f"âŒ {model_name} CVå¤±æ•—")
                        
                except Exception as e:
                    print(f"âŒ {model_name} CVã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            print(f"\nğŸ‰ ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œå®Œäº†: {len(cv_results)}/{total_models}ãƒ¢ãƒ‡ãƒ«")
            return cv_results
            
        except Exception as e:
            print(f"âŒ ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _execute_single_split_cv(self, model_info, X, y, train_start, train_end, test_start, test_end, split_info):
        """å˜ä¸€åˆ†å‰²ã®CVå®Ÿè¡Œï¼ˆå˜ä¸€ã‚¯ãƒ©ã‚¹å•é¡Œä¿®æ­£ç‰ˆï¼‰"""
        try:
            print(f"ğŸ” DEBUG: åˆ†å‰²å‰ y.shape = {y.shape}, y.ndim = {y.ndim}")
            print(f"ğŸ” DEBUG: train_range = {train_start}:{train_end}, test_range = {test_start}:{test_end}")
            
            # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if train_end > len(X) or test_end > len(X) or train_start < 0 or test_start < 0:
                print(f"âŒ ç¯„å›²ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿é•·={len(X)}")
                return None
            
            if train_end <= train_start or test_end <= test_start:
                print(f"âŒ ç„¡åŠ¹ãªç¯„å›²")
                return None
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆå¼·åˆ¶2æ¬¡å…ƒç¶­æŒï¼‰
            X_train = X.iloc[train_start:train_end]
            X_test = X.iloc[test_start:test_end]
            
            # ===== å¼·åˆ¶2æ¬¡å…ƒç¶­æŒï¼ˆä¿®æ­£ç‰ˆï¼‰=====
            y_train = y[train_start:train_end]
            y_test = y[test_start:test_end]
            
            print(f"ğŸ” DEBUG: åˆ†å‰²å¾Œ y_train.shape = {y_train.shape}, y_test.shape = {y_test.shape}")
            
            # å¼·åˆ¶çš„ã«2æ¬¡å…ƒã‚’ä¿æŒ
            if len(y_train.shape) == 1:
                print(f"âš ï¸ y_train 1æ¬¡å…ƒæ¤œå‡º: {y_train.shape} â†’ ä¿®æ­£ä¸­")
                if len(y_train) == 0:
                    y_train = y_train.reshape(0, 31)
                else:
                    y_train = y_train.reshape(-1, 31) if y_train.size % 31 == 0 else y_train.reshape(len(y_train), 1)
                print(f"âœ… y_train ä¿®æ­£å®Œäº†: {y_train.shape}")
            
            if len(y_test.shape) == 1:
                print(f"âš ï¸ y_test 1æ¬¡å…ƒæ¤œå‡º: {y_test.shape} â†’ ä¿®æ­£ä¸­")
                if len(y_test) == 0:
                    y_test = y_test.reshape(0, 31)
                else:
                    y_test = y_test.reshape(-1, 31) if y_test.size % 31 == 0 else y_test.reshape(len(y_test), 1)
                print(f"âœ… y_test ä¿®æ­£å®Œäº†: {y_test.shape}")
            
            # 31æ¬¡å…ƒãƒã‚§ãƒƒã‚¯
            if y_train.shape[1] != 31:
                print(f"âŒ y_train æ¬¡å…ƒã‚¨ãƒ©ãƒ¼: {y_train.shape[1]} != 31")
                return None
            
            if y_test.shape[1] != 31:
                print(f"âŒ y_test æ¬¡å…ƒã‚¨ãƒ©ãƒ¼: {y_test.shape[1]} != 31")
                return None
            
            if len(X_train) < 5 or len(X_test) == 0:
                print(f"âŒ ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³: train={len(X_train)}, test={len(X_test)}")
                return None
            
            # â˜…ä¿®æ­£: å˜ä¸€ã‚¯ãƒ©ã‚¹å•é¡Œãƒã‚§ãƒƒã‚¯å¼·åŒ–ç‰ˆ
            unique_classes_per_output = []
            valid_outputs = 0
            
            for i in range(y_train.shape[1]):
                unique_values = np.unique(y_train[:, i])
                unique_classes = len(unique_values)
                unique_classes_per_output.append(unique_classes)
                
                # æœ‰åŠ¹ãªå‡ºåŠ›ï¼ˆ2ã‚¯ãƒ©ã‚¹ä»¥ä¸Šï¼‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                if unique_classes >= 2:
                    valid_outputs += 1
            
            print(f"ğŸ” ã‚¯ãƒ©ã‚¹å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯: æœ‰åŠ¹å‡ºåŠ›={valid_outputs}/{len(unique_classes_per_output)}")
            
            # æ¡ä»¶1: æœ‰åŠ¹ãªå‡ºåŠ›ãŒå…¨ä½“ã®30%æœªæº€ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            valid_ratio = valid_outputs / len(unique_classes_per_output)
            if valid_ratio < 0.3:
                print(f"âš ï¸ æœ‰åŠ¹å‡ºåŠ›æ¯”ç‡ãŒä½ã™ãã¾ã™: {valid_ratio:.2%} < 30% â†’ ã‚¹ã‚­ãƒƒãƒ—")
                return None
            
            # æ¡ä»¶2: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹å ´åˆã¯ã‚ˆã‚Šå³æ ¼ã«
            if len(X_train) < 30:
                min_required_outputs = max(10, len(unique_classes_per_output) * 0.5)
                if valid_outputs < min_required_outputs:
                    print(f"âš ï¸ å°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€æœ‰åŠ¹å‡ºåŠ›æ•°ä¸è¶³: {valid_outputs} < {min_required_outputs} â†’ ã‚¹ã‚­ãƒƒãƒ—")
                    return None
            
            # æ¡ä»¶3: å…¨å‡ºåŠ›ã®åˆ†æ•£ã‚’ãƒã‚§ãƒƒã‚¯
            output_variances = []
            for i in range(y_train.shape[1]):
                if len(np.unique(y_train[:, i])) >= 2:
                    variance = np.var(y_train[:, i])
                    output_variances.append(variance)
            
            if output_variances:
                mean_variance = np.mean(output_variances)
                if mean_variance < 0.01:  # éå¸¸ã«ä½ã„åˆ†æ•£
                    print(f"âš ï¸ å‡ºåŠ›åˆ†æ•£ãŒä½ã™ãã¾ã™: {mean_variance:.4f} â†’ ã‚¹ã‚­ãƒƒãƒ—")
                    return None
            
            print(f"âœ… ã‚¯ãƒ©ã‚¹å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯é€šé: æœ‰åŠ¹å‡ºåŠ›={valid_outputs}, æ¯”ç‡={valid_ratio:.2%}")
            
            print(f"âœ… æœ€çµ‚å½¢çŠ¶: X_train{X_train.shape}, y_train{y_train.shape}, X_test{X_test.shape}, y_test{y_test.shape}")
print(f"âœ… ã‚¯ãƒ©ã‚¹æ•°ãƒã‚§ãƒƒã‚¯æ¸ˆã¿: æœ‰åŠ¹å‡ºåŠ›={valid_outputs}/{len(unique_classes_per_output)}")

            
            # é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®å®Ÿè£…
            try:
                # mainã§ä¿å­˜ã•ã‚ŒãŸé‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                model_weights = self._load_main_model_weights()
                
                # å…¨ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’åé›†
                all_models_data = self.cv_system.load_available_models_for_cv()
                ensemble_predictions = []
                ensemble_weights = []
                
                for ensemble_model_name, ensemble_model_info in all_models_data.items():
                    try:
                        # å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
                        model = ensemble_model_info['model']
                        model_type = ensemble_model_info.get('model_type', 'classification')
                        
                        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)
                        
                        # ãƒ¢ãƒ‡ãƒ«è¤‡è£½ãƒ»å­¦ç¿’
                        if model_type == "regression_multioutput":
                            from sklearn.base import clone
                            trained_models = []
                            predictions = np.zeros_like(y_test)
                            
                            for i in range(y_train.shape[1]):
                                try:
                                    clf = clone(model[i]) if hasattr(model, '__getitem__') else clone(model)
                                    clf.fit(X_train_scaled, y_train[:, i])
                                    pred = clf.predict(X_test_scaled)
                                    predictions[:, i] = pred
                                    trained_models.append(clf)
                                except Exception as e:
                                    print(f"        âš ï¸ å‡ºåŠ›{i}å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
                                    continue
                            
                        else:
                            # åˆ†é¡ãƒ¢ãƒ‡ãƒ«
                            try:
                                from sklearn.base import clone
                                from sklearn.multioutput import MultiOutputClassifier
                                
                                # â˜…ä¿®æ­£: å­¦ç¿’å‰ã®æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
                                train_classes_check = []
                                for i in range(y_train.shape[1]):
                                    n_classes = len(np.unique(y_train[:, i]))
                                    train_classes_check.append(n_classes)
                                
                                insufficient_classes = sum(1 for n in train_classes_check if n < 2)
                                if insufficient_classes > len(train_classes_check) * 0.7:  # 70%ä»¥ä¸ŠãŒå˜ä¸€ã‚¯ãƒ©ã‚¹
                                    print(f"        âš ï¸ {ensemble_model_name} å­¦ç¿’ã‚¹ã‚­ãƒƒãƒ—: å˜ä¸€ã‚¯ãƒ©ã‚¹å‡ºåŠ›å¤šæ•° ({insufficient_classes}/{len(train_classes_check)})")
                                    continue
                                
                                if hasattr(model, 'estimators_'):
                                    clf = clone(model)
                                    clf.fit(X_train_scaled, y_train)
                                else:
                                    multi_clf = MultiOutputClassifier(clone(model))
                                    clf = multi_clf
                                    clf.fit(X_train_scaled, y_train)
                                
                                predictions = clf.predict(X_test_scaled)
                                
                                if len(predictions.shape) == 1:
                                    predictions = predictions.reshape(-1, 31)
                            
                            except Exception as e:
                                error_msg = str(e).lower()
                                if any(keyword in error_msg for keyword in ['1 class', 'one class', 'single class', 'zero weights']):
                                    print(f"        âš ï¸ {ensemble_model_name} å˜ä¸€ã‚¯ãƒ©ã‚¹å•é¡Œã§ã‚¹ã‚­ãƒƒãƒ—: {e}")
                                else:
                                    print(f"        âŒ {ensemble_model_name} å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
                                continue
                        
                        # é‡ã¿ã‚’å–å¾—
                        weight = model_weights.get(ensemble_model_name, 1.0) if model_weights else 1.0
                        
                        ensemble_predictions.append(predictions)
                        ensemble_weights.append(weight)
                        
                    except Exception as model_error:
                        print(f"        âš ï¸ {ensemble_model_name} ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {model_error}")
                        continue
                
                # é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿè¡Œ
                if ensemble_predictions and ensemble_weights:
                    total_weight = sum(ensemble_weights)
                    final_predictions = np.zeros_like(ensemble_predictions[0], dtype=np.float64)  # â˜…ä¿®æ­£: dtypeæŒ‡å®š
                    
                    for pred, weight in zip(ensemble_predictions, ensemble_weights):
                        # â˜…ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€
                        pred_float = pred.astype(np.float64)
                        final_predictions += pred_float * weight
                    
                    final_predictions /= total_weight
                    
                    # æ–°æŒ‡æ¨™ã§è©•ä¾¡
                    y_true_sets = []
                    for i in range(len(y_test)):
                        true_numbers = [j+1 for j in range(31) if y_test[i][j] == 1]
                        if len(true_numbers) == 5:
                            y_true_sets.append(true_numbers)
                    
                    predicted_sets = []
                    for i in range(len(final_predictions)):
                        top5_indices = np.argsort(final_predictions[i])[-5:]
                        predicted_sets.append([idx+1 for idx in top5_indices])
                    
                    # æ–°æŒ‡æ¨™è©•ä¾¡é–¢æ•°ã‚’å‘¼ã³å‡ºã—
                    quality_scores = self._evaluate_model_set_quality(y_true_sets, predicted_sets)
                    
                    # å¾“æ¥ã®accuracyè¨ˆç®—ã‚‚ä¿æŒ
                    predictions_binary = (final_predictions > 0.5).astype(int)
                    accuracy = accuracy_score(y_test.flatten(), predictions_binary.flatten())
                    
                    # çµæœè¨˜éŒ²ï¼ˆæ–°æŒ‡æ¨™è¾¼ã¿ï¼‰
                    result = {
                        'strategy': split_info['strategy'],
                        'window': split_info['window'],
                        'train_size': len(X_train),
                        'test_size': len(X_test),
                        'score': accuracy,
                        'avg_match_score': quality_scores['avg_match_score'],
                        'max_match_score': quality_scores['max_match_score'],
                        'recall_score': quality_scores['recall_score'],
                        'train_start': train_start,
                        'train_end': train_end,
                        'test_start': test_start,
                        'test_end': test_end
                    }
                    
                    print(f"        âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡æˆåŠŸ: accuracy={accuracy:.4f}, "
                          f"å¹³å‡ä¸€è‡´={quality_scores['avg_match_score']:.2f}, "
                          f"æœ€å¤§ä¸€è‡´={quality_scores['max_match_score']}, "
                          f"recall={quality_scores['recall_score']:.3f}")
                    
                    return result
                else:
                    print(f"        âŒ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å¤±æ•—ã€å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    
            except Exception as ensemble_error:
                print(f"        âš ï¸ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {ensemble_error}")
                print(f"        ğŸ”„ å˜ä¸€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ä¸€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆå¾“æ¥å‡¦ç†ï¼‰
            model = model_info['model']
            model_type = model_info.get('model_type', 'classification')
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ãƒ¢ãƒ‡ãƒ«è¤‡è£½ï¼ˆå…ƒãƒ¢ãƒ‡ãƒ«ä¿è­·ï¼‰
            if model_type == "regression_multioutput":
                from sklearn.base import clone
                trained_models = []
                predictions = np.zeros_like(y_test)
                
                for i in range(y_train.shape[1]):
                    try:
                        clf = clone(model[i]) if hasattr(model, '__getitem__') else clone(model)
                        clf.fit(X_train_scaled, y_train[:, i])
                        pred = clf.predict(X_test_scaled)
                        predictions[:, i] = pred
                        trained_models.append(clf)
                    except Exception as e:
                        print(f"        âš ï¸ å‡ºåŠ›{i}å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
                        continue
                
                predictions_binary = (predictions > 0.5).astype(int)
                score = accuracy_score(y_test.flatten(), predictions_binary.flatten())
            else:
                try:
                    from sklearn.base import clone
                    from sklearn.multioutput import MultiOutputClassifier
                    
                    if hasattr(model, 'estimators_'):
                        clf = clone(model)
                        clf.fit(X_train_scaled, y_train)
                    else:
                        multi_clf = MultiOutputClassifier(clone(model))
                        clf = multi_clf
                        clf.fit(X_train_scaled, y_train)
                    
                    predictions = clf.predict(X_test_scaled)
                    
                    if len(predictions.shape) == 1:
                        predictions = predictions.reshape(-1, 31)
                    
                    score = accuracy_score(y_test.flatten(), predictions.flatten())
                    
                except Exception as e:
                    print(f"        âŒ å˜ä¸€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
                    return None
            
            # çµæœè¨˜éŒ²ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã¯æ–°æŒ‡æ¨™ãªã—ï¼‰
            result = {
                'strategy': split_info['strategy'],
                'window': split_info['window'],
                'train_size': len(X_train),
                'test_size': len(X_test),
                'score': score,
                'avg_match_score': 0.0,
                'max_match_score': 0,
                'recall_score': 0.0,
                'train_start': train_start,
                'train_end': train_end,
                'test_start': test_start,
                'test_end': test_end
            }
            
            return result
            
        except Exception as e:
            print(f"        âŒ åˆ†å‰²CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            print(f"        ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: train_range({train_start}:{train_end}), test_range({test_start}:{test_end})")
            return None

    def _load_main_model_weights(self):
        """mainã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            # é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹å€™è£œï¼ˆä¿®æ­£: æ‹¡å¼µï¼‰
            weight_file_paths = [
                "miniloto_models/model_weights.pkl",
                "/content/drive/MyDrive/miniloto_models/model_weights.pkl",
                "model_weights.pkl",
                "ultra_comprehensive_learning_data_v4.pkl",  # â˜…ä¿®æ­£: è¿½åŠ 
                "/content/drive/MyDrive/miniloto_predictor_ultra/ultra_comprehensive_learning_data_v4.pkl"  # â˜…ä¿®æ­£: è¿½åŠ 
            ]
            
            for weight_path in weight_file_paths:
                if os.path.exists(weight_path):
                    try:
                        with open(weight_path, 'rb') as f:
                            data = pickle.load(f)
                        
                        # â˜…ä¿®æ­£: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«ã‚ˆã‚‹é‡ã¿æŠ½å‡º
                        if isinstance(data, dict):
                            if 'model_weights' in data:
                                model_weights = data['model_weights']
                                print(f"        ğŸ“¥ ãƒ¢ãƒ‡ãƒ«é‡ã¿èª­ã¿è¾¼ã¿æˆåŠŸ(çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«): {weight_path}")
                                return model_weights
                            elif all(isinstance(v, (int, float)) for v in data.values()):
                                # ç›´æ¥é‡ã¿è¾æ›¸ã®å ´åˆ
                                print(f"        ğŸ“¥ ãƒ¢ãƒ‡ãƒ«é‡ã¿èª­ã¿è¾¼ã¿æˆåŠŸ(ç›´æ¥): {weight_path}")
                                return data
                        
                    except Exception as e:
                        print(f"        âš ï¸ é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼({weight_path}): {e}")
                        continue
            
            print(f"        ğŸ“ ãƒ¢ãƒ‡ãƒ«é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€ç­‰é‡ã¿ã‚’ä½¿ç”¨")
            return None
            
        except Exception as e:
            print(f"        âŒ ãƒ¢ãƒ‡ãƒ«é‡ã¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _evaluate_model_set_quality(self, y_true_sets, predicted_sets):
        """
        ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚»ãƒƒãƒˆã®è³ªã‚’3ã¤ã®æŒ‡æ¨™ã§è©•ä¾¡ï¼ˆCVç‰ˆï¼‰
        """
        try:
            if not y_true_sets or not predicted_sets:
                return {"avg_match_score": 0.0, "max_match_score": 0, "recall_score": 0.0}
            
            # ãƒ‡ãƒ¼ã‚¿æ•°ã‚’åˆã‚ã›ã‚‹
            min_len = min(len(y_true_sets), len(predicted_sets))
            y_true_sets = y_true_sets[:min_len]
            predicted_sets = predicted_sets[:min_len]
            
            total_matches = []
            individual_recalls = []
            
            # 1å¯¾1ã§æ¯”è¼ƒ
            for true_set, pred_set in zip(y_true_sets, predicted_sets):
                if isinstance(true_set, (list, tuple)) and isinstance(pred_set, (list, tuple)):
                    # å„ã‚»ãƒƒãƒˆã®ä¸€è‡´æ•°ã‚’è¨ˆç®—
                    match_count = len(set(pred_set) & set(true_set))
                    total_matches.append(match_count)
                    
                    # å€‹åˆ¥recallè¨ˆç®—ï¼ˆãã®å›ã®å½“é¸5ç•ªå·ã®ã†ã¡äºˆæ¸¬ã§æ‹¾ãˆãŸå‰²åˆï¼‰
                    if len(true_set) > 0:
                        individual_recall = len(set(pred_set) & set(true_set)) / len(true_set)
                        individual_recalls.append(individual_recall)
            
            if not total_matches:
                return {"avg_match_score": 0.0, "max_match_score": 0, "recall_score": 0.0}
            
            # 3ã¤ã®æŒ‡æ¨™ã‚’è¨ˆç®—
            avg_match = sum(total_matches) / len(total_matches)
            max_match = max(total_matches)
            
            # recall = å€‹åˆ¥recallã®å¹³å‡
            recall = sum(individual_recalls) / len(individual_recalls) if individual_recalls else 0.0
            
            return {
                "avg_match_score": avg_match,
                "max_match_score": max_match,
                "recall_score": recall
            }
            
        except Exception as e:
            print(f"âŒ _evaluate_model_set_quality ã‚¨ãƒ©ãƒ¼: {e}")
            return {"avg_match_score": 0.0, "max_match_score": 0, "recall_score": 0.0}


# ãƒ‘ãƒ¼ãƒˆ1ã“ã“ã¾ã§

# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part2A: CVæˆ¦ç•¥ãƒ»åˆ†å‰²å‡¦ç†ï¼ˆå‰åŠï¼‰

# ======================================================================
# 3. æ™‚ç³»åˆ—CVæˆ¦ç•¥å®Ÿè£…ï¼ˆScoreBasedCVManagerã‚¯ãƒ©ã‚¹ã®ç¶šãï¼‰
# ======================================================================

    def execute_incremental_cv_for_model(self, model_name, model_info, X, y, splits_per_batch=10):
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®æ®µéšçš„CVå®Ÿè¡Œ"""
        try:
            # ç¶™ç¶šå®Ÿè¡Œã®ç¢ºèª
            start_split, current_results = self.cv_system.continue_cv_from_checkpoint(model_name)
            
            # CVæˆ¦ç•¥å®šç¾©ï¼ˆ6æˆ¦ç•¥ï¼‰
            cv_strategies = [
                {"name": "å›ºå®šçª“", "windows": [20, 30, 40, 50, 60, 70], "cumulative": False, "step": 2},
                {"name": "æ‹¡å¼µçª“", "windows": [20, 30, 40, 50, 60, 70], "cumulative": True, "step": 2},
                {"name": "é©å¿œçª“", "windows": [15, 25, 35, 45, 55, 65], "cumulative": False, "step": 3},
                {"name": "é‡è¤‡çª“", "windows": [25, 35, 45, 55], "cumulative": False, "step": 1},
                {"name": "å­£ç¯€èª¿æ•´çª“", "windows": [30, 50, 70], "cumulative": False, "step": 4},
                {"name": "ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“", "windows": [20, 40, 60], "cumulative": False, "step": 5}
            ]
            
            # å…¨åˆ†å‰²ç”Ÿæˆ
            all_splits = []
            strategy_info = []
            
            for strategy in cv_strategies:
                for window in strategy["windows"]:
                    splits = self._generate_time_series_splits(
                        len(X), window, strategy["cumulative"], strategy["step"]
                    )
                    
                    for split in splits:
                        all_splits.append(split)
                        strategy_info.append({
                            'strategy': strategy["name"],
                            'window': window,
                            'split': split
                        })
            
            total_splits = len(all_splits)
            print(f"    ğŸ“Š ç·åˆ†å‰²æ•°: {total_splits} (é–‹å§‹ä½ç½®: {start_split})")
            
            if start_split >= total_splits:
                print(f"    âœ… {model_name} æ—¢ã«å®Œäº†æ¸ˆã¿")
                return {"completed": True, "cv_score": 0}
            
            # ãƒãƒƒãƒå‡¦ç†ã§CVå®Ÿè¡Œ
            for batch_start in range(start_split, total_splits, splits_per_batch):
                batch_end = min(batch_start + splits_per_batch, total_splits)
                
                print(f"    ğŸ”„ ãƒãƒƒãƒå‡¦ç†: {batch_start+1}-{batch_end}/{total_splits}")
                
                # ãƒãƒƒãƒå†…åˆ†å‰²å‡¦ç†
                batch_results = []
                skipped_splits = 0
                for split_idx in range(batch_start, batch_end):
                    split_info = strategy_info[split_idx]
                    train_start, train_end, test_start, test_end = all_splits[split_idx]
                    

                    try:
                        # å˜ä¸€åˆ†å‰²ã®CVå®Ÿè¡Œ
                        split_result = self._execute_single_split_cv(
                            model_info, X, y, 
                            train_start, train_end, test_start, test_end,
                            split_info
                        )
                        
                        if split_result:
                            batch_results.append(split_result)
                        else:
                            skipped_splits += 1
                            print(f"      âš ï¸ åˆ†å‰²{split_idx+1} ã‚¹ã‚­ãƒƒãƒ— (å˜ä¸€ã‚¯ãƒ©ã‚¹å•é¡Œ)")
                            

                    except Exception as e:
                        skipped_splits += 1
                        error_msg = str(e).lower()
                        if 'not defined' in error_msg or 'name' in error_msg:
                            print(f"      âŒ åˆ†å‰²{split_idx+1}ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                        elif any(keyword in error_msg for keyword in ['1 class', 'one class', 'single class']):
                            print(f"      âš ï¸ åˆ†å‰²{split_idx+1}å˜ä¸€ã‚¯ãƒ©ã‚¹å•é¡Œ: {e}")
                        else:
                            print(f"      âŒ åˆ†å‰²{split_idx+1}ã‚¨ãƒ©ãƒ¼: {e}")
                        continue

                
                # ãƒãƒƒãƒå®Œäº†å ±å‘Šã«ã‚¹ã‚­ãƒƒãƒ—æ•°ã‚’è¿½åŠ 
                print(f"    ğŸ“Š ãƒãƒƒãƒ{batch_start+1}-{batch_end}å®Œäº†: æˆåŠŸ={len(batch_results)}, ã‚¹ã‚­ãƒƒãƒ—={skipped_splits}")
                
                # ãƒãƒƒãƒçµæœã‚’ç´¯ç©
                current_results.extend(batch_results)
                
                # é€²æ—ä¿å­˜
                self.cv_system.save_cv_progress(
                    model_name, current_results, batch_end, total_splits
                )
                
                # å®Œäº†ãƒã‚§ãƒƒã‚¯
                if batch_end >= total_splits:
                    break
            
            # CVçµæœçµ±è¨ˆè¨ˆç®—
            if current_results:
                cv_scores = [r['score'] for r in current_results if 'score' in r]
                cv_summary = {
                    'cv_score': np.mean(cv_scores) if cv_scores else 0,
                    'cv_std': np.std(cv_scores) if cv_scores else 0,
                    'cv_results': current_results,
                    'total_splits': len(current_results),
                    'completed': True
                }
                
                # å¼·åŒ–ãƒ¢ãƒ‡ãƒ«ä¿å­˜
                enhanced_model_data = {
                    'model': model_info['model'],
                    'scaler': model_info['scaler'],
                    'cv_score': cv_summary['cv_score'],
                    'cv_std': cv_summary['cv_std'],
                    'cv_results': current_results
                }
                
                self.cv_system.update_model_with_cv_results(model_name, enhanced_model_data)
                
                return cv_summary
            else:
                print(f"    âŒ {model_name} CVçµæœãªã—")
                return None
                
        except Exception as e:
            print(f"âŒ {model_name} æ®µéšçš„CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _generate_time_series_splits(self, data_length, window_size, cumulative, step):
        """æ™‚ç³»åˆ—åˆ†å‰²ç”Ÿæˆ"""
        try:
            splits = []
            
            if data_length < window_size + 1:
                return splits
            
            if cumulative:
                # æ‹¡å¼µçª“: é–‹å§‹ç‚¹å›ºå®šã€çµ‚äº†ç‚¹ã‚’æ‹¡å¼µ
                for end_idx in range(window_size, data_length, step):
                    train_start = 0
                    train_end = end_idx
                    test_start = end_idx
                    test_end = min(end_idx + 1, data_length)
                    
                    if test_end <= data_length:
                        splits.append((train_start, train_end, test_start, test_end))
            else:
                # å›ºå®šçª“: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºå›ºå®šã§ã‚¹ãƒ©ã‚¤ãƒ‰
                for start_idx in range(0, data_length - window_size, step):
                    train_start = start_idx
                    train_end = start_idx + window_size
                    test_start = train_end
                    test_end = min(train_end + 1, data_length)
                    
                    if test_end <= data_length:
                        splits.append((train_start, train_end, test_start, test_end))
            
            return splits
            
        except Exception as e:
            print(f"âŒ åˆ†å‰²ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

# ãƒ‘ãƒ¼ãƒˆ2Aã“ã“ã¾ã§

# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part2B: CVæˆ¦ç•¥ãƒ»åˆ†å‰²å‡¦ç†ï¼ˆå¾ŒåŠï¼‰

# ======================================================================
# 4. CVåˆ†å‰²å®Ÿè¡Œãƒ»æˆ¦ç•¥è©³ç´°å®Ÿè£…
# ======================================================================

# ======================================================================
# 5. CVæˆ¦ç•¥è©³ç´°å®Ÿè£…
# ======================================================================

class CVStrategyImplementation:
    def __init__(self):
        self.strategy_configs = self._get_strategy_configurations()
    
    def _get_strategy_configurations(self):
        """CVæˆ¦ç•¥è¨­å®š"""
        return {
            "å›ºå®šçª“": {
                "description": "å›ºå®šã‚µã‚¤ã‚ºã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã‚¹ãƒ©ã‚¤ãƒ‰",
                "windows": [20, 30, 40, 50, 60, 70],
                "cumulative": False,
                "step": 2,
                "weight": 1.0
            },
            "æ‹¡å¼µçª“": {
                "description": "é–‹å§‹ç‚¹å›ºå®šã€çµ‚äº†ç‚¹æ‹¡å¼µ",
                "windows": [20, 30, 40, 50, 60, 70],
                "cumulative": True,
                "step": 2,
                "weight": 1.2  # ã‚ˆã‚Šé‡è¦è¦–
            },
            "é©å¿œçª“": {
                "description": "é©å¿œçš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º",
                "windows": [15, 25, 35, 45, 55, 65],
                "cumulative": False,
                "step": 3,
                "weight": 0.9
            },
            "é‡è¤‡çª“": {
                "description": "é«˜é‡è¤‡ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦",
                "windows": [25, 35, 45, 55],
                "cumulative": False,
                "step": 1,
                "weight": 0.8
            },
            "å­£ç¯€èª¿æ•´çª“": {
                "description": "å­£ç¯€æ€§è€ƒæ…®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦",
                "windows": [30, 50, 70],
                "cumulative": False,
                "step": 4,
                "weight": 1.1
            },
            "ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“": {
                "description": "ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦",
                "windows": [20, 40, 60],
                "cumulative": False,
                "step": 5,
                "weight": 0.9
            }
        }
    
    def get_weighted_cv_score(self, cv_results):
        """æˆ¦ç•¥é‡ã¿ä»˜ãCV ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        try:
            if not cv_results:
                return 0
            
            weighted_scores = []
            
            for result in cv_results:
                strategy = result.get('strategy', 'å›ºå®šçª“')
                score = result.get('score', 0)
                
                weight = self.strategy_configs.get(strategy, {}).get('weight', 1.0)
                weighted_score = score * weight
                
                weighted_scores.append(weighted_score)
            
            return np.mean(weighted_scores) if weighted_scores else 0
            
        except Exception as e:
            print(f"âŒ é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
    
    def analyze_strategy_performance(self, cv_results):
        """æˆ¦ç•¥åˆ¥æ€§èƒ½åˆ†æ"""
        try:
            strategy_performance = {}
            
            for result in cv_results:
                strategy = result.get('strategy', 'unknown')
                score = result.get('score', 0)
                
                if strategy not in strategy_performance:
                    strategy_performance[strategy] = []
                
                strategy_performance[strategy].append(score)
            
            # çµ±è¨ˆè¨ˆç®—
            strategy_stats = {}
            for strategy, scores in strategy_performance.items():
                if scores:
                    strategy_stats[strategy] = {
                        'count': len(scores),
                        'mean': np.mean(scores),
                        'std': np.std(scores),
                        'min': min(scores),
                        'max': max(scores)
                    }
            
            return strategy_stats
            
        except Exception as e:
            print(f"âŒ æˆ¦ç•¥æ€§èƒ½åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def get_strategy_summary(self):
        """æˆ¦ç•¥ã‚µãƒãƒªãƒ¼å–å¾—"""
        try:
            summary = {}
            
            for strategy_name, config in self.strategy_configs.items():
                summary[strategy_name] = {
                    'description': config['description'],
                    'windows_count': len(config['windows']),
                    'weight': config['weight'],
                    'step_size': config['step'],
                    'cumulative': config['cumulative']
                }
            
            return summary
            
        except Exception as e:
            print(f"âŒ æˆ¦ç•¥ã‚µãƒãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def calculate_total_splits_estimate(self, data_length):
        """ç·åˆ†å‰²æ•°æ¨å®š"""
        try:
            total_splits = 0
            
            for strategy_name, config in self.strategy_configs.items():
                for window in config['windows']:
                    if data_length < window + 1:
                        continue
                    
                    if config['cumulative']:
                        # æ‹¡å¼µçª“
                        splits_count = max(0, (data_length - window) // config['step'])
                    else:
                        # å›ºå®šçª“
                        splits_count = max(0, (data_length - window) // config['step'])
                    
                    total_splits += splits_count
            
            return total_splits
            
        except Exception as e:
            print(f"âŒ åˆ†å‰²æ•°æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 0

# ======================================================================
# 6. CVå“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================

class CVQualityManager:
    def __init__(self):
        self.strategy_impl = CVStrategyImplementation()
        
    def validate_cv_configuration(self, data_length, model_count):
        """CVè¨­å®šæ¤œè¨¼"""
        try:
            print("ğŸ” === CVè¨­å®šæ¤œè¨¼ ===")
            
            validation_results = {
                'data_sufficient': True,
                'estimated_splits': 0,
                'estimated_time_hours': 0,
                'warnings': [],
                'recommendations': []
            }
            
            # ãƒ‡ãƒ¼ã‚¿é‡ãƒã‚§ãƒƒã‚¯
            min_required_length = 100
            if data_length < min_required_length:
                validation_results['data_sufficient'] = False
                validation_results['warnings'].append(f"ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {data_length}ä»¶ (æœ€ä½{min_required_length}ä»¶å¿…è¦)")
            
            # åˆ†å‰²æ•°æ¨å®š
            total_splits = self.strategy_impl.calculate_total_splits_estimate(data_length)
            validation_results['estimated_splits'] = total_splits
            
            # å‡¦ç†æ™‚é–“æ¨å®šï¼ˆ1åˆ†å‰²ã‚ãŸã‚Šç´„0.1ç§’ã¨ä»®å®šï¼‰
            estimated_seconds = total_splits * model_count * 0.1
            validation_results['estimated_time_hours'] = estimated_seconds / 3600
            
            print(f"ğŸ“Š æ¤œè¨¼çµæœ:")
            print(f"  ãƒ‡ãƒ¼ã‚¿é•·: {data_length}")
            print(f"  ãƒ¢ãƒ‡ãƒ«æ•°: {model_count}")
            print(f"  æ¨å®šåˆ†å‰²æ•°: {total_splits:,}")
            print(f"  æ¨å®šå‡¦ç†æ™‚é–“: {validation_results['estimated_time_hours']:.1f}æ™‚é–“")
            
            # æ¨å¥¨äº‹é …
            if validation_results['estimated_time_hours'] > 24:
                validation_results['recommendations'].append("å‡¦ç†æ™‚é–“ãŒé•·ã„ãŸã‚ã€æ®µéšçš„å®Ÿè¡Œã‚’æ¨å¥¨")
            
            if validation_results['estimated_time_hours'] > 72:
                validation_results['warnings'].append("å‡¦ç†æ™‚é–“ãŒéå¸¸ã«é•·ã„ï¼ˆ3æ—¥ä»¥ä¸Šï¼‰")
                validation_results['recommendations'].append("ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œã¾ãŸã¯å¯¾è±¡ãƒ¢ãƒ‡ãƒ«æ•°ã‚’å‰Šæ¸›ã‚’æ¨å¥¨")
            
            # çµæœè¡¨ç¤º
            if validation_results['warnings']:
                print(f"âš ï¸ è­¦å‘Š:")
                for warning in validation_results['warnings']:
                    print(f"  â€¢ {warning}")
            
            if validation_results['recommendations']:
                print(f"ğŸ’¡ æ¨å¥¨:")
                for rec in validation_results['recommendations']:
                    print(f"  â€¢ {rec}")
            
            return validation_results
            
        except Exception as e:
            print(f"âŒ CVè¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def monitor_cv_health(self, cv_results):
        """CVå®Ÿè¡Œå“è³ªç›£è¦–"""
        try:
            if not cv_results:
                return {}
            
            health_metrics = {
                'success_rate': 0,
                'average_score': 0,
                'score_stability': 0,
                'strategy_balance': {},
                'anomaly_count': 0
            }
            
            scores = [r['score'] for r in cv_results if 'score' in r and r['score'] is not None]
            
            if scores:
                health_metrics['success_rate'] = len(scores) / len(cv_results)
                health_metrics['average_score'] = np.mean(scores)
                health_metrics['score_stability'] = 1 / (1 + np.std(scores))
                
                # ç•°å¸¸å€¤æ¤œå‡ºï¼ˆ3Ïƒå¤–ã‚Œå€¤ï¼‰
                mean_score = np.mean(scores)
                std_score = np.std(scores)
                threshold = 3 * std_score
                
                anomalies = [s for s in scores if abs(s - mean_score) > threshold]
                health_metrics['anomaly_count'] = len(anomalies)
            
            # æˆ¦ç•¥ãƒãƒ©ãƒ³ã‚¹
            strategy_counts = {}
            for result in cv_results:
                strategy = result.get('strategy', 'unknown')
                strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
            
            total_results = len(cv_results)
            if total_results > 0:
                health_metrics['strategy_balance'] = {
                    strategy: count / total_results 
                    for strategy, count in strategy_counts.items()
                }
            
            return health_metrics
            
        except Exception as e:
            print(f"âŒ CVå¥å…¨æ€§ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

# ãƒ‘ãƒ¼ãƒˆ2Bã“ã“ã¾ã§

# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part3: CVè©•ä¾¡ãƒ»é‡ã¿æ±ºå®š

# ======================================================================
# 5. CVè©•ä¾¡ãƒ»é‡ã¿æ±ºå®šã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================

class CVEvaluationSystem:
    def __init__(self):
        self.cv_strategy = CVStrategyImplementation()
        
    def determine_ultra_model_weights(self, all_cv_results):
        """è¶…ç²¾å¯†ãƒ¢ãƒ‡ãƒ«é‡ã¿æ±ºå®š"""
        try:
            print("âš–ï¸ === è¶…ç²¾å¯†ãƒ¢ãƒ‡ãƒ«é‡ã¿æ±ºå®šé–‹å§‹ ===")
            
            if not all_cv_results:
                print("âŒ CVçµæœãŒã‚ã‚Šã¾ã›ã‚“")
                return {}
            
            model_weights = {}
            
            for model_name, cv_result in all_cv_results.items():
                try:
                    if not cv_result or 'cv_results' not in cv_result:
                        model_weights[model_name] = 0.1  # æœ€å°é‡ã¿
                        continue
                    
                    cv_results = cv_result['cv_results']
                    
                    # åŸºæœ¬çµ±è¨ˆ
                    scores = [r['score'] for r in cv_results if 'score' in r]
                    if not scores:
                        model_weights[model_name] = 0.1
                        continue
                    
                    base_score = np.mean(scores)
                    score_std = np.std(scores)
                    
                    # æˆ¦ç•¥é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢
                    weighted_score = self.cv_strategy.get_weighted_cv_score(cv_results)
                    
                    # å®‰å®šæ€§æŒ‡æ¨™
                    stability = 1 / (1 + score_std) if score_std > 0 else 1.0
                    
                    # ä¿¡é ¼æ€§æŒ‡æ¨™ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
                    reliability = min(len(scores) / 100, 1.0)  # 100åˆ†å‰²ã§æœ€å¤§ä¿¡é ¼æ€§
                    
                    # æˆ¦ç•¥åˆ¥æ€§èƒ½
                    strategy_stats = self.cv_strategy.analyze_strategy_performance(cv_results)
                    strategy_bonus = self._calculate_strategy_bonus(strategy_stats)
                    
                    # æœ€çµ‚é‡ã¿è¨ˆç®—
                    final_weight = (
                        weighted_score * 0.4 +
                        base_score * 0.3 +
                        stability * 0.15 +
                        reliability * 0.1 +
                        strategy_bonus * 0.05
                    )
                    
                    model_weights[model_name] = max(final_weight, 0.01)  # æœ€å°é‡ã¿ä¿è¨¼
                    
                    print(f"  {model_name:15s}: é‡ã¿ {final_weight:.4f} "
                          f"(åŸºæœ¬:{base_score:.3f}, é‡ã¿ä»˜:{weighted_score:.3f}, "
                          f"å®‰å®š:{stability:.3f}, ä¿¡é ¼:{reliability:.3f})")
                    
                except Exception as e:
                    print(f"  âš ï¸ {model_name} é‡ã¿è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                    model_weights[model_name] = 0.1
                    continue
            
            # é‡ã¿æ­£è¦åŒ–
            total_weight = sum(model_weights.values())
            if total_weight > 0:
                normalized_weights = {
                    name: weight / total_weight 
                    for name, weight in model_weights.items()
                }
            else:
                # å…¨ã¦ç­‰é‡ã¿
                num_models = len(model_weights)
                normalized_weights = {
                    name: 1.0 / num_models 
                    for name in model_weights.keys()
                }
            
            print(f"\nâš–ï¸ æ­£è¦åŒ–å¾Œé‡ã¿:")
            sorted_weights = sorted(normalized_weights.items(), key=lambda x: x[1], reverse=True)
            for rank, (model_name, weight) in enumerate(sorted_weights, 1):
                print(f"  {rank:2d}ä½: {model_name:15s} é‡ã¿: {weight:.4f}")
            
            return normalized_weights
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«é‡ã¿æ±ºå®šã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _calculate_strategy_bonus(self, strategy_stats):
        """æˆ¦ç•¥åˆ¥ãƒœãƒ¼ãƒŠã‚¹è¨ˆç®—"""
        try:
            if not strategy_stats:
                return 0
            
            # å„æˆ¦ç•¥ã®ç›¸å¯¾æ€§èƒ½ã‚’è©•ä¾¡
            strategy_scores = []
            for strategy, stats in strategy_stats.items():
                strategy_scores.append(stats['mean'])
            
            if not strategy_scores:
                return 0
            
            max_score = max(strategy_scores)
            min_score = min(strategy_scores)
            
            if max_score == min_score:
                return 0.5  # å…¨æˆ¦ç•¥åŒç­‰
            
            # é«˜æ€§èƒ½æˆ¦ç•¥ã®å‰²åˆ
            high_performance_ratio = sum(
                1 for score in strategy_scores 
                if score > (max_score + min_score) / 2
            ) / len(strategy_scores)
            
            return high_performance_ratio
            
        except Exception as e:
            print(f"âŒ æˆ¦ç•¥ãƒœãƒ¼ãƒŠã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
    
    def evaluate_cv_quality(self, all_cv_results):
        """CVå“è³ªè©•ä¾¡"""
        try:
            print("ğŸ“Š === CVå“è³ªè©•ä¾¡ ===")
            
            quality_metrics = {
                'total_models': len(all_cv_results),
                'completed_models': 0,
                'avg_splits_per_model': 0,
                'avg_cv_score': 0,
                'score_variance': 0,
                'reliability_score': 0
            }
            
            completed_results = []
            total_splits = []
            all_scores = []
            
            for model_name, cv_result in all_cv_results.items():
                if cv_result and cv_result.get('completed', False):
                    quality_metrics['completed_models'] += 1
                    
                    cv_results = cv_result.get('cv_results', [])
                    total_splits.append(len(cv_results))
                    
                    scores = [r['score'] for r in cv_results if 'score' in r]
                    all_scores.extend(scores)
                    completed_results.append(cv_result)
            
            if completed_results:
                quality_metrics['avg_splits_per_model'] = np.mean(total_splits)
                quality_metrics['avg_cv_score'] = np.mean(all_scores) if all_scores else 0
                quality_metrics['score_variance'] = np.var(all_scores) if all_scores else 0
                
                # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
                min_splits = min(total_splits) if total_splits else 0
                max_splits = max(total_splits) if total_splits else 0
                
                if max_splits > 0:
                    completion_rate = quality_metrics['completed_models'] / quality_metrics['total_models']
                    split_consistency = 1 - (max_splits - min_splits) / max_splits
                    score_stability = 1 / (1 + quality_metrics['score_variance'])
                    
                    quality_metrics['reliability_score'] = (
                        completion_rate * 0.4 +
                        split_consistency * 0.3 +
                        score_stability * 0.3
                    )
            
            print(f"  ğŸ“Š CVå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
            print(f"    ç·ãƒ¢ãƒ‡ãƒ«æ•°: {quality_metrics['total_models']}")
            print(f"    å®Œäº†ãƒ¢ãƒ‡ãƒ«æ•°: {quality_metrics['completed_models']}")
            print(f"    å®Œäº†ç‡: {quality_metrics['completed_models']/quality_metrics['total_models']*100:.1f}%")
            print(f"    å¹³å‡åˆ†å‰²æ•°: {quality_metrics['avg_splits_per_model']:.1f}")
            print(f"    å¹³å‡CVã‚¹ã‚³ã‚¢: {quality_metrics['avg_cv_score']:.4f}")
            print(f"    ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {quality_metrics['reliability_score']:.4f}")
            
            return quality_metrics
            
        except Exception as e:
            print(f"âŒ CVå“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

# ======================================================================
# 6. CVçµæœçµ±åˆãƒ»å‡ºåŠ›ã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================

# CVResultIntegrationã‚¯ãƒ©ã‚¹ã®_generate_cv_reportãƒ¡ã‚½ãƒƒãƒ‰ã®ä¿®æ­£

class CVResultIntegration:
    def __init__(self):
        self.evaluation_system = CVEvaluationSystem()
        
    def integrate_and_save_cv_results(self, all_cv_results):
        """CVçµæœçµ±åˆãƒ»ä¿å­˜"""
        try:
            print("ğŸ’¾ === CVçµæœçµ±åˆãƒ»ä¿å­˜é–‹å§‹ ===")
            
            # çµ±åˆçµæœä½œæˆ
            integrated_results = {
                'timestamp': datetime.now(),
                'cv_results': all_cv_results,
                'model_weights': {},
                'quality_metrics': {},
                'summary_statistics': {}
            }
            
            # ãƒ¢ãƒ‡ãƒ«é‡ã¿æ±ºå®š
            model_weights = self.evaluation_system.determine_ultra_model_weights(all_cv_results)
            integrated_results['model_weights'] = model_weights
            
            # å“è³ªè©•ä¾¡
            quality_metrics = self.evaluation_system.evaluate_cv_quality(all_cv_results)
            integrated_results['quality_metrics'] = quality_metrics
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            summary_stats = self._calculate_summary_statistics(all_cv_results)
            integrated_results['summary_statistics'] = summary_stats
            
            # çµæœä¿å­˜
            self._save_integrated_results(integrated_results)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self._generate_cv_report(integrated_results)
            
            print("âœ… CVçµæœçµ±åˆãƒ»ä¿å­˜å®Œäº†")
            return integrated_results
            
        except Exception as e:
            print(f"âŒ CVçµæœçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _calculate_summary_statistics(self, all_cv_results):
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼è¨ˆç®—"""
        try:
            summary = {
                'total_models': len(all_cv_results),
                'successful_models': 0,
                'total_cv_splits': 0,
                'avg_model_score': 0,
                'best_model': None,
                'worst_model': None,
                'score_distribution': {}
            }
            
            model_scores = {}
            
            for model_name, cv_result in all_cv_results.items():
                if cv_result and cv_result.get('completed', False):
                    summary['successful_models'] += 1
                    
                    cv_score = cv_result.get('cv_score', 0)
                    model_scores[model_name] = cv_score
                    
                    cv_results = cv_result.get('cv_results', [])
                    summary['total_cv_splits'] += len(cv_results)
            
            if model_scores:
                summary['avg_model_score'] = np.mean(list(model_scores.values()))
                
                # æœ€é«˜ãƒ»æœ€ä½ãƒ¢ãƒ‡ãƒ«
                best_model = max(model_scores.items(), key=lambda x: x[1])
                worst_model = min(model_scores.items(), key=lambda x: x[1])
                
                summary['best_model'] = {'name': best_model[0], 'score': best_model[1]}
                summary['worst_model'] = {'name': worst_model[0], 'score': worst_model[1]}
                
                # ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
                scores = list(model_scores.values())
                summary['score_distribution'] = {
                    'min': min(scores),
                    'max': max(scores),
                    'mean': np.mean(scores),
                    'std': np.std(scores),
                    'median': np.median(scores)
                }
            
            return summary
            
        except Exception as e:
            print(f"âŒ çµ±è¨ˆã‚µãƒãƒªãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _save_integrated_results(self, integrated_results):
        """çµ±åˆçµæœä¿å­˜"""
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
            results_file = "miniloto_models/cv_results/integrated_cv_results.pkl"
            os.makedirs(os.path.dirname(results_file), exist_ok=True)
            
            with open(results_file, 'wb') as f:
                pickle.dump(integrated_results, f)
            
            print(f"ğŸ’¾ çµ±åˆçµæœä¿å­˜: {results_file}")
            
            # CSVå½¢å¼ã§ã‚‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            self._export_cv_results_csv(integrated_results)
            
            # Google Driveä¿å­˜
            try:
                from google.colab import drive
                drive_file = "/content/drive/MyDrive/miniloto_models/cv_results/integrated_cv_results.pkl"
                os.makedirs(os.path.dirname(drive_file), exist_ok=True)
                
                with open(drive_file, 'wb') as f:
                    pickle.dump(integrated_results, f)
                
                print(f"â˜ï¸ Driveä¿å­˜å®Œäº†: {drive_file}")
            except:
                print("âš ï¸ Driveä¿å­˜ã‚¹ã‚­ãƒƒãƒ—")
            
        except Exception as e:
            print(f"âŒ çµ±åˆçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _export_cv_results_csv(self, integrated_results):
        """CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            # ãƒ¢ãƒ‡ãƒ«é‡ã¿CSV
            weights_data = []
            model_weights = integrated_results.get('model_weights', {})
            
            for model_name, weight in model_weights.items():
                cv_result = integrated_results['cv_results'].get(model_name, {})
                cv_score = cv_result.get('cv_score', 0)
                cv_std = cv_result.get('cv_std', 0)
                
                weights_data.append({
                    'ãƒ¢ãƒ‡ãƒ«å': model_name,
                    'é‡ã¿': weight,
                    'CVã‚¹ã‚³ã‚¢': cv_score,
                    'CVæ¨™æº–åå·®': cv_std,
                    'å®Œäº†': cv_result.get('completed', False)
                })
            
            weights_df = pd.DataFrame(weights_data)
            weights_csv = "miniloto_models/cv_results/model_weights.csv"
            weights_df.to_csv(weights_csv, index=False, encoding='utf-8-sig')
            
            print(f"ğŸ“„ é‡ã¿CSVä¿å­˜: {weights_csv}")
            
        except Exception as e:
            print(f"âŒ CSV ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# ======================================================================
# 7. CVãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================


    def _generate_cv_report(self, integrated_results):
        """CVå®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            print("ğŸ“‹ === CVå®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ===")
            
            report_lines = []
            report_lines.append("="*60)
            report_lines.append("ğŸ” ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ")
            report_lines.append("="*60)
            report_lines.append(f"å®Ÿè¡Œæ—¥æ™‚: {integrated_results['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
            report_lines.append("")
            
            # å®Ÿè¡Œæ¦‚è¦
            quality_metrics = integrated_results.get('quality_metrics', {})
            summary_stats = integrated_results.get('summary_statistics', {})
            
            report_lines.append("ğŸ“Š å®Ÿè¡Œæ¦‚è¦:")
            report_lines.append(f"  ç·ãƒ¢ãƒ‡ãƒ«æ•°: {quality_metrics.get('total_models', 0)}")
            report_lines.append(f"  å®Œäº†ãƒ¢ãƒ‡ãƒ«æ•°: {quality_metrics.get('completed_models', 0)}")
            report_lines.append(f"  å®Œäº†ç‡: {quality_metrics.get('completed_models', 0)/max(quality_metrics.get('total_models', 1), 1)*100:.1f}%")
            report_lines.append(f"  ç·CVåˆ†å‰²æ•°: {summary_stats.get('total_cv_splits', 0)}")
            report_lines.append(f"  å¹³å‡CVã‚¹ã‚³ã‚¢: {quality_metrics.get('avg_cv_score', 0):.4f}")
            report_lines.append(f"  ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {quality_metrics.get('reliability_score', 0):.4f}")
            report_lines.append("")
            
            # æœ€é«˜ãƒ»æœ€ä½ãƒ¢ãƒ‡ãƒ«
            if summary_stats.get('best_model'):
                best = summary_stats['best_model']
                worst = summary_stats['worst_model']
                
                report_lines.append("ğŸ† æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
                report_lines.append(f"  æœ€é«˜æ€§èƒ½: {best['name']} (ã‚¹ã‚³ã‚¢: {best['score']:.4f})")
                report_lines.append(f"  æœ€ä½æ€§èƒ½: {worst['name']} (ã‚¹ã‚³ã‚¢: {worst['score']:.4f})")
                report_lines.append("")
            
            # ãƒ¢ãƒ‡ãƒ«é‡ã¿
            model_weights = integrated_results.get('model_weights', {})
            if model_weights:
                sorted_weights = sorted(model_weights.items(), key=lambda x: x[1], reverse=True)
                
                report_lines.append("âš–ï¸ ãƒ¢ãƒ‡ãƒ«é‡ã¿ï¼ˆä¸Šä½10ä½ï¼‰:")
                for rank, (model_name, weight) in enumerate(sorted_weights[:10], 1):
                    report_lines.append(f"  {rank:2d}ä½: {model_name:15s} é‡ã¿: {weight:.4f}")
                report_lines.append("")
            
            # å“è³ªæŒ‡æ¨™è©³ç´°
            score_dist = summary_stats.get('score_distribution', {})
            if score_dist:
                report_lines.append("ğŸ“ˆ ã‚¹ã‚³ã‚¢åˆ†å¸ƒ:")
                report_lines.append(f"  æœ€é«˜ã‚¹ã‚³ã‚¢: {score_dist.get('max', 0):.4f}")
                report_lines.append(f"  æœ€ä½ã‚¹ã‚³ã‚¢: {score_dist.get('min', 0):.4f}")
                report_lines.append(f"  å¹³å‡ã‚¹ã‚³ã‚¢: {score_dist.get('mean', 0):.4f}")
                report_lines.append(f"  æ¨™æº–åå·®: {score_dist.get('std', 0):.4f}")
                report_lines.append(f"  ä¸­å¤®å€¤: {score_dist.get('median', 0):.4f}")
                report_lines.append("")
            
            # æ¨å¥¨äº‹é …
            report_lines.append("ğŸ’¡ æ¨å¥¨äº‹é …:")
            
            completion_rate = quality_metrics.get('completed_models', 0) / max(quality_metrics.get('total_models', 1), 1)
            if completion_rate < 0.8:
                report_lines.append("  â€¢ CVå®Œäº†ç‡ãŒä½ã„ãŸã‚ã€ç¶™ç¶šå®Ÿè¡Œã‚’æ¨å¥¨")
            
            avg_score = quality_metrics.get('avg_cv_score', 0)
            if avg_score < 0.7:
                report_lines.append("  â€¢ å¹³å‡ã‚¹ã‚³ã‚¢ãŒä½ã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«èª¿æ•´ã‚’æ¨å¥¨")
            elif avg_score > 0.9:
                report_lines.append("  â€¢ é«˜ã‚¹ã‚³ã‚¢é”æˆã€éå­¦ç¿’ãƒã‚§ãƒƒã‚¯ã‚’æ¨å¥¨")
            
            reliability = quality_metrics.get('reliability_score', 0)
            if reliability > 0.8:
                report_lines.append("  â€¢ é«˜ä¿¡é ¼æ€§é”æˆã€ãƒ¡ã‚¤ãƒ³äºˆæ¸¬ã«é©ç”¨å¯èƒ½")
            
            report_lines.append("")
            report_lines.append("="*60)
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            report_text = "\n".join(report_lines)
            report_file = f"miniloto_models/cv_results/cv_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
            
            print(f"ğŸ“„ CVãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
            
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
            print("\n" + report_text)
            
        except Exception as e:
            print(f"âŒ CVãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")


# ãƒ‘ãƒ¼ãƒˆ3ã“ã“ã¾ã§

# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part4: ãƒ¬ãƒãƒ¼ãƒˆãƒ»ç¶™ç¶šæ©Ÿèƒ½

# ======================================================================
# 8. CVç¶™ç¶šãƒ»ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================

class CVMonitoringSystem:
    def __init__(self):
        self.cv_manager = ScoreBasedCVManager()
        self.result_integration = CVResultIntegration()
        

    def monitor_cv_progress(self):
        """CVé€²æ—ç›£è¦–"""
        try:
            print("ğŸ‘ï¸ === CVé€²æ—ç›£è¦–é–‹å§‹ ===")
            
            cv_dir = "miniloto_models/cv_results"
            if not os.path.exists(cv_dir):
                print("âŒ CVçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
            
            progress_files = [f for f in os.listdir(cv_dir) if f.endswith('_cv_progress.pkl')]
            
            if not progress_files:
                print("ğŸ“ CVé€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
            
            progress_summary = {}
            
            for progress_file in progress_files:
                try:
                    model_name = progress_file.replace('_cv_progress.pkl', '')
                    file_path = os.path.join(cv_dir, progress_file)
                    
                    with open(file_path, 'rb') as f:
                        progress_data = pickle.load(f)
                    
                    progress_summary[model_name] = {
                        'completed_splits': progress_data.get('completed_splits', 0),
                        'total_splits': progress_data.get('total_splits', 0),
                        'completion_rate': progress_data.get('completion_rate', 0),
                        'timestamp': progress_data.get('timestamp', datetime.now())
                    }
                    
                except Exception as e:
                    print(f"âš ï¸ {progress_file} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # é€²æ—è¡¨ç¤º
            print(f"ğŸ“Š CVé€²æ—ã‚µãƒãƒªãƒ¼ ({len(progress_summary)}ãƒ¢ãƒ‡ãƒ«):")
            
            sorted_progress = sorted(
                progress_summary.items(),
                key=lambda x: x[1]['completion_rate'],
                reverse=True
            )
            
            for model_name, progress in sorted_progress:
                completed = progress['completed_splits']
                total = progress['total_splits']
                rate = progress['completion_rate']
                
                print(f"  {model_name:15s}: {completed:4d}/{total:4d} ({rate*100:5.1f}%)")
            
            return progress_summary
            
        except Exception as e:
            print(f"âŒ CVé€²æ—ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    
    def resume_incomplete_cv(self, max_models=None):
        """æœªå®Œäº†CVå†é–‹"""
        try:
            print("ğŸ”„ === æœªå®Œäº†CVå†é–‹å®Ÿè¡Œ ===")
            
            # é€²æ—ç¢ºèª
            progress_summary = self.monitor_cv_progress()
            
            if not progress_summary:
                print("âŒ å†é–‹å¯¾è±¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # æœªå®Œäº†ãƒ¢ãƒ‡ãƒ«æŠ½å‡º
            incomplete_models = [
                model_name for model_name, progress in progress_summary.items()
                if progress['completion_rate'] < 1.0
            ]
            
            if not incomplete_models:
                print("âœ… å…¨ãƒ¢ãƒ‡ãƒ«å®Œäº†æ¸ˆã¿")
                return True
            
            if max_models:
                incomplete_models = incomplete_models[:max_models]
            
            print(f"ğŸ¯ å†é–‹å¯¾è±¡: {len(incomplete_models)}ãƒ¢ãƒ‡ãƒ«")
            
            # ç‰¹å¾´é‡èª­ã¿è¾¼ã¿
            X, y = self.cv_manager.cv_system.load_features_for_cv()
            if X is None or y is None:
                print("âŒ ç‰¹å¾´é‡èª­ã¿è¾¼ã¿å¤±æ•—")
                return False
            
            # å†é–‹å®Ÿè¡Œ
            resumed_results = {}
            
            for model_name in incomplete_models:
                print(f"\nğŸ”„ {model_name} CVå†é–‹...")
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—
                models_data = self.cv_manager.cv_system.load_available_models_for_cv()
                if model_name not in models_data:
                    print(f"âŒ {model_name} ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    continue
                
                model_info = models_data[model_name]
                
                # CVå®Ÿè¡Œ
                try:
                    cv_result = self.cv_manager.execute_incremental_cv_for_model(
                        model_name, model_info, X, y, splits_per_batch=10
                    )
                    
                    if cv_result:
                        resumed_results[model_name] = cv_result
                        print(f"âœ… {model_name} CVå†é–‹å®Œäº†")
                    else:
                        print(f"âŒ {model_name} CVå†é–‹å¤±æ•—")
                        
                except Exception as e:
                    print(f"âŒ {model_name} CVå†é–‹ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            if resumed_results:
                print(f"\nğŸ‰ CVå†é–‹å®Œäº†: {len(resumed_results)}ãƒ¢ãƒ‡ãƒ«")
                
                # çµæœçµ±åˆ
                self.result_integration.integrate_and_save_cv_results(resumed_results)
                return True
            else:
                print("âŒ CVå†é–‹ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except Exception as e:
            print(f"âŒ CVå†é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def cleanup_cv_files(self, keep_recent=3):
        """CVä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            print("ğŸ§¹ === CVãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===")
            
            cv_dir = "miniloto_models/cv_results"
            if not os.path.exists(cv_dir):
                return
            
            # é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†
            progress_files = []
            for filename in os.listdir(cv_dir):
                if filename.endswith('_cv_progress.pkl'):
                    file_path = os.path.join(cv_dir, filename)
                    modification_time = os.path.getmtime(file_path)
                    progress_files.append((filename, modification_time))
            
            # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if len(progress_files) > keep_recent:
                progress_files.sort(key=lambda x: x[1], reverse=True)
                files_to_delete = progress_files[keep_recent:]
                
                deleted_count = 0
                for filename, _ in files_to_delete:
                    try:
                        file_path = os.path.join(cv_dir, filename)
                        os.remove(file_path)
                        deleted_count += 1
                        print(f"  ğŸ—‘ï¸ å‰Šé™¤: {filename}")
                    except Exception as e:
                        print(f"  âš ï¸ å‰Šé™¤å¤±æ•—: {filename} - {e}")
                
                print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤")
            else:
                print("ğŸ“ å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
                
        except Exception as e:
            print(f"âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ‘ãƒ¼ãƒˆ4ã“ã“ã¾ã§

# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part5: ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œæ©Ÿèƒ½

# ======================================================================
# 9. ãƒ¡ã‚¤ãƒ³CVå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 
# ======================================================================

class MainCVExecutor:
    def __init__(self):
        self.cv_manager = ScoreBasedCVManager()
        self.monitoring = CVMonitoringSystem()
        self.result_integration = CVResultIntegration()
        
    def execute_full_background_cv(self, resume_incomplete=True, max_models=None):
        """ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œ"""
        try:
            start_time = time.time()
            
            print("ğŸš€ === ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œé–‹å§‹ ===")
            print("â±ï¸ äºˆæƒ³å‡¦ç†æ™‚é–“: æ•°æ™‚é–“ï½æ•°æ—¥ï¼ˆãƒ¢ãƒ‡ãƒ«æ•°ãƒ»åˆ†å‰²æ•°ã«ã‚ˆã‚‹ï¼‰")
            print("ğŸ“Š ã‚¹ã‚³ã‚¢é †å®Ÿè¡Œãƒ»æ®µéšçš„ä¿å­˜ãƒ»ç¶™ç¶šå¯èƒ½")
            
            # æœªå®Œäº†CVç¢ºèªãƒ»å†é–‹
            if resume_incomplete:
                print("\nğŸ” æœªå®Œäº†CVç¢ºèªä¸­...")
                progress_summary = self.monitoring.monitor_cv_progress()
                
                if progress_summary:
                    incomplete_count = sum(
                        1 for progress in progress_summary.values()
                        if progress['completion_rate'] < 1.0
                    )
                    
                    if incomplete_count > 0:
                        print(f"ğŸ”„ æœªå®Œäº†ãƒ¢ãƒ‡ãƒ«ç™ºè¦‹: {incomplete_count}å€‹")
                        print("æœªå®Œäº†CVå†é–‹ã‚’å®Ÿè¡Œã—ã¾ã™...")
                        
                        if self.monitoring.resume_incomplete_cv(max_models):
                            print("âœ… æœªå®Œäº†CVå†é–‹å®Œäº†")
                        else:
                            print("âš ï¸ æœªå®Œäº†CVå†é–‹ã«ä¸€éƒ¨å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸ")
            
            # ç‰¹å¾´é‡èª­ã¿è¾¼ã¿
            print("\nğŸ“¥ CVç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
            X, y = self.cv_manager.cv_system.load_features_for_cv()
            
            if X is None or y is None:
                print("âŒ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                print("ğŸ”§ å…ˆã«ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆrun_ultra_maximum_precision_predictionï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
                return None
            
            print(f"âœ… ç‰¹å¾´é‡èª­ã¿è¾¼ã¿å®Œäº†: {X.shape}")
            
            # ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œ
            print("\nğŸ” ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œé–‹å§‹...")
            cv_results = self.cv_manager.execute_cv_in_score_order(
                X, y, max_models=max_models, splits_per_batch=10
            )
            
            if not cv_results:
                print("âŒ CVå®Ÿè¡Œçµæœãªã—")
                return None
            
            # çµæœçµ±åˆãƒ»ä¿å­˜
            print("\nğŸ’¾ CVçµæœçµ±åˆãƒ»ä¿å­˜...")
            integrated_results = self.result_integration.integrate_and_save_cv_results(cv_results)
            
            # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
            total_elapsed = time.time() - start_time
            
            print(f"\nğŸ‰ === ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œå®Œäº† ===")
            print(f"â±ï¸ ç·å®Ÿè¡Œæ™‚é–“: {total_elapsed/3600:.1f}æ™‚é–“")
            print(f"ğŸ¤– å®Œäº†ãƒ¢ãƒ‡ãƒ«æ•°: {len(cv_results)}")
            
            if integrated_results:
                quality_metrics = integrated_results.get('quality_metrics', {})
                print(f"ğŸ“Š å¹³å‡CVã‚¹ã‚³ã‚¢: {quality_metrics.get('avg_cv_score', 0):.4f}")
                print(f"ğŸ¯ ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {quality_metrics.get('reliability_score', 0):.4f}")
                
                # æ¬¡å›å®Ÿè¡Œæ¨å¥¨
                reliability = quality_metrics.get('reliability_score', 0)
                if reliability > 0.8:
                    print("âœ… é«˜ä¿¡é ¼æ€§é”æˆã€‚ãƒ¡ã‚¤ãƒ³äºˆæ¸¬ã§ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
                elif reliability > 0.6:
                    print("ğŸ“ˆ è‰¯å¥½ãªçµæœã€‚ç¶™ç¶šå®Ÿè¡Œã§ã•ã‚‰ãªã‚‹æ”¹å–„å¯èƒ½")
                else:
                    print("ğŸ”„ ä¿¡é ¼æ€§å‘ä¸Šã®ãŸã‚ç¶™ç¶šå®Ÿè¡Œã‚’æ¨å¥¨ã—ã¾ã™")
            
            return integrated_results
            
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"âŒ ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            print(f"â±ï¸ ã‚¨ãƒ©ãƒ¼æ™‚ç‚¹ã§ã®å®Ÿè¡Œæ™‚é–“: {elapsed/3600:.1f}æ™‚é–“")
            print(f"è©³ç´°: {traceback.format_exc()}")
            return None
    
    def execute_quick_cv(self, target_models=5, splits_per_batch=5):
        """ã‚¯ã‚¤ãƒƒã‚¯CVå®Ÿè¡Œï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        try:
            print("âš¡ === ã‚¯ã‚¤ãƒƒã‚¯CVå®Ÿè¡Œé–‹å§‹ ===")
            print(f"ğŸ¯ å¯¾è±¡: ä¸Šä½{target_models}ãƒ¢ãƒ‡ãƒ«")
            
            start_time = time.time()
            
            # ç‰¹å¾´é‡èª­ã¿è¾¼ã¿
            X, y = self.cv_manager.cv_system.load_features_for_cv()
            if X is None or y is None:
                print("âŒ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãªã—")
                return None
            
            # ä¸Šä½ãƒ¢ãƒ‡ãƒ«ã®ã¿CVå®Ÿè¡Œ
            cv_results = self.cv_manager.execute_cv_in_score_order(
                X, y, max_models=target_models, splits_per_batch=splits_per_batch
            )
            
            elapsed_time = time.time() - start_time
            
            if cv_results:
                print(f"âœ… ã‚¯ã‚¤ãƒƒã‚¯CVå®Œäº†: {len(cv_results)}ãƒ¢ãƒ‡ãƒ« ({elapsed_time/60:.1f}åˆ†)")
                
                # ç°¡æ˜“çµæœä¿å­˜
                quick_results = {
                    'timestamp': datetime.now(),
                    'cv_results': cv_results,
                    'execution_time': elapsed_time,
                    'type': 'quick_cv'
                }
                
                quick_file = f"miniloto_models/cv_results/quick_cv_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
                with open(quick_file, 'wb') as f:
                    pickle.dump(quick_results, f)
                
                print(f"ğŸ’¾ ã‚¯ã‚¤ãƒƒã‚¯çµæœä¿å­˜: {quick_file}")
                return quick_results
            else:
                print("âŒ ã‚¯ã‚¤ãƒƒã‚¯CVå¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ ã‚¯ã‚¤ãƒƒã‚¯CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def execute_single_model_cv(self, model_name, splits_per_batch=10):
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«CVå®Ÿè¡Œ"""
        try:
            print(f"ğŸ¯ === å˜ä¸€ãƒ¢ãƒ‡ãƒ«CVå®Ÿè¡Œ: {model_name} ===")
            
            start_time = time.time()
            
            # ç‰¹å¾´é‡èª­ã¿è¾¼ã¿
            X, y = self.cv_manager.cv_system.load_features_for_cv()
            if X is None or y is None:
                print("âŒ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãªã—")
                return None
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—
            models_data = self.cv_manager.cv_system.load_available_models_for_cv()
            if model_name not in models_data:
                print(f"âŒ {model_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                print(f"åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {list(models_data.keys())}")
                return None
            
            model_info = models_data[model_name]
            
            # CVå®Ÿè¡Œ
            cv_result = self.cv_manager.execute_incremental_cv_for_model(
                model_name, model_info, X, y, splits_per_batch
            )
            
            elapsed_time = time.time() - start_time
            
            if cv_result:
                print(f"âœ… {model_name} CVå®Œäº† ({elapsed_time/60:.1f}åˆ†)")
                print(f"ğŸ“Š CVã‚¹ã‚³ã‚¢: {cv_result.get('cv_score', 0):.4f}")
                
                return {model_name: cv_result}
            else:
                print(f"âŒ {model_name} CVå¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ å˜ä¸€ãƒ¢ãƒ‡ãƒ«CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def validate_feature_compatibility(self):
        """ç‰¹å¾´é‡äº’æ›æ€§æ¤œè¨¼"""
        try:
            print("ğŸ” ç‰¹å¾´é‡äº’æ›æ€§æ¤œè¨¼ä¸­...")
            
            cv_dir = "miniloto_models/cv_results"
            if not os.path.exists(cv_dir):
                print("ğŸ“ CVçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã—ã€å•é¡Œãªã—")
                return True
            
            # ç¾åœ¨ã®ç‰¹å¾´é‡ãƒãƒ¼ã‚¸ãƒ§ãƒ³
            features_file = "miniloto_models/features/features_cache.pkl"
            if os.path.exists(features_file):
                import hashlib
                mtime = os.path.getmtime(features_file)
                current_version = hashlib.md5(str(mtime).encode()).hexdigest()[:8]
            else:
                print("âŒ ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
            progress_files = [f for f in os.listdir(cv_dir) if f.endswith('_cv_progress.pkl')]
            
            compatible_count = 0
            incompatible_count = 0
            
            for progress_file in progress_files:
                try:
                    file_path = os.path.join(cv_dir, progress_file)
                    with open(file_path, 'rb') as f:
                        progress_data = pickle.load(f)
                    
                    saved_version = progress_data.get('feature_version', 'unknown')
                    
                    if saved_version == current_version:
                        compatible_count += 1
                    else:
                        incompatible_count += 1
                        model_name = progress_file.replace('_cv_progress.pkl', '')
                        print(f"  âš ï¸ {model_name}: v{saved_version} â†’ v{current_version} (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´)")
                        
                except Exception as e:
                    print(f"  âŒ {progress_file} ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
                    incompatible_count += 1
            
            print(f"âœ… äº’æ›æ€§ãƒã‚§ãƒƒã‚¯å®Œäº†:")
            print(f"  äº’æ›: {compatible_count}ãƒ¢ãƒ‡ãƒ«")
            print(f"  éäº’æ›: {incompatible_count}ãƒ¢ãƒ‡ãƒ«")
            
            if incompatible_count > 0:
                print(f"ğŸ’¡ éäº’æ›ãƒ¢ãƒ‡ãƒ«ã¯æ–°ã—ã„ç‰¹å¾´é‡ã§æ–°è¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾´é‡äº’æ›æ€§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False

# ======================================================================
# 10. CVçŠ¶æ…‹ç®¡ç†ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ======================================================================

class CVUtilities:
    @staticmethod
    def show_cv_status():
        """CVçŠ¶æ…‹è¡¨ç¤º"""
        try:
            print("ğŸ“Š === CVçŠ¶æ…‹è¡¨ç¤º ===")
            
            monitoring = CVMonitoringSystem()
            progress_summary = monitoring.monitor_cv_progress()
            
            if not progress_summary:
                print("ğŸ“ CVå®Ÿè¡Œå±¥æ­´ãªã—")
                return
            
            # å®Œäº†çŠ¶æ³
            completed_models = [
                name for name, progress in progress_summary.items()
                if progress['completion_rate'] >= 1.0
            ]
            
            incomplete_models = [
                name for name, progress in progress_summary.items()
                if progress['completion_rate'] < 1.0
            ]
            
            print(f"âœ… å®Œäº†ãƒ¢ãƒ‡ãƒ«: {len(completed_models)}å€‹")
            print(f"ğŸ”„ æœªå®Œäº†ãƒ¢ãƒ‡ãƒ«: {len(incomplete_models)}å€‹")
            
            if incomplete_models:
                print("\nğŸ”„ æœªå®Œäº†ãƒ¢ãƒ‡ãƒ«è©³ç´°:")
                for model_name in incomplete_models[:5]:  # ä¸Šä½5å€‹è¡¨ç¤º
                    progress = progress_summary[model_name]
                    rate = progress['completion_rate']
                    print(f"  {model_name}: {rate*100:.1f}%å®Œäº†")
            
            # æœ€æ–°çµæœç¢ºèª
            cv_results_dir = "miniloto_models/cv_results"
            if os.path.exists(cv_results_dir):
                result_files = [
                    f for f in os.listdir(cv_results_dir) 
                    if f.startswith('integrated_cv_results') and f.endswith('.pkl')
                ]
                
                if result_files:
                    latest_file = max(result_files, key=lambda f: os.path.getmtime(os.path.join(cv_results_dir, f)))
                    file_time = datetime.fromtimestamp(os.path.getmtime(os.path.join(cv_results_dir, latest_file)))
                    print(f"\nğŸ“„ æœ€æ–°çµ±åˆçµæœ: {latest_file}")
                    print(f"ğŸ•’ æ›´æ–°æ—¥æ™‚: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    
        except Exception as e:
            print(f"âŒ CVçŠ¶æ…‹è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    @staticmethod
    def clean_cv_data(confirm=False):
        """CVãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if not confirm:
                print("âš ï¸ CVãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
                print("å…¨ã¦ã®é€²æ—ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¾ã™ã€‚")
                print("å®Ÿè¡Œã™ã‚‹å ´åˆã¯ clean_cv_data(confirm=True) ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
                return
            
            print("ğŸ§¹ === CVãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ ===")
            
            cv_dir = "miniloto_models/cv_results"
            if not os.path.exists(cv_dir):
                print("ğŸ“ CVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return
            
            # é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            progress_files = [f for f in os.listdir(cv_dir) if f.endswith('_cv_progress.pkl')]
            deleted_count = 0
            
            for filename in progress_files:
                try:
                    file_path = os.path.join(cv_dir, filename)
                    os.remove(file_path)
                    deleted_count += 1
                    print(f"  ğŸ—‘ï¸ å‰Šé™¤: {filename}")
                except Exception as e:
                    print(f"  âš ï¸ å‰Šé™¤å¤±æ•—: {filename} - {e}")
            
            print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤")
            
        except Exception as e:
            print(f"âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    @staticmethod
    def export_cv_summary():
        """CVçµæœã‚µãƒãƒªãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            print("ğŸ“Š === CVçµæœã‚µãƒãƒªãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ===")
            
            # æœ€æ–°çµ±åˆçµæœèª­ã¿è¾¼ã¿
            cv_results_dir = "miniloto_models/cv_results"
            integrated_file = os.path.join(cv_results_dir, "integrated_cv_results.pkl")
            
            if not os.path.exists(integrated_file):
                print("âŒ çµ±åˆCVçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            with open(integrated_file, 'rb') as f:
                integrated_results = pickle.load(f)
            
            # ã‚µãƒãƒªãƒ¼ä½œæˆ
            summary = {
                "å®Ÿè¡Œæ—¥æ™‚": integrated_results['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                "å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹": integrated_results.get('quality_metrics', {}),
                "çµ±è¨ˆã‚µãƒãƒªãƒ¼": integrated_results.get('summary_statistics', {}),
                "ãƒ¢ãƒ‡ãƒ«é‡ã¿ä¸Šä½5ä½": {}
            }
            
            # ä¸Šä½5ãƒ¢ãƒ‡ãƒ«é‡ã¿
            model_weights = integrated_results.get('model_weights', {})
            if model_weights:
                sorted_weights = sorted(model_weights.items(), key=lambda x: x[1], reverse=True)
                for rank, (model_name, weight) in enumerate(sorted_weights[:5], 1):
                    summary["ãƒ¢ãƒ‡ãƒ«é‡ã¿ä¸Šä½5ä½"][f"{rank}ä½"] = f"{model_name} ({weight:.4f})"
            
            # JSONå½¢å¼ã§ä¿å­˜
            import json
            summary_file = f"miniloto_models/cv_results/cv_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ ã‚µãƒãƒªãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {summary_file}")
            return summary_file
            
        except Exception as e:
            print(f"âŒ ã‚µãƒãƒªãƒ¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

# ãƒ‘ãƒ¼ãƒˆ5ã“ã“ã¾ã§

# -*- coding: utf-8 -*-
# ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Part6: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

# ======================================================================
# 11. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ç¾¤
# ======================================================================

def run_background_cv_full():
    """ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œ"""
    try:
        print("ğŸŒŸ === ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ ===")
        print("ğŸš€ ãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰: å…¨ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¹ã‚³ã‚¢é †ãƒ»æ®µéšçš„ä¿å­˜")
        print("="*60)
        
        # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
        executor = MainCVExecutor()
        result = executor.execute_full_background_cv(
            resume_incomplete=True,
            max_models=None  # å…¨ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
        )
        
        if result:
            print("\nğŸ‰ ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡ŒæˆåŠŸï¼")
            
            # çµæœã‚µãƒãƒªãƒ¼
            quality_metrics = result.get('quality_metrics', {})
            model_weights = result.get('model_weights', {})
            
            print(f"ğŸ“Š å®Ÿè¡Œçµæœ:")
            print(f"  å®Œäº†ãƒ¢ãƒ‡ãƒ«æ•°: {quality_metrics.get('completed_models', 0)}")
            print(f"  å¹³å‡CVã‚¹ã‚³ã‚¢: {quality_metrics.get('avg_cv_score', 0):.4f}")
            print(f"  ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {quality_metrics.get('reliability_score', 0):.4f}")
            
            if model_weights:
                sorted_weights = sorted(model_weights.items(), key=lambda x: x[1], reverse=True)
                print(f"\nâš–ï¸ ä¸Šä½3ãƒ¢ãƒ‡ãƒ«é‡ã¿:")
                for rank, (model_name, weight) in enumerate(sorted_weights[:3], 1):
                    print(f"    {rank}ä½: {model_name} ({weight:.4f})")
            
            print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            print(f"  ğŸ”„ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å†å®Ÿè¡Œã§æœ€é«˜ç²¾åº¦äºˆæ¸¬")
            print(f"  ğŸ“Š run_ultra_maximum_precision_prediction()")
            
        else:
            print("\nğŸ˜ ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
            print("ğŸ” ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
        
    except Exception as e:
        print(f"\nğŸ’¥ ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"è©³ç´°: {traceback.format_exc()}")

def run_background_cv_quick():
    """ã‚¯ã‚¤ãƒƒã‚¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œ"""
    try:
        print("âš¡ === ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œ ===")
        print("ğŸ¯ é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰: ä¸Šä½5ãƒ¢ãƒ‡ãƒ«ãƒ»æœ€å°åˆ†å‰²")
        print("="*50)
        
        executor = MainCVExecutor()
        result = executor.execute_quick_cv(
            target_models=5,
            splits_per_batch=5
        )
        
        if result:
            print("\nâœ… ã‚¯ã‚¤ãƒƒã‚¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Œäº†ï¼")
            print("ğŸ”„ ãƒ•ãƒ«å®Ÿè¡Œã§ã®ç²¾åº¦å‘ä¸Šã‚‚å¯èƒ½ã§ã™")
        else:
            print("\nâŒ ã‚¯ã‚¤ãƒƒã‚¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå¤±æ•—")
        
    except Exception as e:
        print(f"\nğŸ’¥ ã‚¯ã‚¤ãƒƒã‚¯CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

def run_background_cv_resume():
    """æœªå®Œäº†CVå†é–‹å®Ÿè¡Œ"""
    try:
        print("ğŸ”„ === æœªå®Œäº†CVå†é–‹å®Ÿè¡Œ ===")
        
        monitoring = CVMonitoringSystem()
        success = monitoring.resume_incomplete_cv(max_models=10)
        
        if success:
            print("âœ… æœªå®Œäº†CVå†é–‹å®Œäº†")
        else:
            print("âŒ æœªå®Œäº†CVå†é–‹å¤±æ•—")
        
    except Exception as e:
        print(f"ğŸ’¥ CVå†é–‹ã‚¨ãƒ©ãƒ¼: {e}")

def run_background_cv_single(model_name):
    """å˜ä¸€ãƒ¢ãƒ‡ãƒ«CVå®Ÿè¡Œ"""
    try:
        print(f"ğŸ¯ === å˜ä¸€ãƒ¢ãƒ‡ãƒ«CVå®Ÿè¡Œ: {model_name} ===")
        
        executor = MainCVExecutor()
        result = executor.execute_single_model_cv(model_name)
        
        if result:
            print(f"âœ… {model_name} CVå®Œäº†")
        else:
            print(f"âŒ {model_name} CVå¤±æ•—")
        
    except Exception as e:
        print(f"ğŸ’¥ å˜ä¸€ãƒ¢ãƒ‡ãƒ«CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

# ======================================================================
# 12. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å®Ÿè¡Œé–¢æ•°
# ======================================================================

def show_cv_progress():
    """CVé€²æ—è¡¨ç¤º"""
    CVUtilities.show_cv_status()

def clean_cv_progress(confirm=False):
    """CVé€²æ—ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    CVUtilities.clean_cv_data(confirm=confirm)

def export_cv_results():
    """CVçµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    return CVUtilities.export_cv_summary()

def cleanup_cv_files():
    """CVä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    monitoring = CVMonitoringSystem()
    monitoring.cleanup_cv_files()

# ======================================================================
# 13. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ¡ãƒ‹ãƒ¥ãƒ¼
# ======================================================================

def show_cv_menu():
    """CVãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º"""
    print("\n" + "="*60)
    print("ğŸ” ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸš€ æ”¹ä¿®ç‰ˆ: ã‚¹ã‚³ã‚¢é †ãƒ»æ®µéšçš„ä¿å­˜ãƒ»ç¶™ç¶šå®Ÿè¡Œå¯¾å¿œ")
    print("="*60)
    print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:")
    print("  1. ãƒ•ãƒ«å®Ÿè¡Œ: run_background_cv_full()")
    print("  2. ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œ: run_background_cv_quick()")
    print("  3. æœªå®Œäº†å†é–‹: run_background_cv_resume()")
    print("  4. å˜ä¸€ãƒ¢ãƒ‡ãƒ«: run_background_cv_single('model_name')")
    print("  5. é€²æ—ç¢ºèª: show_cv_progress()")
    print("  6. çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: export_cv_results()")
    print("  7. ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†: cleanup_cv_files()")
    print("\nğŸ”§ æ”¹ä¿®ã®ç‰¹å¾´:")
    print("  â€¢ ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œï¼ˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼‰")
    print("  â€¢ 10ä»¶ã”ã¨æ®µéšçš„ä¿å­˜ï¼ˆä¸­æ–­å®‰å…¨ï¼‰")
    print("  â€¢ ç¶™ç¶šå®Ÿè¡Œå¯èƒ½ï¼ˆã„ã¤ã§ã‚‚å†é–‹ï¼‰")
    print("  â€¢ Google Driveè‡ªå‹•åŒæœŸ")
    print("\nâš¡ æ¨å¥¨å®Ÿè¡Œé †åº:")
    print("  1. ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œï¼ˆãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼‰")
    print("  2. ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVå®Ÿè¡Œï¼ˆç²¾åº¦å‘ä¸Šï¼‰")
    print("  3. ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å†å®Ÿè¡Œï¼ˆæœ€é«˜ç²¾åº¦äºˆæ¸¬ï¼‰")

def run_cv_interactive():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–CVå®Ÿè¡Œï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    try:
        show_cv_menu()
        
        # é€²æ—çŠ¶æ³ã‚’è‡ªå‹•åˆ¤å®š
        monitoring = CVMonitoringSystem()
        progress_summary = monitoring.monitor_cv_progress()
        
        if not progress_summary:
            # é€²æ—ãƒ•ã‚¡ã‚¤ãƒ«ãªã— = åˆå›å®Ÿè¡Œ
            print(f"\nğŸ†• åˆå›å®Ÿè¡Œ: ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVã‚’é–‹å§‹ã—ã¾ã™")
            run_background_cv_full()
            
        else:
            # ç‰¹å¾´é‡äº’æ›æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            executor = MainCVExecutor()
            compatibility_ok = executor.validate_feature_compatibility()
            
            if not compatibility_ok:
                print(f"\nğŸ”„ ç‰¹å¾´é‡å¤‰æ›´æ¤œå‡º: ãƒ•ãƒ«CVå†å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™")
                run_background_cv_full()
                
            else:
                # äº’æ›æ€§OK = ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®é€²æ—çŠ¶æ³ã‚’åˆ¤å®š
                incomplete_count = sum(
                    1 for progress in progress_summary.values()
                    if progress['completion_rate'] < 1.0
                )
                
                if incomplete_count > 0:
                    print(f"\nğŸ”„ æœªå®Œäº†CVç™ºè¦‹: ç¶™ç¶šå®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™")
                    run_background_cv_resume()
                else:
                    print(f"\nâœ… å…¨CVå®Œäº†æ¸ˆã¿: ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ã®äºˆæ¸¬å®Ÿè¡Œã‚’æ¨å¥¨")
                    print(f"ğŸ“Š è¿½åŠ å®Ÿè¡ŒãŒå¿…è¦ãªå ´åˆã¯æ‰‹å‹•ã§é–¢æ•°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
    except Exception as e:
        print(f"ğŸ’¥ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–CVå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

# ======================================================================
# 14. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ======================================================================

if __name__ == "__main__":
    print("ğŸ” ãƒŸãƒ‹ãƒ­ãƒˆæ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    print("ğŸ¯ æ”¹ä¿®ç‰ˆ: æ®µéšçš„ä¿å­˜ãƒ»ç¶™ç¶šå®Ÿè¡Œãƒ»ã‚¹ã‚³ã‚¢é †å¯¾å¿œ")
    print("="*60)
    
    try:
        # ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª
        print("ğŸ” ã‚·ã‚¹ãƒ†ãƒ ç¢ºèªä¸­...")
        
        # å¿…è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs("miniloto_models/cv_results", exist_ok=True)
        os.makedirs("miniloto_models/models", exist_ok=True)
        
        # CVçŠ¶æ…‹ç¢ºèª
        print("ğŸ“Š ç¾åœ¨ã®CVçŠ¶æ…‹:")
        CVUtilities.show_cv_status()
        
        print(f"\nğŸ• ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
        run_cv_interactive()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        print("ğŸ”„ ç¶™ç¶šå®Ÿè¡Œæ©Ÿèƒ½ã«ã‚ˆã‚Šã€ã„ã¤ã§ã‚‚å†é–‹å¯èƒ½ã§ã™")
    except Exception as e:
        print(f"\nğŸ’¥ ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ”§ ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ãŒå…ˆã«å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
    finally:
        print(f"\nğŸ•’ ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("ğŸ™ æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")

# ======================================================================
# ãƒ‘ãƒ¼ãƒˆ6ã“ã“ã¾ã§
# 
# ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰CVæ”¹ä¿®å®Œäº†ã€‘
# - ã‚¹ã‚³ã‚¢é †CVå®Ÿè¡Œï¼ˆé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼‰
# - æ®µéšçš„ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ10ä»¶ã”ã¨ä¿å­˜ï¼‰
# - ç¶™ç¶šå®Ÿè¡Œæ©Ÿèƒ½ï¼ˆä¸­æ–­ãƒ»å†é–‹å¯¾å¿œï¼‰
# - CVçµæœçµ±åˆãƒ»é‡ã¿æ±ºå®š
# - Google Driveè‡ªå‹•åŒæœŸ
# - åŒ…æ‹¬çš„ç›£è¦–ãƒ»ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½
# 
# ã€ä½¿ç”¨æ–¹æ³•ã€‘
# 1. ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå¾Œã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
# 2. run_background_cv_full() ã§ãƒ•ãƒ«å®Ÿè¡Œ
# 3. run_background_cv_quick() ã§é«˜é€Ÿå®Ÿè¡Œ
# 4. show_cv_progress() ã§é€²æ—ç¢ºèª
# 5. ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å†å®Ÿè¡Œã§æœ€é«˜ç²¾åº¦äºˆæ¸¬
# ======================================================================